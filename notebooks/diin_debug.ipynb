{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.9 64-bit",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "# TODO : Add Embedding penalty\n",
    "\n",
    "\n",
    "class DIIN_conf:\n",
    "    embedding_dim = 800\n",
    "    hidden_size = 300\n",
    "    num_layers = 2\n",
    "    freeze_encoder = True\n",
    "    dense_net_growth_rate = 20\n",
    "    dense_net_layers = 3\n",
    "    dense_net_transition_rate = 0.2\n",
    "    dense_net_kernel_size = 3                       #do not change\n",
    "    dense_net_channels = 100\n",
    "    dense_net_first_scale_down_ratio = 0.3\n",
    "    first_scale_down_kernel = 1                    # [1-5]\n",
    "    batch_size = 32\n",
    "    dropout = [0.3,0.3,0.3,0.3,0.3]\n",
    "\n",
    "    def __init__(self, num_sent, encoder, **kwargs):\n",
    "        self.encoder = encoder\n",
    "        self.num_sent = num_sent\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "class Highway(nn.Module):\n",
    "    def __init__(self, size, num_layers, dropout):\n",
    "\n",
    "        super(Highway, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.nonlinear = nn.ModuleList(\n",
    "            [nn.Linear(size, size) for _ in range(num_layers)]\n",
    "        )\n",
    "\n",
    "        self.linear = nn.ModuleList([nn.Linear(size, size) for _ in range(num_layers)])\n",
    "\n",
    "        self.gate = nn.ModuleList([nn.Linear(size, size) for _ in range(num_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.f = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: tensor with shape of [batch_size, size]\n",
    "        :return: tensor with shape of [batch_size, size]\n",
    "        applies σ(x) ⨀ (f(G(x))) + (1 - σ(x)) ⨀ (Q(x)) transformation | G and Q is affine transformation,\n",
    "        f is non-linear transformation, σ(x) is affine transformation with sigmoid non-linearition\n",
    "        and ⨀ is element-wise multiplication\n",
    "        \"\"\"\n",
    "\n",
    "        for layer in range(self.num_layers):\n",
    "            gate = torch.sigmoid(self.gate[layer](x))\n",
    "\n",
    "            nonlinear = self.f(self.nonlinear[layer](x))\n",
    "            linear = self.linear[layer](x)\n",
    "            linear = self.dropout(linear)\n",
    "            x = gate * nonlinear + (1 - gate) * linear\n",
    "        return x\n",
    "\n",
    "\n",
    "class self_attention(nn.Module):\n",
    "    \"\"\"[summary]\n",
    "    Self attention modeled as demonstrated in NATURAL LANGUAGE INFERENCE OVER INTERACTION SPACE paper\n",
    "\n",
    "    REF: https://github.com/YerevaNN/DIIN-in-Keras/blob/master/layers/encoding.py\n",
    "\n",
    "    # P = P_hw\n",
    "    # itr_attn = P_itrAtt\n",
    "    # encoding = P_enc\n",
    "    # The paper takes inputs to be P(_hw) as an example and then computes the same thing for H,\n",
    "    # therefore we'll name our inputs P too.\n",
    "\n",
    "    # Input of encoding is P with shape (batch, p, d). It would be (batch, h, d) for hypothesis\n",
    "    # Construct alphaP of shape (batch, p, 3*d, p)\n",
    "    # A = dot(w_itr_att, alphaP)\n",
    "\n",
    "    # alphaP consists of 3*d rows along 2nd axis\n",
    "    # 1. up   -> first  d items represent P[i]\n",
    "    # 2. mid  -> second d items represent P[j]\n",
    "    # 3. down -> final items represent alpha(P[i], P[j]) which is element-wise product of P[i] and P[j] = P[i]*P[j]\n",
    "\n",
    "    # If we look at one slice of alphaP we'll see that it has the following elements:\n",
    "    # ----------------------------------------\n",
    "    # P[i][0], P[i][0], P[i][0], ... P[i][0]   ▲\n",
    "    # P[i][1], P[i][1], P[i][1], ... P[i][1]   |\n",
    "    # P[i][2], P[i][2], P[i][2], ... P[i][2]   |\n",
    "    # ...                              ...     | up\n",
    "    #      ...                         ...     |\n",
    "    #             ...                  ...     |\n",
    "    # P[i][d], P[i][d], P[i][d], ... P[i][d]   ▼\n",
    "    # ----------------------------------------\n",
    "    # P[0][0], P[1][0], P[2][0], ... P[p][0]   ▲\n",
    "    # P[0][1], P[1][1], P[2][1], ... P[p][1]   |\n",
    "    # P[0][2], P[1][2], P[2][2], ... P[p][2]   |\n",
    "    # ...                              ...     | mid\n",
    "    #      ...                         ...     |\n",
    "    #             ...                  ...     |\n",
    "    # P[0][d], P[1][d], P[2][d], ... P[p][d]   ▼\n",
    "    # ----------------------------------------\n",
    "    #                                          ▲\n",
    "    #                                          |\n",
    "    #                                          |\n",
    "    #               up * mid                   | down\n",
    "    #          element-wise product            |\n",
    "    #                                          |\n",
    "    #                                          ▼\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # For every slice(i) the up part changes its P[i] values\n",
    "    # The middle part is repeated p times in depth (for every i)\n",
    "    # So we can get the middle part by doing the following:\n",
    "    # mid = broadcast(P) -> to get tensor of shape (batch, p, d, p)\n",
    "    # As we can notice up is the same mid, but with changed axis, so to obtain up from mid we can do:\n",
    "    # up = swap_axes(mid, axis1=0, axis2=2)\n",
    "\n",
    "    # P_itr_attn[i] = sum of for j = 1...p:\n",
    "    #                           s = sum(for k = 1...p:  e^A[k][j]\n",
    "    #                           ( e^A[i][j] / s ) * P[j]  --> P[j] is the j-th row, while the first part is a number\n",
    "    # So P_itr_attn is the weighted sum of P\n",
    "    # SA is column-wise soft-max applied on A\n",
    "    # P_itr_attn[i] is the sum of all rows of P scaled by i-th row of SA\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, conf):\n",
    "        super().__init__()\n",
    "        self.w = nn.Linear(3 * conf.hidden_size, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(conf.dropout[2])\n",
    "\n",
    "    def forward(self, p):\n",
    "        # p = [B,P,D]\n",
    "        p_dim = p.shape[1]\n",
    "        mid = p.unsqueeze(3).expand(-1, -1, -1, p_dim)\n",
    "        # min = [B,P,D,P]\n",
    "        up = mid.permute(0, 3, 2, 1)\n",
    "        alpha = torch.cat([up, mid, up * mid], dim=2)\n",
    "        A = (self.w.weight @ alpha).squeeze(2)\n",
    "        A = self.dropout(A)\n",
    "        sA = A.softmax(dim=2)\n",
    "        itr_attn = torch.bmm(sA, p)\n",
    "        return itr_attn\n",
    "\n",
    "\n",
    "class fuse_gate(nn.Module):\n",
    "    \"\"\"[summary]\n",
    "    Fuse gate is used to provide a Skip connection for the encoding and the attended output.\n",
    "    The author uses:\n",
    "    zi = tanh(W1 * [P:P_att]+b1)\n",
    "    ri = Sigmoid(W2 * [P:P_att]+b2)\n",
    "    fi = Sigmoid(W3 * [P:P_att]+b3)\n",
    "    P_new  = r dot P + fi dot zi\n",
    "\n",
    "    W1,W2,W3 = Linear(2d,d)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, conf):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(conf.hidden_size * 2, conf.hidden_size)\n",
    "        self.fc2 = nn.Linear(conf.hidden_size * 2, conf.hidden_size)\n",
    "        self.fc3 = nn.Linear(conf.hidden_size * 2, conf.hidden_size)\n",
    "        self.dropout = nn.Dropout(conf.dropout[3])\n",
    "\n",
    "    def forward(self, p_hat_i, p_dash_i):\n",
    "        x = torch.cat([p_hat_i, p_dash_i], dim=2)\n",
    "        z = torch.tanh(self.dropout(self.fc1(x)))\n",
    "        r = torch.sigmoid(self.dropout(self.fc1(x)))\n",
    "        f = torch.sigmoid(self.dropout(self.fc1(x)))\n",
    "        enc = r * p_hat_i + f * z\n",
    "        return enc\n",
    "\n",
    "\n",
    "class interaction(nn.Module):\n",
    "    def __init__(self, conf):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, p, h):\n",
    "        p = p.unsqueeze(2)\n",
    "        h = h.unsqueeze(1)\n",
    "        return p * h\n",
    "\n",
    "\n",
    "class Dense_net_block(nn.Module):\n",
    "    def __init__(self, outChannels, growth_rate, kernel_size):\n",
    "        super(Dense_net_block, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            outChannels, growth_rate, kernel_size=kernel_size, bias=False, padding=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ft = F.relu(self.conv(x))\n",
    "        out = torch.cat((x, ft), dim=1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Dense_net_transition(nn.Module):\n",
    "    def __init__(self, nChannels, outChannels):\n",
    "        super(Dense_net_transition, self).__init__()\n",
    "        self.conv = nn.Conv2d(nChannels, outChannels, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = F.max_pool2d(out, (2, 2), (2, 2), padding=0)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, nChannels, growthRate, reduction, nDenseBlocks, kernel_size):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.dense1 = self._make_dense(nChannels, growthRate, nDenseBlocks, kernel_size)\n",
    "        nChannels += nDenseBlocks * growthRate\n",
    "        nOutChannels = int(math.floor(nChannels * reduction))\n",
    "        self.trans1 = Dense_net_transition(nChannels, nOutChannels)\n",
    "        nChannels = nOutChannels\n",
    "\n",
    "        self.dense2 = self._make_dense(nChannels, growthRate, nDenseBlocks, kernel_size)\n",
    "        nChannels += nDenseBlocks * growthRate\n",
    "        nOutChannels = int(math.floor(nChannels * reduction))\n",
    "        self.trans2 = Dense_net_transition(nChannels, nOutChannels)\n",
    "        nChannels = nOutChannels\n",
    "\n",
    "        self.dense3 = self._make_dense(nChannels, growthRate, nDenseBlocks, kernel_size)\n",
    "        nChannels += nDenseBlocks * growthRate\n",
    "        nOutChannels = int(math.floor(nChannels * reduction))\n",
    "        self.trans3 = Dense_net_transition(nChannels, nOutChannels)\n",
    "\n",
    "    def _make_dense(self, nChannels, growthRate, nDenseBlocks, kernel_size):\n",
    "        layers = []\n",
    "        for i in range(int(nDenseBlocks)):\n",
    "            layers.append(Dense_net_block(nChannels, growthRate, kernel_size))\n",
    "            nChannels += growthRate\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        out = self.trans1(self.dense1(x))\n",
    "        # print(out.shape)\n",
    "        out = self.trans2(self.dense2(out))\n",
    "        # print(out.shape)\n",
    "        out = self.trans3(self.dense3(out))\n",
    "        # print(out.shape)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DIIN(nn.Module):\n",
    "    def __init__(self, conf):\n",
    "        super().__init__()\n",
    "        self.conf = conf\n",
    "        self.encoder = self.conf.encoder\n",
    "        self.encoder.requires_grad = conf.freeze_encoder\n",
    "        self.num_sent = conf.num_sent\n",
    "\n",
    "        self.template = nn.Parameter(torch.zeros((1)), requires_grad=True)\n",
    "        self.dropout = nn.Dropout(conf.dropout[4])\n",
    "\n",
    "        self.translate = nn.Linear(conf.embedding_dim, self.conf.hidden_size)\n",
    "        self.highway = Highway(self.conf.hidden_size, conf.num_layers,conf.dropout[1])\n",
    "        self.attn = self_attention(self.conf)\n",
    "        self.fuse = fuse_gate(self.conf)\n",
    "        self.interact = interaction(self.conf)\n",
    "        self.interaction_cnn = nn.Conv2d(\n",
    "            self.conf.hidden_size,\n",
    "            int(self.conf.hidden_size * self.conf.dense_net_first_scale_down_ratio),\n",
    "            self.conf.first_scale_down_kernel,\n",
    "            padding=0,\n",
    "        )\n",
    "        nChannels = int(self.conf.hidden_size * self.conf.dense_net_first_scale_down_ratio)\n",
    "        features = self.num_sent\n",
    "        for i in range(3):\n",
    "            nChannels += self.conf.dense_net_layers * self.conf.dense_net_growth_rate\n",
    "            nOutChannels = int(math.floor(nChannels * self.conf.dense_net_transition_rate))\n",
    "            nChannels = nOutChannels\n",
    "            features = features//2\n",
    "        final_layer_size = ((features**2)*nChannels)\n",
    "\n",
    "        self.dense_net = DenseNet(\n",
    "            int(self.conf.hidden_size * self.conf.dense_net_first_scale_down_ratio),\n",
    "            self.conf.dense_net_growth_rate,\n",
    "            self.conf.dense_net_transition_rate,\n",
    "            self.conf.dense_net_layers,\n",
    "            self.conf.dense_net_kernel_size,\n",
    "        )\n",
    "        self.fc1 = nn.Linear(final_layer_size, 2)\n",
    "\n",
    "        \n",
    "\n",
    "    def encode(self, src):\n",
    "        batch_size = src.shape[0]\n",
    "        x = src.view(-1, self.num_sent)\n",
    "        x_padded_idx = x.sum(dim=1) != 0\n",
    "        x_enc = []\n",
    "        for sub_batch in x[x_padded_idx].split(64):\n",
    "            x_enc.append(self.encoder(sub_batch)[0])\n",
    "        x_enc = torch.cat(x_enc, dim=0)\n",
    "        x_enc_t = torch.zeros((batch_size * self.num_sent, x_enc.size(1))).to(\n",
    "            self.template.device\n",
    "        )\n",
    "        x_enc_t[x_padded_idx] = x_enc\n",
    "        x_enc_t = x_enc_t.view(batch_size, self.num_sent, -1)\n",
    "        return x_enc_t\n",
    "\n",
    "    def encode_attn(self, x):\n",
    "        print(\"START\")\n",
    "        print(x.shape)\n",
    "        x = self.encode(x)\n",
    "        print(x.shape)\n",
    "        x = self.translate(x)\n",
    "        print(x.shape)\n",
    "        x = self.highway(x)\n",
    "        print(x.shape)\n",
    "        x_att = self.attn(x)\n",
    "        print(x_att.shape)\n",
    "        enc = self.fuse(x, x_att)\n",
    "        print(enc.shape)\n",
    "        print(\"END\")\n",
    "        return enc\n",
    "\n",
    "    def forward(self, p_tok, h_tok):\n",
    "        batch_size = p_tok.shape[0]\n",
    "        p_enc = self.encode_attn(p_tok)\n",
    "        # print(p_enc.shape)\n",
    "        h_enc = self.encode_attn(h_tok)\n",
    "        intr = self.interact(p_enc, h_enc).permute(0, 3, 1, 2)\n",
    "        # print(intr.shape)\n",
    "        fm = self.interaction_cnn(intr)\n",
    "        # print(fm.shape)\n",
    "        dense = self.dense_net(fm)\n",
    "        # print(dense.shape)\n",
    "        opt = self.fc1(dense.reshape(batch_size, -1))\n",
    "        # print(opt.shape)\n",
    "        return opt\n",
    "\n",
    "from utils import load_bilstm_encoder, load_attn_encoder\n",
    "\n",
    "\n",
    "encoder, Lang = load_attn_encoder()\n",
    "\n",
    "conf = DIIN_conf(100,encoder)\n",
    "nov_model = DIIN(conf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from novelty.train_utils import *\n",
    "from datamodule import *\n",
    "data_module = webis_data_module(Lang)\n",
    "data_module.batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([16, 100, 100]) torch.Size([16, 100, 100]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for i in data_module.val_dataloader():\n",
    "    x0,x1,y = i\n",
    "    print(x0.shape,x1.shape,y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "START\n",
      "torch.Size([16, 100, 100])\n",
      "torch.Size([16, 100, 800])\n",
      "torch.Size([16, 100, 300])\n",
      "torch.Size([16, 100, 300])\n",
      "torch.Size([16, 100, 300])\n",
      "torch.Size([16, 100, 300])\n",
      "END\n",
      "START\n",
      "torch.Size([16, 100, 100])\n",
      "torch.Size([16, 100, 800])\n",
      "torch.Size([16, 100, 300])\n",
      "torch.Size([16, 100, 300])\n",
      "torch.Size([16, 100, 300])\n",
      "torch.Size([16, 100, 300])\n",
      "END\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.0112,  0.0047],\n",
       "        [-0.0112,  0.0047],\n",
       "        [-0.0112,  0.0047],\n",
       "        [-0.0112,  0.0047],\n",
       "        [-0.0112,  0.0047],\n",
       "        [-0.0112,  0.0047],\n",
       "        [-0.0112,  0.0047],\n",
       "        [-0.0112,  0.0047],\n",
       "        [-0.0112,  0.0047],\n",
       "        [-0.0112,  0.0047],\n",
       "        [-0.0112,  0.0047],\n",
       "        [-0.0112,  0.0047],\n",
       "        [-0.0112,  0.0047],\n",
       "        [-0.0112,  0.0047],\n",
       "        [-0.0111,  0.0047],\n",
       "        [-0.0112,  0.0047]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "nov_model(x0,x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}