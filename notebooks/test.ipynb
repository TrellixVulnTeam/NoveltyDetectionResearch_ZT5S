{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.9 64-bit",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snli.bert.bert import *\n",
    "from snli.train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "encoder = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "data_module = snli_bert_data_module(32,combine=True,tokenizer = tokenizer)\n",
    "Lang = data_module.Lang\n",
    "embedding_matrix = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from transformers import BertModel,DistilBertModel\n",
    "\n",
    "\n",
    "class Bert_Encoder_conf:\n",
    "    encoder_dim = 768\n",
    "    encoder = None\n",
    "    batch_size = None\n",
    "    def __init__(self, **kwargs):\n",
    "        for k,v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "class Bert_Encoder(nn.Module):\n",
    "    def __init__(self,conf):\n",
    "        super(Bert_Encoder,self).__init__()\n",
    "        self.conf=conf\n",
    "        self.bert = conf.encoder\n",
    "        self.fc = nn.Linear(conf.encoder_dim,3)\n",
    "\n",
    "    def forward(self,x0):\n",
    "        enc = self.bert.forward(x0)[0][:, 0, :]\n",
    "        opt = self.fc(enc)\n",
    "        opt = opt.unsqueeze(0)\n",
    "        return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Bert_Encoder(\n  (bert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (1): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (2): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (3): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (4): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (5): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (fc): Linear(in_features=768, out_features=3, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# model_conf = Bert_Encoder_conf()\n",
    "model_conf = Bert_Encoder_conf(**{\"encoder\":encoder})\n",
    "model = Bert_Encoder(model_conf)\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[-1.5606e-01,  3.3819e-01, -5.2539e-02],\n         [-1.5597e-01,  3.1152e-01, -8.4443e-02],\n         [-1.6710e-01,  2.8999e-01, -9.2950e-02],\n         [-1.3891e-01,  2.8695e-01,  2.7773e-02],\n         [-1.5344e-01,  2.7768e-01,  3.5789e-02],\n         [-1.5021e-01,  2.6954e-01,  3.5361e-02],\n         [-8.6597e-02,  2.8779e-01, -3.1927e-03],\n         [-1.0897e-01,  3.0146e-01,  2.2138e-02],\n         [-1.0828e-01,  2.7488e-01, -6.9044e-03],\n         [-1.1929e-01,  2.9659e-01, -7.0752e-02],\n         [-1.0563e-01,  2.8370e-01, -6.9148e-02],\n         [-1.0763e-01,  2.8029e-01, -7.3718e-02],\n         [-1.3063e-01,  2.9325e-01, -4.3215e-02],\n         [-1.4046e-01,  3.0330e-01, -3.2987e-02],\n         [-1.3897e-01,  3.0665e-01, -3.6979e-02],\n         [-1.7560e-01,  2.7722e-01,  6.6635e-02],\n         [-1.5968e-01,  2.7369e-01,  6.9692e-02],\n         [-1.4553e-01,  2.6856e-01,  3.4076e-02],\n         [-1.1465e-01,  2.5734e-01, -1.0196e-02],\n         [-1.1534e-01,  2.6951e-01, -2.9981e-02],\n         [-9.2200e-02,  2.5022e-01, -2.5434e-03],\n         [-1.5132e-01,  3.6697e-01, -5.2364e-02],\n         [-1.5318e-01,  3.5760e-01, -6.9230e-02],\n         [-1.3919e-01,  3.3657e-01, -4.7827e-02],\n         [-9.0840e-02,  3.3621e-01, -7.9189e-03],\n         [-9.5716e-02,  3.3987e-01, -1.5893e-02],\n         [-7.9798e-02,  3.3259e-01, -1.5290e-02],\n         [-6.3982e-02,  2.4984e-01, -7.2008e-02],\n         [-1.6295e-01,  2.7147e-01, -5.0387e-02],\n         [-1.3896e-01,  2.6764e-01, -4.1531e-02],\n         [-1.6174e-01,  3.1179e-01, -4.7052e-02],\n         [-1.5549e-01,  3.0029e-01, -3.5086e-02],\n         [-1.5813e-01,  3.1903e-01, -2.6941e-02],\n         [-1.2270e-01,  3.4612e-01, -4.3878e-02],\n         [-1.2962e-01,  3.3280e-01, -6.0376e-02],\n         [-1.1789e-01,  3.4818e-01, -3.0810e-02],\n         [-1.1244e-01,  2.7724e-01, -5.9420e-02],\n         [-1.0923e-01,  2.7134e-01, -6.4716e-02],\n         [-1.0146e-01,  2.9812e-01, -5.8324e-02],\n         [-1.2928e-01,  3.3538e-01, -3.3748e-03],\n         [-1.0885e-01,  3.2951e-01, -2.4169e-02],\n         [-1.2463e-01,  3.2430e-01, -1.5964e-02],\n         [-1.4782e-01,  3.1316e-01, -1.1143e-02],\n         [-1.4983e-01,  2.9940e-01, -4.7587e-03],\n         [-1.4672e-01,  2.9187e-01,  1.3719e-03],\n         [-1.0686e-01,  2.6832e-01,  1.8423e-02],\n         [-1.1358e-01,  2.6024e-01,  9.8236e-04],\n         [-1.0772e-01,  2.5355e-01,  4.7903e-02],\n         [-1.0682e-01,  2.5793e-01, -5.8198e-02],\n         [-9.7995e-02,  2.4613e-01, -6.1471e-02],\n         [-1.0156e-01,  2.5665e-01, -4.9227e-02],\n         [-1.2912e-01,  2.7195e-01, -2.4982e-02],\n         [-1.1181e-01,  3.0688e-01, -4.0298e-02],\n         [-1.3227e-01,  2.8743e-01, -4.7015e-02],\n         [-1.1594e-01,  2.7561e-01, -2.4815e-02],\n         [-1.2985e-01,  2.6862e-01, -2.1750e-02],\n         [-1.3197e-01,  2.8047e-01, -3.6198e-02],\n         [-1.5581e-01,  2.4267e-01,  4.4762e-03],\n         [-1.6559e-01,  2.4466e-01, -5.6323e-03],\n         [-1.6422e-01,  2.4176e-01,  8.1284e-04],\n         [-9.0246e-02,  3.3111e-01, -3.9459e-02],\n         [-1.0189e-01,  3.2424e-01, -1.2285e-02],\n         [-1.3114e-01,  3.2658e-01, -3.7481e-02],\n         [-1.0091e-01,  2.9311e-01, -1.0889e-02],\n         [-1.0952e-01,  2.8128e-01, -1.2923e-02],\n         [-1.0877e-01,  2.7605e-01, -7.5778e-03],\n         [-1.5407e-01,  3.0073e-01, -2.2618e-02],\n         [-1.4295e-01,  3.2065e-01, -7.6316e-03],\n         [-1.0008e-01,  3.1893e-01, -1.2137e-02],\n         [-8.8012e-02,  2.9923e-01, -2.3226e-02],\n         [-9.6855e-02,  2.9340e-01, -1.1705e-02],\n         [-1.4499e-01,  3.1279e-01, -6.5454e-02],\n         [-1.3538e-01,  3.1563e-01, -4.6383e-02],\n         [-1.3787e-01,  3.2442e-01, -3.7651e-02],\n         [-1.2382e-01,  3.0571e-01,  1.8868e-03],\n         [-1.2358e-01,  3.0286e-01,  7.6981e-03],\n         [-1.2861e-01,  3.2172e-01,  3.1905e-02],\n         [-1.3544e-01,  3.5873e-01, -1.7083e-03],\n         [-1.4322e-01,  3.4536e-01, -2.0194e-03],\n         [-1.3806e-01,  3.1748e-01, -1.1000e-02],\n         [-1.0821e-01,  2.5887e-01, -4.2780e-03],\n         [-1.2179e-01,  2.5106e-01,  4.5231e-03],\n         [-1.3909e-01,  2.7904e-01, -2.3612e-02],\n         [-1.0475e-01,  3.1328e-01, -2.4821e-02],\n         [-1.2529e-01,  3.3667e-01, -2.2200e-02],\n         [-1.3071e-01,  3.3194e-01, -2.4292e-02],\n         [-1.9872e-01,  3.1006e-01, -6.5083e-02],\n         [-2.0765e-01,  2.9235e-01, -7.1779e-02],\n         [-1.7052e-01,  3.2428e-01, -5.6908e-02],\n         [-1.2667e-01,  2.7347e-01, -1.4350e-02],\n         [-1.2173e-01,  2.7815e-01, -4.3972e-03],\n         [-1.2875e-01,  2.7809e-01, -2.7893e-02],\n         [-1.7911e-01,  2.9365e-01, -9.3178e-03],\n         [-1.9528e-01,  2.8123e-01,  5.5539e-03],\n         [-1.8104e-01,  2.6871e-01, -5.0595e-03],\n         [-8.8645e-02,  2.5800e-01, -2.3498e-02],\n         [-8.2125e-02,  2.6448e-01, -4.1149e-02],\n         [-9.5663e-02,  2.9148e-01, -5.9951e-02],\n         [-6.8397e-02,  2.8157e-01, -2.2696e-02],\n         [-5.9777e-02,  2.7407e-01, -2.6059e-02],\n         [-7.8120e-02,  2.8788e-01, -1.5680e-02],\n         [-6.9452e-02,  2.7315e-01, -3.1047e-02],\n         [-3.6474e-02,  2.5944e-01, -2.3209e-02],\n         [-6.9884e-02,  2.6545e-01, -4.6556e-02],\n         [-1.5567e-01,  3.1131e-01,  1.6815e-02],\n         [-1.5041e-01,  3.1703e-01,  2.8747e-02],\n         [-1.7917e-01,  3.1825e-01,  1.2043e-02],\n         [-1.6510e-01,  3.3612e-01, -1.6679e-02],\n         [-1.3844e-01,  3.0057e-01,  8.4841e-03],\n         [-1.5075e-01,  3.1271e-01, -2.0342e-02],\n         [-1.6423e-01,  3.3568e-01, -2.4548e-02],\n         [-1.6099e-01,  3.5054e-01, -1.0667e-04],\n         [-1.6053e-01,  3.3611e-01, -1.9497e-02],\n         [-1.2560e-01,  3.3077e-01, -9.8010e-03],\n         [-1.7529e-01,  3.2028e-01, -2.5795e-03],\n         [-1.7306e-01,  3.1628e-01,  9.6049e-03],\n         [-1.5762e-01,  3.1355e-01, -6.1837e-02],\n         [-1.4290e-01,  2.9116e-01, -6.6057e-02],\n         [-1.1447e-01,  2.8692e-01, -4.5509e-02],\n         [-1.1962e-01,  3.1436e-01, -3.1167e-02],\n         [-1.2908e-01,  3.1226e-01, -2.6081e-02],\n         [-1.3253e-01,  3.0343e-01, -1.9134e-02],\n         [-1.2165e-01,  2.8203e-01, -2.6372e-02],\n         [-1.2965e-01,  2.9076e-01, -3.8627e-02],\n         [-1.3180e-01,  3.0650e-01, -3.3139e-02],\n         [-9.9036e-02,  2.3396e-01,  6.8689e-03],\n         [-1.1771e-01,  2.3851e-01,  6.1969e-04],\n         [-8.9423e-02,  2.4631e-01,  7.0955e-03],\n         [-1.7052e-01,  2.9572e-01, -5.3897e-03],\n         [-1.6576e-01,  2.9290e-01,  1.0775e-02],\n         [-1.5308e-01,  2.9571e-01, -5.9994e-03],\n         [-1.5364e-01,  2.9370e-01, -7.1598e-02],\n         [-1.5825e-01,  3.0448e-01, -5.9769e-02],\n         [-1.4501e-01,  3.0112e-01, -7.7124e-02],\n         [-1.0881e-01,  2.8438e-01,  6.7542e-03],\n         [-1.2677e-01,  2.9544e-01,  2.9999e-02],\n         [-1.1845e-01,  2.9761e-01,  3.9018e-03],\n         [-1.3892e-01,  3.2928e-01,  6.2556e-02],\n         [-1.6511e-01,  3.1144e-01,  5.4559e-02],\n         [-1.3901e-01,  3.2293e-01,  5.3927e-02],\n         [-1.3985e-01,  2.9177e-01, -9.0142e-03],\n         [-1.1975e-01,  3.0381e-01, -2.0774e-03],\n         [-9.6499e-02,  3.0673e-01, -3.6474e-02],\n         [-1.5502e-01,  2.9249e-01,  9.5143e-02],\n         [-1.5433e-01,  2.3587e-01,  4.8656e-02],\n         [-1.5035e-01,  2.7491e-01,  3.5894e-02],\n         [-1.2652e-01,  3.2613e-01, -3.1968e-02],\n         [-1.3223e-01,  2.9709e-01, -4.6008e-02],\n         [-1.2781e-01,  3.0174e-01, -5.2750e-02],\n         [-1.2636e-01,  3.0254e-01,  1.3611e-02],\n         [-1.5248e-01,  2.9065e-01, -4.0622e-03],\n         [-1.6225e-01,  2.8834e-01,  4.6870e-03],\n         [-1.5022e-01,  2.7386e-01, -1.3985e-02],\n         [-1.5301e-01,  2.8136e-01, -1.9130e-02],\n         [-1.6702e-01,  2.7436e-01, -1.0855e-02],\n         [-1.2980e-01,  3.0999e-01, -4.9501e-02],\n         [-1.3671e-01,  3.2081e-01, -7.4902e-03],\n         [-1.2265e-01,  3.1559e-01, -2.6770e-02],\n         [-1.9019e-01,  3.3267e-01, -4.6548e-02],\n         [-1.8491e-01,  3.1690e-01, -5.3193e-02],\n         [-1.8978e-01,  3.3571e-01, -4.1843e-02],\n         [-1.3356e-01,  3.0438e-01, -6.0018e-02],\n         [-1.5872e-01,  3.0873e-01, -4.1192e-02],\n         [-1.3328e-01,  3.0819e-01, -3.6155e-02],\n         [-1.2466e-01,  2.8929e-01, -1.5135e-02],\n         [-1.4646e-01,  2.8265e-01, -1.4621e-02],\n         [-1.2234e-01,  2.7330e-01,  2.8077e-03],\n         [-1.0307e-01,  2.8862e-01,  3.6637e-03],\n         [-1.3461e-01,  2.9508e-01, -1.3506e-02],\n         [-1.4622e-01,  3.0930e-01,  3.7491e-03],\n         [-1.3243e-01,  2.6364e-01,  2.2056e-03],\n         [-1.1220e-01,  2.6828e-01, -1.9006e-02],\n         [-1.1602e-01,  2.6691e-01,  1.7583e-02],\n         [-1.5865e-01,  3.1806e-01, -5.6154e-02],\n         [-1.2811e-01,  3.1055e-01, -6.9466e-02],\n         [-1.7327e-01,  3.0660e-01, -7.0786e-02],\n         [-1.4121e-01,  3.0994e-01, -3.7504e-02],\n         [-1.4137e-01,  3.1497e-01, -3.5151e-02],\n         [-1.4083e-01,  3.0471e-01, -4.2507e-02],\n         [-9.8337e-02,  2.7638e-01, -1.9295e-02],\n         [-1.4587e-01,  3.4185e-01, -4.0009e-02],\n         [-1.2272e-01,  3.1080e-01, -1.2852e-02],\n         [-1.5938e-01,  2.4390e-01, -2.6909e-02],\n         [-1.7439e-01,  2.5014e-01, -2.3168e-02],\n         [-1.5369e-01,  2.4749e-01, -3.4851e-02],\n         [-1.2997e-01,  3.6842e-01, -5.6987e-02],\n         [-1.0640e-01,  3.9310e-01, -7.4560e-02],\n         [-1.2557e-01,  3.8903e-01, -7.8594e-02],\n         [-1.3234e-01,  2.5865e-01, -5.2261e-02],\n         [-1.5647e-01,  2.6903e-01, -5.2055e-02],\n         [-1.4313e-01,  2.7456e-01, -4.5862e-02],\n         [-1.5767e-01,  3.2100e-01, -6.2484e-02],\n         [-1.6230e-01,  3.2860e-01, -6.8360e-02],\n         [-1.5423e-01,  3.5785e-01, -5.6238e-02],\n         [-9.2298e-02,  2.8524e-01, -3.7583e-02],\n         [-1.0687e-01,  3.0377e-01, -5.6110e-03],\n         [-9.9550e-02,  2.8761e-01,  5.2369e-04],\n         [-1.3268e-01,  3.0580e-01, -1.6375e-02],\n         [-1.2425e-01,  3.1222e-01, -1.4079e-02],\n         [-1.1675e-01,  3.1465e-01, -2.5701e-03],\n         [-2.0667e-01,  4.4598e-01,  1.1202e-01],\n         [-2.0579e-01,  4.3475e-01,  1.2183e-01],\n         [-1.5988e-01,  3.3357e-01, -4.1578e-02],\n         [-1.6277e-01,  3.4702e-01, -3.9006e-02],\n         [-1.4085e-01,  3.4941e-01, -9.5937e-03],\n         [-1.1219e-01,  2.7780e-01,  6.9267e-02],\n         [-1.2129e-01,  2.8688e-01,  1.0210e-01],\n         [-1.0175e-01,  2.8834e-01,  5.0502e-02],\n         [-1.5197e-01,  3.3395e-01, -1.6028e-03],\n         [-1.3399e-01,  3.2097e-01, -2.4452e-02],\n         [-1.3807e-01,  3.1081e-01, -2.7929e-02],\n         [-1.3369e-01,  3.0112e-01, -2.1448e-02],\n         [-1.2038e-01,  2.8155e-01, -3.9438e-02],\n         [-1.2298e-01,  3.0626e-01, -3.3207e-02],\n         [-1.2014e-01,  2.3511e-01, -2.0720e-02],\n         [-1.2344e-01,  2.4596e-01, -3.3770e-02],\n         [-1.3443e-01,  2.5323e-01, -3.0339e-02],\n         [-1.8577e-01,  3.3639e-01,  2.5067e-03],\n         [-1.4552e-01,  2.9528e-01, -2.6923e-02],\n         [-1.5196e-01,  2.6704e-01,  7.6934e-03],\n         [-1.2790e-01,  2.6280e-01,  1.7461e-02],\n         [-1.3596e-01,  2.5807e-01,  1.9162e-02],\n         [-1.6585e-01,  3.1550e-01,  1.4835e-02],\n         [-1.2710e-01,  2.8530e-01, -4.5469e-03],\n         [-1.4937e-01,  3.0847e-01,  1.1756e-02],\n         [-9.8432e-02,  2.9514e-01, -2.1647e-02],\n         [-1.2079e-01,  2.9496e-01,  7.0146e-03],\n         [-1.2279e-01,  2.9877e-01,  3.1370e-03],\n         [-1.9643e-01,  3.2320e-01,  2.0032e-02],\n         [-1.9906e-01,  3.2262e-01,  1.4517e-02],\n         [-2.0928e-01,  3.2728e-01,  3.4836e-02],\n         [-8.8473e-02,  2.6873e-01, -4.8994e-02],\n         [-9.1387e-02,  2.6099e-01, -4.6275e-02],\n         [-9.8826e-02,  2.7569e-01, -5.5310e-02],\n         [-1.2394e-01,  2.9701e-01, -2.7694e-03],\n         [-1.2048e-01,  2.8507e-01,  1.3643e-02],\n         [-1.1495e-01,  2.9936e-01, -1.4172e-03],\n         [-1.6308e-01,  3.4377e-01,  2.0204e-02],\n         [-1.6718e-01,  3.3092e-01,  4.8260e-02],\n         [-1.4482e-01,  3.2596e-01,  4.0534e-03],\n         [-1.2351e-01,  2.7601e-01,  9.3656e-03],\n         [-1.2010e-01,  2.7911e-01,  2.0354e-03],\n         [-1.1967e-01,  2.4642e-01,  2.0616e-02],\n         [-1.5095e-01,  3.0335e-01, -1.1447e-02],\n         [-1.6419e-01,  2.9726e-01, -2.1492e-02],\n         [-1.6133e-01,  3.0109e-01, -3.1381e-02],\n         [-1.3771e-01,  2.7908e-01,  6.5072e-02],\n         [-1.5741e-01,  2.8799e-01,  3.9601e-02],\n         [-1.5378e-01,  2.7572e-01,  5.0735e-02],\n         [-1.2393e-01,  2.8639e-01,  1.1572e-02],\n         [-1.6480e-01,  2.7424e-01, -5.4305e-03],\n         [-1.2857e-01,  2.8012e-01, -1.7669e-04],\n         [-1.4976e-01,  3.2810e-01,  8.3569e-03],\n         [-1.6924e-01,  3.4028e-01, -8.3963e-03],\n         [-1.5304e-01,  3.7954e-01, -1.4926e-02],\n         [-1.4216e-01,  3.0758e-01,  4.8654e-03]]], device=&#39;cuda:0&#39;,\n       grad_fn=&lt;UnsqueezeBackward0&gt;)\n"
    }
   ],
   "source": [
    "\n",
    "data_module.batch_size = 256\n",
    "for batch in data_module.val_dataloader():\n",
    "    inp = batch[0]\n",
    "    print(model(inp.cuda()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([256, 512])"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "encoder.forward(inp.cuda())[0][:, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel,DistilBertModel\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from snli.bilstm.bilstm import *\n",
    "from snli.attn_enc.attn_enc import *\n",
    "from lang import *\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bert_encoder():\n",
    "    BERT_ENC_PATH = f\"./models/bert_encoder/\"\n",
    "    with open(BERT_ENC_PATH + \"model_conf.pkl\", \"rb\") as f:\n",
    "        model_conf = pickle.load(f)\n",
    "    with open(BERT_ENC_PATH + \"lang.pkl\", \"rb\") as f:\n",
    "        Lang = joblib.load(f)\n",
    "    encoder = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "    encoder.load_state_dict(torch.load(BERT_ENC_PATH + \"weights.pt\"))\n",
    "    return encoder, Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(DistilBertModel(\n",
       "   (embeddings): Embeddings(\n",
       "     (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "     (position_embeddings): Embedding(512, 768)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (transformer): Transformer(\n",
       "     (layer): ModuleList(\n",
       "       (0): TransformerBlock(\n",
       "         (attention): MultiHeadSelfAttention(\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "           (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "         )\n",
       "         (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (ffn): FFN(\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "           (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         )\n",
       "         (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       )\n",
       "       (1): TransformerBlock(\n",
       "         (attention): MultiHeadSelfAttention(\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "           (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "         )\n",
       "         (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (ffn): FFN(\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "           (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         )\n",
       "         (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       )\n",
       "       (2): TransformerBlock(\n",
       "         (attention): MultiHeadSelfAttention(\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "           (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "         )\n",
       "         (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (ffn): FFN(\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "           (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         )\n",
       "         (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       )\n",
       "       (3): TransformerBlock(\n",
       "         (attention): MultiHeadSelfAttention(\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "           (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "         )\n",
       "         (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (ffn): FFN(\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "           (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         )\n",
       "         (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       )\n",
       "       (4): TransformerBlock(\n",
       "         (attention): MultiHeadSelfAttention(\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "           (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "         )\n",
       "         (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (ffn): FFN(\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "           (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         )\n",
       "         (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       )\n",
       "       (5): TransformerBlock(\n",
       "         (attention): MultiHeadSelfAttention(\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "           (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "         )\n",
       "         (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (ffn): FFN(\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "           (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         )\n",
       "         (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ), <lang.LanguageIndex at 0x7f763ce080f0>)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "load_bert_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from novelty_serve import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_from_drive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://ui.neptune.ai/aditya140/NoveltyCNN/e/NOVELTY-319\n",
      "NeptuneLogger will work in online mode\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type           | Params\n",
      "-----------------------------------------\n",
      "0 | model | DeepNoveltyCNN | 19 M  \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc453b5feade40ec87c80c371a02564a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ""
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd58ec08d8c04d878e3e4a610ecbee28"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36cfc3500a4c44c78efa04ee5940f07c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to send channel value.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/channels/channels_values_sender.py\", line 156, in _send_values\n    self._experiment._send_channels_values(channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/experiments.py\", line 1138, in _send_channels_values\n    self._backend.send_channels_values(self, channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/utils.py\", line 210, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 565, in send_channels_values\n    raise ChannelsValuesSendBatchError(experiment.id, batch_errors)\nneptune.api_exceptions.ChannelsValuesSendBatchError: Received batch errors sending channels' values to experiment NOVELTY-319. Cause: Error(code=400, message='X-coordinates must be strictly increasing for channel: afa9fa66-c607-46ad-b537-c4c061f52d7c. Invalid point: InputChannelValue(timestamp=2020-10-19T02:15:32.812Z, x=133.0, numericValue=0.0, textValue=null, ima', type=None) (metricId: 'afa9fa66-c607-46ad-b537-c4c061f52d7c', x: 133.0) Skipping 1 values.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc82230e373e4d5185533245ea37a6dd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to send channel value.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/channels/channels_values_sender.py\", line 156, in _send_values\n    self._experiment._send_channels_values(channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/experiments.py\", line 1138, in _send_channels_values\n    self._backend.send_channels_values(self, channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/utils.py\", line 210, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 565, in send_channels_values\n    raise ChannelsValuesSendBatchError(experiment.id, batch_errors)\nneptune.api_exceptions.ChannelsValuesSendBatchError: Received batch errors sending channels' values to experiment NOVELTY-319. Cause: Error(code=400, message='X-coordinates must be strictly increasing for channel: afa9fa66-c607-46ad-b537-c4c061f52d7c. Invalid point: InputChannelValue(timestamp=2020-10-19T02:20:17.276Z, x=267.0, numericValue=1.0, textValue=null, ima', type=None) (metricId: 'afa9fa66-c607-46ad-b537-c4c061f52d7c', x: 267.0) Skipping 1 values.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19f9abdeaa414512a101df7713a33e4a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to send channel value.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/channels/channels_values_sender.py\", line 156, in _send_values\n    self._experiment._send_channels_values(channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/experiments.py\", line 1138, in _send_channels_values\n    self._backend.send_channels_values(self, channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/utils.py\", line 210, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 565, in send_channels_values\n    raise ChannelsValuesSendBatchError(experiment.id, batch_errors)\nneptune.api_exceptions.ChannelsValuesSendBatchError: Received batch errors sending channels' values to experiment NOVELTY-319. Cause: Error(code=400, message='X-coordinates must be strictly increasing for channel: afa9fa66-c607-46ad-b537-c4c061f52d7c. Invalid point: InputChannelValue(timestamp=2020-10-19T02:25:02.742Z, x=401.0, numericValue=2.0, textValue=null, ima', type=None) (metricId: 'afa9fa66-c607-46ad-b537-c4c061f52d7c', x: 401.0) Skipping 1 values.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "819a2fc71453428ababfe427d94562c5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to send channel value.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/channels/channels_values_sender.py\", line 156, in _send_values\n    self._experiment._send_channels_values(channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/experiments.py\", line 1138, in _send_channels_values\n    self._backend.send_channels_values(self, channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/utils.py\", line 210, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 565, in send_channels_values\n    raise ChannelsValuesSendBatchError(experiment.id, batch_errors)\nneptune.api_exceptions.ChannelsValuesSendBatchError: Received batch errors sending channels' values to experiment NOVELTY-319. Cause: Error(code=400, message='X-coordinates must be strictly increasing for channel: afa9fa66-c607-46ad-b537-c4c061f52d7c. Invalid point: InputChannelValue(timestamp=2020-10-19T02:29:49.545Z, x=535.0, numericValue=3.0, textValue=null, ima', type=None) (metricId: 'afa9fa66-c607-46ad-b537-c4c061f52d7c', x: 535.0) Skipping 1 values.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2c7543b2bb344b18b38c73d48d4030a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Saving latest checkpoint..\n",
      "\n",
      "Failed to send channel value.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/channels/channels_values_sender.py\", line 156, in _send_values\n",
      "    self._experiment._send_channels_values(channels_with_values)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/neptune/experiments.py\", line 1138, in _send_channels_values\n",
      "    self._backend.send_channels_values(self, channels_with_values)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/neptune/utils.py\", line 210, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 565, in send_channels_values\n",
      "    raise ChannelsValuesSendBatchError(experiment.id, batch_errors)\n",
      "neptune.api_exceptions.ChannelsValuesSendBatchError: Received batch errors sending channels' values to experiment NOVELTY-319. Cause: Error(code=400, message='X-coordinates must be strictly increasing for channel: afa9fa66-c607-46ad-b537-c4c061f52d7c. Invalid point: InputChannelValue(timestamp=2020-10-19T02:34:35.135Z, x=669.0, numericValue=4.0, textValue=null, ima', type=None) (metricId: 'afa9fa66-c607-46ad-b537-c4c061f52d7c', x: 669.0) Skipping 1 values.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bee5d0563806422fb1472f96cd0e7fef"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_acc': tensor(0.9078),\n 'test_f1': tensor(0.9057),\n 'test_loss': tensor(0.2386, device='cuda:0')}\n--------------------------------------------------------------------------------\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "import pickle\n",
    "import argparse\n",
    "from lang import *\n",
    "from novelty.cnn.cnn_model import *\n",
    "from snli.bilstm.bilstm import *\n",
    "from snli.attn_enc.attn_enc import *\n",
    "from joblib import Memory\n",
    "import shutil\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateLogger\n",
    "from pytorch_lightning.profiler import AdvancedProfiler\n",
    "from pytorch_lightning.loggers import NeptuneLogger, TensorBoardLogger\n",
    "from pytorch_lightning.metrics import Accuracy\n",
    "from utils import load_bilstm_encoder, load_attn_encoder,seed_torch\n",
    "from novelty.train_utils import *\n",
    "from datamodule import *\n",
    "import os\n",
    "from keys import NEPTUNE_API\n",
    "\n",
    "seed_torch()\n",
    "\n",
    "\n",
    "encoder_ = \"BiLSTM\"\n",
    "dataset_ = \"DLND\"\n",
    "\n",
    "if encoder_ == 'Attention':\n",
    "    encoder, Lang = load_attn_encoder()\n",
    "else:\n",
    "    encoder, Lang = load_bilstm_encoder()\n",
    "\n",
    "if dataset_ == \"Webis\":\n",
    "    data_module = webis_data_module(Lang)\n",
    "else:\n",
    "    data_module = dlnd_data_module(Lang)\n",
    "\n",
    "params = {\n",
    "    \"num_filters\": 60,\n",
    "    \"dropout\": 0.3,\n",
    "    \"expand features\": True,\n",
    "    \"filter_sizes\": [4, 6, 9],\n",
    "    \"freeze_embedding\": False,\n",
    "    \"activation\": \"tanh\",\n",
    "    \"optim\": \"adamw\",\n",
    "    \"weight_decay\":0.1,\n",
    "    \"lr\": 0.00010869262115700171,\n",
    "    \"scheduler\": \"constant\",\n",
    "}\n",
    "\n",
    "model_conf = Novelty_CNN_conf(100, encoder, **params)\n",
    "model = Novelty_CNN_model(DeepNoveltyCNN, model_conf, params)\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "neptune_logger = NeptuneLogger(\n",
    "    api_key=NEPTUNE_API,\n",
    "    project_name=\"aditya140/NoveltyCNN\",\n",
    "    experiment_name=\"Evaluation\",  # Optional,\n",
    "    tags=[ dataset_, \"test\", \"CNN\",encoder_],\n",
    ")\n",
    "\n",
    "tensorboard_logger = TensorBoardLogger(\"lightning_logs\")\n",
    "\n",
    "lr_logger = LearningRateLogger(logging_interval=\"step\")\n",
    "neptune_logger.experiment.log_metric(\"epochs\", EPOCHS)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=EPOCHS,\n",
    "    progress_bar_refresh_rate=10,\n",
    "    profiler=False,\n",
    "    auto_lr_find=False,\n",
    "    callbacks=[lr_logger],\n",
    "    logger=[neptune_logger, tensorboard_logger],\n",
    "    row_log_interval=2,\n",
    ")\n",
    "trainer.fit(model, data_module)\n",
    "trainer.test(model, datamodule=data_module)\n",
    "\n",
    "MODEL_PATH = \"./models/cnn_novelty/\"\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)\n",
    "torch.save(model.model.state_dict(), MODEL_PATH + \"weights.pt\")\n",
    "with open(MODEL_PATH + \"model_conf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_conf, f)\n",
    "with open(MODEL_PATH + \"lang.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Lang, f)\n",
    "shutil.make_archive(\"./models/cnn_novelty\", \"zip\", \"./models/cnn_novelty\")\n",
    "neptune_logger.experiment.log_artifact(\"./models/cnn_novelty.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = torch.zeros((0))\n",
    "pred = torch.zeros((0,2))\n",
    "for i in data_module.test_dataloader():\n",
    "    a,b,c = i\n",
    "    true = torch.cat([true,c],dim = 0)\n",
    "    opt = model(a.cuda(),b.cuda()).detach().cpu()\n",
    "    pred = torch.cat([pred,opt],dim = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = pred.numpy()\n",
    "Y_test = true.numpy()\n",
    "Y_test = np.append((1-np.expand_dims(Y_test, axis=0)),np.expand_dims(Y_test, axis=0),0).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_bilstm_encoder, load_attn_encoder,seed_torch\n",
    "\n",
    "encoder, Lang = load_bilstm_encoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datamodule import IMDBDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = IMDBDataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "data.prepare_data(Lang,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[tensor([[[  101,  3040,  2933,  ...,     0,     0,     0],\n         [  101,  2028,  1997,  ...,     0,     0,     0],\n         [  101,  1996, 12700,  ...,     0,     0,     0],\n         ...,\n         [    0,     0,     0,  ...,     0,     0,     0],\n         [    0,     0,     0,  ...,     0,     0,     0],\n         [    0,     0,     0,  ...,     0,     0,     0]],\n\n        [[  101,  2023,  5015,  ...,     0,     0,     0],\n         [  101,  2009,  2428,  ...,     0,     0,     0],\n         [  101,  2009,  2001,  ...,     0,     0,     0],\n         ...,\n         [    0,     0,     0,  ...,     0,     0,     0],\n         [    0,     0,     0,  ...,     0,     0,     0],\n         [    0,     0,     0,  ...,     0,     0,     0]],\n\n        [[  101,  2065,  2017,  ...,     0,     0,     0],\n         [  101,  2025,  3243,  ...,     0,     0,     0],\n         [  101,  1037,  2442,  ...,     0,     0,     0],\n         ...,\n         [    0,     0,     0,  ...,     0,     0,     0],\n         [    0,     0,     0,  ...,     0,     0,     0],\n         [    0,     0,     0,  ...,     0,     0,     0]],\n\n        ...,\n\n        [[  101, 15067,  1996,  ...,     0,     0,     0],\n         [  101,  1996,  3715,  ...,     0,     0,     0],\n         [  101,  2007,  2087,  ...,     0,     0,     0],\n         ...,\n         [    0,     0,     0,  ...,     0,     0,     0],\n         [    0,     0,     0,  ...,     0,     0,     0],\n         [    0,     0,     0,  ...,     0,     0,     0]],\n\n        [[  101,  2023,  2518,  ...,     0,     0,     0],\n         [  101,  1996,  3841,  ...,     0,     0,     0],\n         [  101,  1998,  2002,  ...,     0,     0,     0],\n         ...,\n         [    0,     0,     0,  ...,     0,     0,     0],\n         [    0,     0,     0,  ...,     0,     0,     0],\n         [    0,     0,     0,  ...,     0,     0,     0]],\n\n        [[  101,  1996,  6355,  ...,     0,     0,     0],\n         [  101,  6157,   102,  ...,     0,     0,     0],\n         [  101,  7987,  7987,  ...,     0,     0,     0],\n         ...,\n         [    0,     0,     0,  ...,     0,     0,     0],\n         [    0,     0,     0,  ...,     0,     0,     0],\n         [    0,     0,     0,  ...,     0,     0,     0]]]), tensor([ 4,  4,  1,  1,  4,  9,  1, 10,  7,  4, 10,  8, 10,  9,  2,  8])]\n"
     ]
    }
   ],
   "source": [
    "for i in data.train_dataloader():\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://ui.neptune.ai/aditya140/Imdb/e/IM-11\n",
      "NeptuneLogger will work in online mode\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type           | Params\n",
      "-----------------------------------------\n",
      "0 | model | HAN_classifier | 19 M  \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c50397902eb9434eab1ff68e1503e91b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ""
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53964cf00ee841b7bf7ee6b2e03d72cd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1cca23b6be1a469babbb66e7a728f05e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5b8b0d4543c4ad3b33beb6014e51d2e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1f3ba12a62e4a87b201bef1e8c5fb53"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Saving latest checkpoint..\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd900088846644ffacb667ddc4bd37e5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_acc': tensor(0.4235),\n 'test_f1': tensor(0.2145),\n 'test_loss': tensor(1.5252, device='cuda:0')}\n--------------------------------------------------------------------------------\n\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "import joblib\n",
    "import pickle\n",
    "import argparse\n",
    "from lang import *\n",
    "from document.han.han import *\n",
    "from snli.bilstm.bilstm import *\n",
    "from snli.attn_enc.attn_enc import *\n",
    "from joblib import Memory\n",
    "import shutil\n",
    "import pytorch_lightning as pl\n",
    "from document.han.han import HAN_conf,HAN_classifier,HAN\n",
    "from pytorch_lightning.callbacks import LearningRateLogger\n",
    "from pytorch_lightning.profiler import AdvancedProfiler\n",
    "from pytorch_lightning.loggers import NeptuneLogger, TensorBoardLogger\n",
    "from pytorch_lightning.metrics import Accuracy\n",
    "from utils import load_bilstm_encoder, load_attn_encoder\n",
    "from document.train_utils import *\n",
    "from datamodule import *\n",
    "import os\n",
    "from keys import NEPTUNE_API\n",
    "\n",
    "\n",
    "encoder_ = 'bilstm'\n",
    "\n",
    "\n",
    "if encoder_ == \"bilstm\":\n",
    "    encoder, Lang = load_bilstm_encoder()\n",
    "elif encoder_ == \"attention\":\n",
    "    encoder, Lang = load_attn_encoder()\n",
    "\n",
    "data_module = imdb_data_module(Lang)\n",
    "\n",
    "params = {\n",
    "    \"optim\": \"adamw\",\n",
    "    \"weight_decay\":0.1,\n",
    "    \"lr\": 0.00010869262115700171,\n",
    "    \"scheduler\": \"constant\",\n",
    "}\n",
    "\n",
    "model_conf = HAN_conf(100, encoder, **params)\n",
    "model = Document_model_clf(HAN_classifier, model_conf, params)\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "neptune_logger = NeptuneLogger(\n",
    "    api_key=NEPTUNE_API,\n",
    "    project_name=\"aditya140/Imdb\",\n",
    "    experiment_name=\"training\", \n",
    "    tags=['HAN'],\n",
    ")\n",
    "\n",
    "tensorboard_logger = TensorBoardLogger(\"lightning_logs\")\n",
    "\n",
    "lr_logger = LearningRateLogger(logging_interval=\"step\")\n",
    "neptune_logger.experiment.log_metric(\"epochs\", EPOCHS)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=EPOCHS,\n",
    "    progress_bar_refresh_rate=10,\n",
    "    profiler=False,\n",
    "    auto_lr_find=False,\n",
    "    callbacks=[lr_logger],\n",
    "    logger=[neptune_logger, tensorboard_logger],\n",
    "    row_log_interval=2,\n",
    ")\n",
    "trainer.fit(model, data_module)\n",
    "trainer.test(model, datamodule=data_module)\n",
    "\n",
    "\n",
    "MODEL_PATH = \"./models/document_imdb_han/\"\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)\n",
    "torch.save(model.model.state_dict(), MODEL_PATH + \"weights.pt\")\n",
    "with open(MODEL_PATH + \"model_conf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_conf, f)\n",
    "with open(MODEL_PATH + \"lang.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Lang, f)\n",
    "shutil.make_archive(\"./models/document_imdb_han\", \"zip\", \"./models/document_imdb_han\")\n",
    "neptune_logger.experiment.log_artifact(\"./models/document_imdb_han.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://ui.neptune.ai/aditya140/Imdb/e/IM-18\n",
      "NeptuneLogger will work in online mode\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type          | Params\n",
      "------------------------------------------\n",
      "0 | model   | HAN_regressor | 19 M  \n",
      "1 | loss_fn | MSELoss       | 0     \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "54c6dadc01ac4940adb4437a52b460c5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ""
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8c5d8d92bd74f78bdd557c8b414c6d4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98b591d60bc74d8190e569dd2375638d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c683ce61d1dd4d718c451a8673eea8f9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc2044c95a75440b9c272da7af580aab"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec74a45c1c5147339e557138ea588619"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Saving latest checkpoint..\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a0b6b4f5d8d4285bf4941faa5a71d9e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_acc': tensor(0.3101),\n 'test_f1': tensor(0.2188),\n 'test_loss': tensor(2.4614, device='cuda:0'),\n 'test_rmse': tensor(1.5594, device='cuda:0')}\n--------------------------------------------------------------------------------\n\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "import joblib\n",
    "import pickle\n",
    "import argparse\n",
    "from lang import *\n",
    "from document.han.han import *\n",
    "from snli.bilstm.bilstm import *\n",
    "from snli.attn_enc.attn_enc import *\n",
    "from joblib import Memory\n",
    "import shutil\n",
    "import pytorch_lightning as pl\n",
    "from document.han.han import HAN_conf,HAN_classifier,HAN\n",
    "from pytorch_lightning.callbacks import LearningRateLogger\n",
    "from pytorch_lightning.profiler import AdvancedProfiler\n",
    "from pytorch_lightning.loggers import NeptuneLogger, TensorBoardLogger\n",
    "from pytorch_lightning.metrics import Accuracy\n",
    "from utils import load_bilstm_encoder, load_attn_encoder\n",
    "from document.train_utils import *\n",
    "from datamodule import *\n",
    "import os\n",
    "from keys import NEPTUNE_API\n",
    "\n",
    "\n",
    "encoder_ = 'bilstm'\n",
    "\n",
    "\n",
    "if encoder_ == \"bilstm\":\n",
    "    encoder, Lang = load_bilstm_encoder()\n",
    "elif encoder_ == \"attention\":\n",
    "    encoder, Lang = load_attn_encoder()\n",
    "\n",
    "data_module = imdb_data_module(Lang)\n",
    "\n",
    "params = {\n",
    "    \"optim\": \"adamw\",\n",
    "    \"weight_decay\":0.1,\n",
    "    \"lr\": 0.00010869262115700171,\n",
    "    \"scheduler\": \"constant\",\n",
    "}\n",
    "\n",
    "model_conf = HAN_conf(100, encoder, **params)\n",
    "model = Document_model_reg(HAN_regressor, model_conf, params)\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "neptune_logger = NeptuneLogger(\n",
    "    api_key=NEPTUNE_API,\n",
    "    project_name=\"aditya140/Imdb\",\n",
    "    experiment_name=\"training\", \n",
    "    tags=['HAN'],\n",
    ")\n",
    "\n",
    "tensorboard_logger = TensorBoardLogger(\"lightning_logs\")\n",
    "\n",
    "lr_logger = LearningRateLogger(logging_interval=\"step\")\n",
    "neptune_logger.experiment.log_metric(\"epochs\", EPOCHS)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=EPOCHS,\n",
    "    progress_bar_refresh_rate=10,\n",
    "    profiler=False,\n",
    "    auto_lr_find=False,\n",
    "    callbacks=[lr_logger],\n",
    "    logger=[neptune_logger, tensorboard_logger],\n",
    "    row_log_interval=2,\n",
    ")\n",
    "trainer.fit(model, data_module)\n",
    "trainer.test(model, datamodule=data_module)\n",
    "\n",
    "\n",
    "MODEL_PATH = \"./models/document_imdb_han/\"\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)\n",
    "torch.save(model.model.state_dict(), MODEL_PATH + \"weights.pt\")\n",
    "with open(MODEL_PATH + \"model_conf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_conf, f)\n",
    "with open(MODEL_PATH + \"lang.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Lang, f)\n",
    "shutil.make_archive(\"./models/document_imdb_han\", \"zip\", \"./models/document_imdb_han\")\n",
    "neptune_logger.experiment.log_artifact(\"./models/document_imdb_han.zip\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "for i in data_module.test_dataloader():\n",
    "    print(i[1].dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model(i[0].cuda()).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([2, 1, 1, 5, 6, 6, 1, 6, 6, 6, 3, 7, 7, 1, 6, 7, 2, 5, 0, 3, 4, 4, 2, 6,\n",
       "        2, 2, 6, 6, 1, 2, 1, 3, 1, 7, 5, 6, 5, 1, 2, 5, 6, 3, 0, 5, 1, 8, 6, 1,\n",
       "        1, 4, 0, 4, 0, 1, 1, 7, 1, 7, 6, 3, 7, 4, 4, 1], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "torch.round(a).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([5, 3, 0, 7, 3, 4, 2, 4, 4, 7, 5, 5, 7, 0, 7, 7, 6, 5, 0, 3, 6, 5, 4, 5,\n",
       "        3, 3, 7, 6, 0, 3, 0, 5, 2, 7, 2, 7, 5, 2, 3, 6, 7, 3, 3, 7, 0, 7, 7, 0,\n",
       "        3, 1, 0, 7, 0, 3, 1, 7, 0, 7, 7, 3, 6, 3, 3, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = Accuracy(num_classes=10)\n",
    "metricF1 = F1(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.2031)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "metric(torch.round(a).to(torch.int64).detach().cpu(),i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(15.6313, grad_fn=<MseLossBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "han,lang = load_han_reg_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "HAN(\n",
       "  (encoder): Attn_Encoder(\n",
       "    (embedding): Embedding(30522, 300, padding_idx=0)\n",
       "    (translate): Linear(in_features=300, out_features=400, bias=True)\n",
       "    (act): Tanh()\n",
       "    (lstm_layer): LSTM(400, 400, num_layers=2, bidirectional=True)\n",
       "    (attention): Attention(\n",
       "      (Ws): Linear(in_features=800, out_features=100, bias=False)\n",
       "      (Wa): Linear(in_features=100, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (translate): Linear(in_features=800, out_features=300, bias=True)\n",
       "  (act): ReLU()\n",
       "  (lstm_layer): LSTM(300, 300, num_layers=2, bidirectional=True)\n",
       "  (attention): Attention(\n",
       "    (Ws): Linear(in_features=600, out_features=50, bias=False)\n",
       "    (Wa): Linear(in_features=50, out_features=1, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "han"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\"The CNN then extracts the features from the relative document representation and finally classifies the incoming document. Results signify that our network is able to learn the complex semantic interactions between source and target information necessary to conclude upon the state of novelty of a document. It is to be noted that except (Ghosal et al., 2018) and our baselines, all other measures that we consider for comparison were developed with an information retrieval perspective. The p-values for F1 score produced by 20 runs of our system against the baseline are less than 0.05 and hence the improvement is statistically significant and unlikely to be observed by chance in 95 confidence interval.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vec = [lang.preprocess_sentence(i) for i in a.split(\".\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_novelty_tensor(s, Lang, num_sent):\n",
    "    if isinstance(s, list):\n",
    "        s = \". \".join(s)\n",
    "    pad_arr = [0] * Lang.max_len\n",
    "    t = Lang.encode_batch(Lang.preprocess_sentence(s).split(\".\"))\n",
    "    if t.shape[0] < num_sent:\n",
    "        opt = np.append(t, [pad_arr] * (num_sent - t.shape[0]), axis=0)\n",
    "    else:\n",
    "        opt = t[\n",
    "            : model_conf.num_sent,\n",
    "        ]\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 600])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "doc_ = torch.tensor(to_novelty_tensor(a,lang,100)).unsqueeze(0)\n",
    "han(doc_).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = han(doc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://ui.neptune.ai/aditya140/Novelty/e/NOVE-223\n",
      "NeptuneLogger will work in online mode\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | HAN_Novelty | 21 M  \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a8c4efd4837461bb665bac945599cef"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ""
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2678bb2274c3464d969ebfdf81810e45"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27e3a110d74f406e803808f9b8fa31e4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to send channel value.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/channels/channels_values_sender.py\", line 156, in _send_values\n    self._experiment._send_channels_values(channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/experiments.py\", line 1138, in _send_channels_values\n    self._backend.send_channels_values(self, channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/utils.py\", line 210, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 565, in send_channels_values\n    raise ChannelsValuesSendBatchError(experiment.id, batch_errors)\nneptune.api_exceptions.ChannelsValuesSendBatchError: Received batch errors sending channels' values to experiment NOVE-223. Cause: Error(code=400, message='X-coordinates must be strictly increasing for channel: a9f80a4c-b813-440e-b911-d4d59ac34286. Invalid point: InputChannelValue(timestamp=2020-10-20T02:32:51.511Z, x=133.0, numericValue=0.0, textValue=null, ima', type=None) (metricId: 'a9f80a4c-b813-440e-b911-d4d59ac34286', x: 133.0) Skipping 1 values.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c97cecc466e04693b14ef580f00c3d12"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to send channel value.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/channels/channels_values_sender.py\", line 156, in _send_values\n    self._experiment._send_channels_values(channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/experiments.py\", line 1138, in _send_channels_values\n    self._backend.send_channels_values(self, channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/utils.py\", line 210, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 565, in send_channels_values\n    raise ChannelsValuesSendBatchError(experiment.id, batch_errors)\nneptune.api_exceptions.ChannelsValuesSendBatchError: Received batch errors sending channels' values to experiment NOVE-223. Cause: Error(code=400, message='X-coordinates must be strictly increasing for channel: a9f80a4c-b813-440e-b911-d4d59ac34286. Invalid point: InputChannelValue(timestamp=2020-10-20T02:36:28.758Z, x=267.0, numericValue=1.0, textValue=null, ima', type=None) (metricId: 'a9f80a4c-b813-440e-b911-d4d59ac34286', x: 267.0) Skipping 1 values.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b28c2d4f5c5a4e9981627d16477fcf3d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to send channel value.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/channels/channels_values_sender.py\", line 156, in _send_values\n    self._experiment._send_channels_values(channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/experiments.py\", line 1138, in _send_channels_values\n    self._backend.send_channels_values(self, channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/utils.py\", line 210, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 565, in send_channels_values\n    raise ChannelsValuesSendBatchError(experiment.id, batch_errors)\nneptune.api_exceptions.ChannelsValuesSendBatchError: Received batch errors sending channels' values to experiment NOVE-223. Cause: Error(code=400, message='X-coordinates must be strictly increasing for channel: a9f80a4c-b813-440e-b911-d4d59ac34286. Invalid point: InputChannelValue(timestamp=2020-10-20T02:40:04.112Z, x=401.0, numericValue=2.0, textValue=null, ima', type=None) (metricId: 'a9f80a4c-b813-440e-b911-d4d59ac34286', x: 401.0) Skipping 1 values.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59ac50560d204076bae214dc13459d8c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to send channel value.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/channels/channels_values_sender.py\", line 156, in _send_values\n    self._experiment._send_channels_values(channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/experiments.py\", line 1138, in _send_channels_values\n    self._backend.send_channels_values(self, channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/utils.py\", line 210, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 565, in send_channels_values\n    raise ChannelsValuesSendBatchError(experiment.id, batch_errors)\nneptune.api_exceptions.ChannelsValuesSendBatchError: Received batch errors sending channels' values to experiment NOVE-223. Cause: Error(code=400, message='X-coordinates must be strictly increasing for channel: a9f80a4c-b813-440e-b911-d4d59ac34286. Invalid point: InputChannelValue(timestamp=2020-10-20T02:43:39.691Z, x=535.0, numericValue=3.0, textValue=null, ima', type=None) (metricId: 'a9f80a4c-b813-440e-b911-d4d59ac34286', x: 535.0) Skipping 1 values.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52dddf63513e41689db97ec05c8a6db9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Saving latest checkpoint..\n",
      "\n",
      "Failed to send channel value.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/channels/channels_values_sender.py\", line 156, in _send_values\n",
      "    self._experiment._send_channels_values(channels_with_values)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/neptune/experiments.py\", line 1138, in _send_channels_values\n",
      "    self._backend.send_channels_values(self, channels_with_values)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/neptune/utils.py\", line 210, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 565, in send_channels_values\n",
      "    raise ChannelsValuesSendBatchError(experiment.id, batch_errors)\n",
      "neptune.api_exceptions.ChannelsValuesSendBatchError: Received batch errors sending channels' values to experiment NOVE-223. Cause: Error(code=400, message='X-coordinates must be strictly increasing for channel: a9f80a4c-b813-440e-b911-d4d59ac34286. Invalid point: InputChannelValue(timestamp=2020-10-20T02:47:15.192Z, x=669.0, numericValue=4.0, textValue=null, ima', type=None) (metricId: 'a9f80a4c-b813-440e-b911-d4d59ac34286', x: 669.0) Skipping 1 values.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "710550dd7d9c4da3b222cc4a759a351d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_acc': tensor(0.8754),\n 'test_f1': tensor(0.8691),\n 'test_loss': tensor(0.4162, device='cuda:0')}\n--------------------------------------------------------------------------------\n\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "import joblib\n",
    "import pickle\n",
    "import argparse\n",
    "from lang import *\n",
    "from novelty.han.han_novelty import *\n",
    "from snli.bilstm.bilstm import *\n",
    "from snli.attn_enc.attn_enc import *\n",
    "from joblib import Memory\n",
    "import shutil\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateLogger\n",
    "from pytorch_lightning.profiler import AdvancedProfiler\n",
    "from pytorch_lightning.loggers import NeptuneLogger, TensorBoardLogger\n",
    "from pytorch_lightning.metrics import Accuracy\n",
    "from utils import load_bilstm_encoder, load_attn_encoder, load_han_clf_encoder,load_han_reg_encoder,reset_model\n",
    "from novelty.train_utils import *\n",
    "from datamodule import *\n",
    "import os\n",
    "from keys import NEPTUNE_API\n",
    "\n",
    "encoder_ ='reg'\n",
    "\n",
    "if encoder_ == \"reg\":\n",
    "    encoder, Lang = load_han_reg_encoder()\n",
    "elif encoder_ == \"clf\":\n",
    "    encoder, Lang = load_han_clf_encoder()\n",
    "\n",
    "data_module = dlnd_data_module(Lang)\n",
    "\n",
    "params = {\n",
    "    \"optim\": \"adamw\",\n",
    "    \"weight_decay\":0.1,\n",
    "    \"lr\": 0.00010869262115700171,\n",
    "    \"scheduler\": \"lambda\",\n",
    "}\n",
    "\n",
    "model_conf = HAN_Novelty_conf(encoder, **params)\n",
    "model = Novelty_CNN_model(HAN_Novelty, model_conf, params)\n",
    "\n",
    "model.model = reset_model(model.model)\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "neptune_logger = NeptuneLogger(\n",
    "    api_key=NEPTUNE_API,\n",
    "    project_name=\"aditya140/Novelty\",\n",
    "    experiment_name=\"Evaluation\",  # Optional,\n",
    "    tags=[\"DLND\", \"test\", \"HAN\"],\n",
    ")\n",
    "\n",
    "tensorboard_logger = TensorBoardLogger(\"lightning_logs\")\n",
    "\n",
    "lr_logger = LearningRateLogger(logging_interval=\"step\")\n",
    "neptune_logger.experiment.log_metric(\"epochs\", EPOCHS)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=EPOCHS,\n",
    "    progress_bar_refresh_rate=10,\n",
    "    profiler=False,\n",
    "    auto_lr_find=False,\n",
    "    callbacks=[lr_logger],\n",
    "    logger=[neptune_logger, tensorboard_logger],\n",
    "    row_log_interval=2,\n",
    ")\n",
    "trainer.fit(model, data_module)\n",
    "trainer.test(model, datamodule=data_module)\n",
    "\n",
    "MODEL_PATH = \"./models/cnn_novelty/\"\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)\n",
    "torch.save(model.model.state_dict(), MODEL_PATH + \"weights.pt\")\n",
    "with open(MODEL_PATH + \"model_conf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_conf, f)\n",
    "with open(MODEL_PATH + \"lang.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Lang, f)\n",
    "shutil.make_archive(\"./models/cnn_novelty\", \"zip\", \"./models/cnn_novelty\")\n",
    "neptune_logger.experiment.log_artifact(\"./models/cnn_novelty.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Structured Self Attention"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "import math\n",
    "\n",
    "\n",
    "class Struc_Attn_Encoder_conf:\n",
    "    embedding_dim = 300\n",
    "    hidden_size = 300\n",
    "    fcs = 1\n",
    "    r = 30\n",
    "    num_layers = 2\n",
    "    dropout = 0.1\n",
    "    opt_labels = 3\n",
    "    bidirectional = True\n",
    "    attn_type = \"dot\"\n",
    "    attention_layer_param = 100\n",
    "    activation = \"tanh\"\n",
    "    freeze_embedding = False\n",
    "    gated_embedding_dim = 100\n",
    "    gated = True\n",
    "    pool_strategy = 'max' # max,avg\n",
    "    penalty =True\n",
    "\n",
    "    def __init__(self, lang, embedding_matrix=None, **kwargs):\n",
    "        self.embedding_matrix = None\n",
    "        if lang.tokenizer == \"BERT\":\n",
    "            self.vocab_size = lang.vocab_size\n",
    "            self.padding_idx = lang.bert_tokenizer.vocab[\"[PAD]\"]\n",
    "        else:\n",
    "            self.embedding_matrix = embedding_matrix\n",
    "            self.vocab_size = lang.vocab_size_final()\n",
    "            self.padding_idx = lang.word2idx[lang.config.pad]\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "\n",
    "class Struc_Attention(nn.Module):\n",
    "    def __init__(self, conf):\n",
    "        super(Struc_Attention, self).__init__()\n",
    "        self.Ws = nn.Linear(\n",
    "            (2 if conf.bidirectional else 1) * conf.hidden_size,\n",
    "            conf.attention_layer_param,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.Wa = nn.Linear(conf.attention_layer_param, conf.r, bias=False)\n",
    "\n",
    "    def forward(self, hid):\n",
    "        opt = self.Ws(hid)\n",
    "        opt = F.tanh(opt)\n",
    "        opt = self.Wa(opt)\n",
    "        opt = F.softmax(opt)\n",
    "        return opt\n",
    "\n",
    "\n",
    "class Struc_Attn_Encoder(nn.Module):\n",
    "    def __init__(self, conf):\n",
    "        super(Struc_Attn_Encoder, self).__init__()\n",
    "        self.conf = conf\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=self.conf.vocab_size,\n",
    "            embedding_dim=self.conf.embedding_dim,\n",
    "            padding_idx=self.conf.padding_idx,\n",
    "        )\n",
    "        self.translate = nn.Linear(self.conf.embedding_dim, self.conf.hidden_size) # make (300,..) if not working\n",
    "        self.init_activation()\n",
    "        if isinstance(self.conf.embedding_matrix, np.ndarray):\n",
    "            self.embedding.from_pretrained(\n",
    "                torch.tensor(self.conf.embedding_matrix),\n",
    "                freeze=self.conf.freeze_embedding,\n",
    "            )\n",
    "        self.lstm_layer = nn.LSTM(\n",
    "            input_size=self.conf.hidden_size,\n",
    "            hidden_size=self.conf.hidden_size,\n",
    "            num_layers=self.conf.num_layers,\n",
    "            bidirectional=self.conf.bidirectional,\n",
    "        )\n",
    "        self.attention = Struc_Attention(conf)\n",
    "    \n",
    "    def init_activation(self):\n",
    "        if self.conf.activation.lower() == \"relu\".lower():\n",
    "            self.act = nn.ReLU()\n",
    "        elif self.conf.activation.lower() == \"tanh\".lower():\n",
    "            self.act = nn.Tanh()\n",
    "        elif self.conf.activation.lower() == \"leakyrelu\".lower():\n",
    "            self.act = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, inp):\n",
    "        batch_size = inp.shape[0]\n",
    "        embedded = self.embedding(inp)\n",
    "        embedded = self.translate(embedded)\n",
    "        embedded = self.act(embedded)\n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        all_, (hid, cell) = self.lstm_layer(embedded)\n",
    "        attn = self.attention(all_)\n",
    "        cont = torch.bmm(all_.permute(1, 2, 0), attn.permute(1, 0, 2)).permute(2, 0, 1)\n",
    "        return cont,attn\n",
    "\n",
    "\n",
    "class Struc_Attn_encoder_snli(nn.Module):\n",
    "    def __init__(self, conf):\n",
    "        super(Struc_Attn_encoder_snli, self).__init__()\n",
    "        self.conf = conf\n",
    "        self.encoder = Struc_Attn_Encoder(conf)\n",
    "        self.gated = self.conf.gated\n",
    "        self.penalty = self.conf.penalty\n",
    "        self.template = nn.Parameter(torch.zeros((1)), requires_grad=True)\n",
    "\n",
    "        # Gated parameters\n",
    "        if self.gated :\n",
    "            self.wt_p = torch.nn.Parameter(\n",
    "            torch.rand(\n",
    "                    (self.conf.r,\n",
    "                    (2 if conf.bidirectional else 1) * self.conf.hidden_size,\n",
    "                    self.conf.gated_embedding_dim\n",
    "                    )\n",
    "                ))\n",
    "            self.wt_h = torch.nn.Parameter(\n",
    "                torch.rand(\n",
    "                        (self.conf.r,\n",
    "                        (2 if conf.bidirectional else 1) * self.conf.hidden_size,\n",
    "                        self.conf.gated_embedding_dim\n",
    "                        )\n",
    "                    ))\n",
    "            self.fc_in = nn.Linear(\n",
    "                self.conf.gated_embedding_dim * self.conf.r,\n",
    "                self.conf.hidden_size,\n",
    "            )\n",
    "            self.fcs = nn.ModuleList(\n",
    "                [\n",
    "                    nn.Linear(self.conf.hidden_size, self.conf.hidden_size)\n",
    "                    for i in range(self.conf.fcs)\n",
    "                ]\n",
    "            )\n",
    "            self.fc_out = nn.Linear(self.conf.hidden_size, self.conf.opt_labels)\n",
    "\n",
    "        # Non Gated Version (max pool avg pool)\n",
    "        else:\n",
    "            self.fc_in = nn.Linear(\n",
    "            (2 if conf.bidirectional else 1) * 4 * self.conf.hidden_size,\n",
    "            self.conf.hidden_size,\n",
    "            )\n",
    "            self.fcs = nn.ModuleList(\n",
    "                [\n",
    "                    nn.Linear(self.conf.hidden_size, self.conf.hidden_size)\n",
    "                    for i in range(self.conf.fcs)\n",
    "                ]\n",
    "            )\n",
    "            self.fc_out = nn.Linear(self.conf.hidden_size, self.conf.opt_labels)\n",
    "\n",
    "\n",
    "        self.init_activation()\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.dropout = nn.Dropout(p=self.conf.dropout)\n",
    "        self.init_gated_encoder()\n",
    "\n",
    "    def init_gated_encoder(self):\n",
    "        kaiming_uniform_(self.wt_p)\n",
    "        kaiming_uniform_(self.wt_h)\n",
    "\n",
    "    def init_activation(self):\n",
    "        if self.conf.activation.lower() == \"relu\".lower():\n",
    "            self.act = nn.ReLU()\n",
    "        elif self.conf.activation.lower() == \"tanh\".lower():\n",
    "            self.act = nn.Tanh()\n",
    "        elif self.conf.activation.lower() == \"leakyrelu\".lower():\n",
    "            self.act = nn.LeakyReLU()\n",
    "\n",
    "    def penalty_l2(self,att):\n",
    "        att = att.permute(1,0,2)\n",
    "        penalty = (torch.norm(torch.bmm(att,att.transpose(1,2)) - torch.eye(att.size(1)).to(self.template.device),p='fro'))**2/att.size(0)\n",
    "        return penalty\n",
    "\n",
    "    def forward(self, x0, x1):\n",
    "        x0_enc,x0_attn = self.encoder(x0.long())\n",
    "        x0_enc = self.dropout(x0_enc)\n",
    "        x1_enc,x1_attn = self.encoder(x1.long())\n",
    "        x1_enc = self.dropout(x1_enc)\n",
    "\n",
    "        if self.gated:\n",
    "            F0 = x0_enc @ self.wt_p\n",
    "            F1 = x1_enc @ self.wt_h\n",
    "            \n",
    "            Fr = F0*F1\n",
    "\n",
    "            Fr = Fr.permute(1,0,2).flatten(start_dim=1)\n",
    "        else:\n",
    "            F0 = x0_enc.mean(0,keepdim=True)\n",
    "            F1 = x1_enc.mean(0,keepdim=True)\n",
    "            Fr = torch.cat(\n",
    "                [F0, F1, torch.abs(F0 - F1), F0 * F1], dim=2\n",
    "            )\n",
    "\n",
    "        opt = self.fc_in(Fr)\n",
    "        opt = self.dropout(opt)\n",
    "        for fc in self.fcs:\n",
    "            opt = fc(opt)\n",
    "            opt = self.dropout(opt)\n",
    "            opt = self.act(opt)\n",
    "        opt = self.fc_out(opt)\n",
    "        if self.penalty:\n",
    "            return opt,x0_attn,x1_attn\n",
    "        return opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "creating embedding matrix\n"
     ]
    }
   ],
   "source": [
    "from snli.train_utils import SNLI_model, snli_glove_data_module, snli_bert_data_module,SwitchOptim,SNLI_struc_attn_model\n",
    "from utils import *\n",
    "\n",
    "seed_torch()\n",
    "\n",
    "\n",
    "data_module = snli_glove_data_module(128)\n",
    "Lang = data_module.Lang\n",
    "embedding_matrix = read_embedding_file(Lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conf = Struc_Attn_Encoder_conf(Lang,embedding_matrix)\n",
    "model = Struc_Attn_encoder_snli(model_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[tensor([[  1, 223, 604,  ...,   0,   0,   2],\n        [  1, 223, 604,  ...,   0,   0,   2],\n        [  1, 223, 604,  ...,   0,   0,   2],\n        ...,\n        [  1,  16,  59,  ...,   0,   0,   2],\n        [  1, 479, 134,  ...,   0,   0,   2],\n        [  1, 479, 134,  ...,   0,   0,   2]]), tensor([[   1,    6,  604,  ...,    0,    0,    2],\n        [   1,    6,  604,  ...,    0,    0,    2],\n        [   1,    4, 1246,  ...,    0,    0,    2],\n        ...,\n        [   1,   16,  134,  ...,    0,    0,    2],\n        [   1,    4,  127,  ...,    0,    0,    2],\n        [   1,   16,  134,  ...,    0,    0,    2]]), tensor([2, 1, 0, 2, 1, 0, 1, 2, 0, 2, 1, 0, 1, 1, 0, 0, 1, 2, 1, 0, 2, 0, 1, 2,\n        2, 0, 1, 1, 2, 0, 0, 1, 1, 1, 2, 0, 2, 1, 0, 1, 2, 0, 0, 1, 2, 2, 0, 1,\n        2, 0, 2, 1, 0, 2, 0, 1, 1, 0, 2, 1, 0, 2, 2, 1, 0, 1, 2, 2, 0, 2, 1, 0,\n        1, 2, 0, 1, 2, 1, 1, 0, 0, 0, 1, 1, 0, 2, 0, 2, 1, 2, 0, 1, 2, 1, 0, 0,\n        1, 2, 2, 1, 0, 2, 1, 0, 1, 2, 1, 0, 1, 1, 1, 0, 2, 1, 0, 2, 1, 0, 0, 1,\n        2, 2, 0, 2, 1, 0, 2, 1])]\n"
     ]
    }
   ],
   "source": [
    "for i in data_module.test_dataloader():\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([100, 128, 30]) torch.Size([30, 128, 600])\n",
      "torch.Size([100, 128, 30]) torch.Size([30, 128, 600])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([128, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "model(i[0],i[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://ui.neptune.ai/aditya140/SNLI/e/SNLI-215\n",
      "NeptuneLogger will work in online mode\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                    | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------\n",
      "0 | model | Struc_Attn_encoder_snli | 27 M   | ?        | ?        \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee5a2bfbcab445fc8a82815440c2f2df"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ""
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0cda21e48e44182b955c42f435ca807"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c24650f54494b4d8541ab4ce855d576"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to send channel value.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/channels/channels_values_sender.py\", line 156, in _send_values\n    self._experiment._send_channels_values(channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/experiments.py\", line 1138, in _send_channels_values\n    self._backend.send_channels_values(self, channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/utils.py\", line 210, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 565, in send_channels_values\n    raise ChannelsValuesSendBatchError(experiment.id, batch_errors)\nneptune.api_exceptions.ChannelsValuesSendBatchError: Received batch errors sending channels' values to experiment SNLI-215. Cause: Error(code=400, message='X-coordinates must be strictly increasing for channel: 1e49768c-5024-452e-ae2a-6419158835a7. Invalid point: InputChannelValue(timestamp=2020-10-22T06:33:10.375Z, x=4291.0, numericValue=0.0, textValue=null, im', type=None) (metricId: '1e49768c-5024-452e-ae2a-6419158835a7', x: 4291.0) Skipping 1 values.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fa7d0b2d77e47e2b9be57a781d18726"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to send channel value.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/channels/channels_values_sender.py\", line 156, in _send_values\n    self._experiment._send_channels_values(channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/experiments.py\", line 1138, in _send_channels_values\n    self._backend.send_channels_values(self, channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/utils.py\", line 210, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 565, in send_channels_values\n    raise ChannelsValuesSendBatchError(experiment.id, batch_errors)\nneptune.api_exceptions.ChannelsValuesSendBatchError: Received batch errors sending channels' values to experiment SNLI-215. Cause: Error(code=400, message='X-coordinates must be strictly increasing for channel: 1e49768c-5024-452e-ae2a-6419158835a7. Invalid point: InputChannelValue(timestamp=2020-10-22T06:43:12.634Z, x=8583.0, numericValue=1.0, textValue=null, im', type=None) (metricId: '1e49768c-5024-452e-ae2a-6419158835a7', x: 8583.0) Skipping 1 values.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2536f0f5605487a8913336ff8e6e51b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to send channel value.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/channels/channels_values_sender.py\", line 156, in _send_values\n    self._experiment._send_channels_values(channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/experiments.py\", line 1138, in _send_channels_values\n    self._backend.send_channels_values(self, channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/utils.py\", line 210, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 565, in send_channels_values\n    raise ChannelsValuesSendBatchError(experiment.id, batch_errors)\nneptune.api_exceptions.ChannelsValuesSendBatchError: Received batch errors sending channels' values to experiment SNLI-215. Cause: Error(code=400, message='X-coordinates must be strictly increasing for channel: 1e49768c-5024-452e-ae2a-6419158835a7. Invalid point: InputChannelValue(timestamp=2020-10-22T06:53:15.237Z, x=12875.0, numericValue=2.0, textValue=null, i', type=None) (metricId: '1e49768c-5024-452e-ae2a-6419158835a7', x: 12875.0) Skipping 1 values.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "448808ba8008446fba2753c361d23865"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to send channel value.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/channels/channels_values_sender.py\", line 156, in _send_values\n    self._experiment._send_channels_values(channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/experiments.py\", line 1138, in _send_channels_values\n    self._backend.send_channels_values(self, channels_with_values)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/utils.py\", line 210, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 565, in send_channels_values\n    raise ChannelsValuesSendBatchError(experiment.id, batch_errors)\nneptune.api_exceptions.ChannelsValuesSendBatchError: Received batch errors sending channels' values to experiment SNLI-215. Cause: Error(code=400, message='X-coordinates must be strictly increasing for channel: 1e49768c-5024-452e-ae2a-6419158835a7. Invalid point: InputChannelValue(timestamp=2020-10-22T07:03:19.357Z, x=17167.0, numericValue=3.0, textValue=null, i', type=None) (metricId: '1e49768c-5024-452e-ae2a-6419158835a7', x: 17167.0) Skipping 1 values.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2e14a504e0e4062a4c4c71e5868409a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to send channel value.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/channels/channels_values_sender.py\", line 156, in _send_values\n",
      "    self._experiment._send_channels_values(channels_with_values)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/neptune/experiments.py\", line 1138, in _send_channels_values\n",
      "    self._backend.send_channels_values(self, channels_with_values)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/neptune/utils.py\", line 210, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 565, in send_channels_values\n",
      "    raise ChannelsValuesSendBatchError(experiment.id, batch_errors)\n",
      "neptune.api_exceptions.ChannelsValuesSendBatchError: Received batch errors sending channels' values to experiment SNLI-215. Cause: Error(code=400, message='X-coordinates must be strictly increasing for channel: 1e49768c-5024-452e-ae2a-6419158835a7. Invalid point: InputChannelValue(timestamp=2020-10-22T07:13:22.852Z, x=21459.0, numericValue=4.0, textValue=null, i', type=None) (metricId: '1e49768c-5024-452e-ae2a-6419158835a7', x: 21459.0) Skipping 1 values.\n",
      "Saving latest checkpoint..\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fca4a95849a0485eb040f1bb5e3be8df"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_acc': tensor(0.7854), 'test_loss': tensor(0.5690, device='cuda:0')}\n--------------------------------------------------------------------------------\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'test_acc': 0.7854099273681641, 'test_loss': 0.5690193772315979}]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from utils import *\n",
    "from datamodule import *\n",
    "from pytorch_lightning.callbacks import LearningRateLogger\n",
    "from snli.attn_enc.attn_enc import *\n",
    "from pytorch_lightning.loggers import NeptuneLogger, TensorBoardLogger\n",
    "from pytorch_lightning.profiler import AdvancedProfiler\n",
    "from pytorch_lightning.metrics import Accuracy\n",
    "import pickle\n",
    "import os\n",
    "from joblib import Memory\n",
    "import shutil\n",
    "import argparse\n",
    "from lang import *\n",
    "from snli.train_utils import SNLI_model, snli_glove_data_module, snli_bert_data_module,SwitchOptim\n",
    "from keys import NEPTUNE_API\n",
    "\n",
    "conf_kwargs = {\n",
    "        \"batch_size\": 128,\n",
    "        \"max_len\": 100,\n",
    "        \"embedding_dim\": 300,\n",
    "        \"hidden_size\" :300,\n",
    "        \"fcs\" : 1,\n",
    "        \"r\" : 30,\n",
    "        \"num_layers\" : 2,\n",
    "        \"dropout\" : 0.1,\n",
    "        \"opt_labels\" : 3,\n",
    "        \"bidirectional\" : True,\n",
    "        \"attention_layer_param\" :100,\n",
    "        \"activation\" : \"tanh\",\n",
    "        \"freeze_embedding\" : False,\n",
    "        \"gated_embedding_dim\" : 300,\n",
    "        \"gated\" : False,\n",
    "        \"pool_strategy\" : 'max',\n",
    "        \"C\":1.\n",
    "    }\n",
    "\n",
    "hparams = {\n",
    "    \"optimizer_base\":{\n",
    "        \"optim\": \"adamw\",\n",
    "        \"lr\": 0.0010039910781394373,\n",
    "        \"scheduler\": \"const\"\n",
    "        },\n",
    "    \"optimizer_tune\":{\n",
    "        \"optim\": \"sgd\",\n",
    "        \"lr\": 3e-4,\n",
    "        \"momentum\": 0,\n",
    "        \"weight_decay\": 0,\n",
    "        \"scheduler\": \"const\"\n",
    "    },\n",
    "    \"switch_epoch\":10,\n",
    "} \n",
    "\n",
    "Lang = data_module.Lang\n",
    "\n",
    "model_conf = Struc_Attn_Encoder_conf(Lang, embedding_matrix,**conf_kwargs)\n",
    "model = SNLI_struc_attn_model(Struc_Attn_encoder_snli, model_conf, hparams)\n",
    "\n",
    "EPOCHS = 6\n",
    "\n",
    "neptune_logger = NeptuneLogger(\n",
    "    api_key=NEPTUNE_API,\n",
    "    project_name=\"aditya140/SNLI\",\n",
    "    experiment_name=\"Evaluation\",\n",
    "    tags=[\"Struc Self Attention\"],\n",
    ")\n",
    "tensorboard_logger = TensorBoardLogger(\"lightning_logs\")\n",
    "lr_logger = LearningRateLogger(logging_interval=\"step\")\n",
    "\n",
    "neptune_logger.experiment.log_metric(\"epochs\", EPOCHS)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=EPOCHS,\n",
    "    progress_bar_refresh_rate=10,\n",
    "    profiler=False,\n",
    "    auto_lr_find=False,\n",
    "    callbacks=[lr_logger,SwitchOptim()],\n",
    "    logger=[neptune_logger, tensorboard_logger],\n",
    "    row_log_interval=2,\n",
    "    # gradient_clip_val=0.5,\n",
    ")\n",
    "trainer.fit(model, data_module)\n",
    "trainer.test(model, datamodule=data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([30, 600, 50])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= torch.rand((30,1,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([30, 1, 50])"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "torch.bmm(b,a).shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = torch.ones((30,128,600))\n",
    "wt = torch.ones((30,600,50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Expected tensor to have size 3840 at dimension 0, but got size 30 for argument #2 'batch2' (while checking arguments for bmm)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-c9cc37fa6958>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor to have size 3840 at dimension 0, but got size 30 for argument #2 'batch2' (while checking arguments for bmm)"
     ]
    }
   ],
   "source": [
    "torch.bmm(emb.view(30*128,1,600),wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "t() expects a tensor with <= 2 dimensions, but self is 3D",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-5ac7ee791e47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: t() expects a tensor with <= 2 dimensions, but self is 3D"
     ]
    }
   ],
   "source": [
    "F.linear(emb,wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([30, 128, 50])"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "emb.matmul(wt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = torch.rand((3,3,2))\n",
    "wt = torch.ones((3,2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0.6342, 0.6342, 0.6342, 0.6342]],\n",
       "\n",
       "        [[0.8806, 0.8806, 0.8806, 0.8806]],\n",
       "\n",
       "        [[0.8448, 0.8448, 0.8448, 0.8448]]])"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "emb[:,0,:].unsqueeze(1).matmul(wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0.4267, 0.2076],\n",
       "         [0.8026, 0.1468],\n",
       "         [0.3473, 0.9222]],\n",
       "\n",
       "        [[0.8667, 0.0139],\n",
       "         [0.6279, 0.6860],\n",
       "         [0.0298, 0.9107]],\n",
       "\n",
       "        [[0.2677, 0.5772],\n",
       "         [0.7093, 0.7226],\n",
       "         [0.4398, 0.0881]]])"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0.6342, 0.6342, 0.6342, 0.6342]],\n",
       "\n",
       "        [[0.8806, 0.8806, 0.8806, 0.8806]],\n",
       "\n",
       "        [[0.8448, 0.8448, 0.8448, 0.8448]]])"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "emb.matmul(wt)[:,0,:].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = torch.nn.Parameter(torch.rand((3,2,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.init import kaiming_uniform_\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[ 0.0090, -0.2795, -0.0215, -0.1704],\n",
       "         [-0.0792,  0.0280,  0.3027,  0.3143]],\n",
       "\n",
       "        [[-0.2606, -0.2643,  0.2702,  0.0258],\n",
       "         [-0.1872, -0.1068,  0.2531,  0.3323]],\n",
       "\n",
       "        [[ 0.3368, -0.0465, -0.1596, -0.0386],\n",
       "         [ 0.0175, -0.1783, -0.1059, -0.2353]]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "kaiming_uniform_(wt,a=math.sqrt(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand([30, 128, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([128, 3000])"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "a.permute(1,0,2).flatten(start_dim =1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = torch.rand([100, 128, 30]).permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(4539.1821)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "(torch.norm(torch.bmm(att,att.transpose(1,2)) - torch.eye(att.size(1)),p='fro')/att.size(0))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}