{
    "metadata": {
        "language_info": {
            "codemirror_mode": {"name": "ipython", "version": 3},
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9-final",
        },
        "orig_nbformat": 2,
        "kernelspec": {
            "name": "Python 3.6.9 64-bit",
            "display_name": "Python 3.6.9 64-bit",
            "metadata": {
                "interpreter": {
                    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
                }
            },
        },
    },
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from novelty_serve import *\n",
                "download_from_drive()\n",
                "model = load_novelty_cnn()\n",
                'model["model"] = model["model"].cuda()\n',
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                's="""The china taiwan conflict"""# has given rise to one of the biggest wars ever"""\n',
                't="""The china taiwan conflict has been resolved after 3 years of war """\n',
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {"text/plain": "[0.7373086810112, 0.26269131898880005]"},
                    "metadata": {},
                    "execution_count": 3,
                }
            ],
            "source": ["predict_novelty(s,t,model)"],
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import joblib\n",
                "import pickle\n",
                "import argparse\n",
                "from lang import *\n",
                "from novelty.cnn.cnn_model import *\n",
                "from snli.bilstm.bilstm import *\n",
                "from snli.attn_enc.attn_enc import *\n",
                "from joblib import Memory\n",
                "import shutil\n",
                "import pytorch_lightning as pl\n",
                "from pytorch_lightning.callbacks import LearningRateLogger\n",
                "from pytorch_lightning.profiler import AdvancedProfiler\n",
                "from pytorch_lightning.loggers import NeptuneLogger, TensorBoardLogger\n",
                "from pytorch_lightning.metrics import Accuracy\n",
                "from utils import load_bilstm_encoder,load_attn_encoder\n",
                "from novelty.train_utils import *\n",
                "from datamodule import *\n",
                "import os\n",
                "from keys import NEPTUNE_API\n",
                "from novelty.diin.diin import *\n",
                "\n",
                "\n",
                'arg_enc = "attention"\n',
                "arg_webis = False\n",
                "\n",
                'if arg_enc=="bilstm":\n',
                "    encoder, Lang = load_bilstm_encoder()\n",
                'elif arg_enc == "attention":\n',
                "    encoder, Lang = load_attn_encoder()\n",
                "\n",
                "data_module = webis_data_module(Lang) if arg_webis else dlnd_data_module(Lang)\n",
                "data_module.batch_size = 32\n",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {"tags": []},
            "outputs": [],
            "source": [
                "for x,y,z in data_module.val_dataloader():\n",
                "    print(x.shape,y.shape,z.shape)\n",
                "    break",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch\n",
                "import math\n",
                "\n",
                "\n",
                "#TODO : Add Dropout\n",
                "#TODO : Add Embedding penalty\n",
                "\n",
                "class DIIN_conf:\n",
                "    freeze_encoder = True\n",
                "\n",
                "    hidden_size = 300\n",
                "    fcs = 1\n",
                "    num_layers = 2\n",
                "    dropout = 0.1\n",
                "    opt_labels = 3\n",
                "    bidirectional = True\n",
                "    freeze_embedding = False\n",
                "    dense_net_growth_rate = 20\n",
                "    dense_net_layers = 8\n",
                "    dense_net_transition_rate = 0.5\n",
                "    dense_net_kernel_size = 3\n",
                "    dense_net_channels = 100\n",
                "    dense_net_first_scale_down_ratio = 0.3\n",
                "    first_scale_down_kernel = 1\n",
                "\n",
                "\n",
                "    num_sent = 100\n",
                "    batch_size = 32\n",
                "\n",
                "    def __init__(self,lang,encoder, **kwargs):\n",
                "        self.encoder = encoder\n",
                "        for k,v in kwargs.items():\n",
                "            setattr(self, k, v)\n",
                "\n",
                "class Highway(nn.Module):\n",
                "    def __init__(self, size, num_layers):\n",
                "\n",
                "        super(Highway, self).__init__()\n",
                "\n",
                "        self.num_layers = num_layers\n",
                "\n",
                "        self.nonlinear = nn.ModuleList([nn.Linear(size, size) for _ in range(num_layers)])\n",
                "\n",
                "        self.linear = nn.ModuleList([nn.Linear(size, size) for _ in range(num_layers)])\n",
                "\n",
                "        self.gate = nn.ModuleList([nn.Linear(size, size) for _ in range(num_layers)])\n",
                "\n",
                "        self.f = nn.Tanh()\n",
                "\n",
                "    def forward(self, x):\n",
                '        """\n',
                "        :param x: tensor with shape of [batch_size, size]\n",
                "        :return: tensor with shape of [batch_size, size]\n",
                "        applies σ(x) ⨀ (f(G(x))) + (1 - σ(x)) ⨀ (Q(x)) transformation | G and Q is affine transformation,\n",
                "        f is non-linear transformation, σ(x) is affine transformation with sigmoid non-linearition\n",
                "        and ⨀ is element-wise multiplication\n",
                '        """\n',
                "\n",
                "        for layer in range(self.num_layers):\n",
                "            gate = torch.sigmoid(self.gate[layer](x))\n",
                "\n",
                "            nonlinear = self.f(self.nonlinear[layer](x))\n",
                "            linear = self.linear[layer](x)\n",
                "\n",
                "            x = gate * nonlinear + (1 - gate) * linear\n",
                "        return x\n",
                "\n",
                "class self_attention(nn.Module):\n",
                '    """[summary]\n',
                "    Self attention modeled as demonstrated in NATURAL LANGUAGE INFERENCE OVER INTERACTION SPACE paper\n",
                "\n",
                "    REF: https://github.com/YerevaNN/DIIN-in-Keras/blob/master/layers/encoding.py\n",
                "\n",
                "    # P = P_hw\n",
                "    # itr_attn = P_itrAtt\n",
                "    # encoding = P_enc\n",
                "    # The paper takes inputs to be P(_hw) as an example and then computes the same thing for H,\n",
                "    # therefore we'll name our inputs P too.\n",
                "\n",
                "    # Input of encoding is P with shape (batch, p, d). It would be (batch, h, d) for hypothesis\n",
                "    # Construct alphaP of shape (batch, p, 3*d, p)\n",
                "    # A = dot(w_itr_att, alphaP)\n",
                "\n",
                "    # alphaP consists of 3*d rows along 2nd axis\n",
                "    # 1. up   -> first  d items represent P[i]\n",
                "    # 2. mid  -> second d items represent P[j]\n",
                "    # 3. down -> final items represent alpha(P[i], P[j]) which is element-wise product of P[i] and P[j] = P[i]*P[j]\n",
                "\n",
                "    # If we look at one slice of alphaP we'll see that it has the following elements:\n",
                "    # ----------------------------------------\n",
                "    # P[i][0], P[i][0], P[i][0], ... P[i][0]   ▲\n",
                "    # P[i][1], P[i][1], P[i][1], ... P[i][1]   |\n",
                "    # P[i][2], P[i][2], P[i][2], ... P[i][2]   |\n",
                "    # ...                              ...     | up\n",
                "    #      ...                         ...     |\n",
                "    #             ...                  ...     |\n",
                "    # P[i][d], P[i][d], P[i][d], ... P[i][d]   ▼\n",
                "    # ----------------------------------------\n",
                "    # P[0][0], P[1][0], P[2][0], ... P[p][0]   ▲\n",
                "    # P[0][1], P[1][1], P[2][1], ... P[p][1]   |\n",
                "    # P[0][2], P[1][2], P[2][2], ... P[p][2]   |\n",
                "    # ...                              ...     | mid\n",
                "    #      ...                         ...     |\n",
                "    #             ...                  ...     |\n",
                "    # P[0][d], P[1][d], P[2][d], ... P[p][d]   ▼\n",
                "    # ----------------------------------------\n",
                "    #                                          ▲\n",
                "    #                                          |\n",
                "    #                                          |\n",
                "    #               up * mid                   | down\n",
                "    #          element-wise product            |\n",
                "    #                                          |\n",
                "    #                                          ▼\n",
                "    # ----------------------------------------\n",
                "\n",
                "    # For every slice(i) the up part changes its P[i] values\n",
                "    # The middle part is repeated p times in depth (for every i)\n",
                "    # So we can get the middle part by doing the following:\n",
                "    # mid = broadcast(P) -> to get tensor of shape (batch, p, d, p)\n",
                "    # As we can notice up is the same mid, but with changed axis, so to obtain up from mid we can do:\n",
                "    # up = swap_axes(mid, axis1=0, axis2=2)\n",
                "\n",
                "    # P_itr_attn[i] = sum of for j = 1...p: \n",
                "    #                           s = sum(for k = 1...p:  e^A[k][j]\n",
                "    #                           ( e^A[i][j] / s ) * P[j]  --> P[j] is the j-th row, while the first part is a number\n",
                "    # So P_itr_attn is the weighted sum of P\n",
                "    # SA is column-wise soft-max applied on A\n",
                "    # P_itr_attn[i] is the sum of all rows of P scaled by i-th row of SA\n",
                "\n",
                '    """\n',
                "    def __init__(self,conf):\n",
                "        super().__init__()\n",
                "        self.w = nn.Linear(3*conf.hidden_size,1,bias=False)\n",
                "\n",
                "    def forward(self,p):\n",
                "        # p = [B,P,D]\n",
                "        p_dim = p.shape[1]\n",
                "        mid = p.unsqueeze(3).expand(-1,-1,-1,p_dim)\n",
                "        # min = [B,P,D,P]\n",
                "        up = mid.permute(0,3,2,1)\n",
                "        alpha = torch.cat([up,mid,up*mid],dim = 2)\n",
                "        A = (self.w.weight@alpha).squeeze(2)\n",
                "        sA = A.softmax(dim = 2)\n",
                "        itr_attn = torch.bmm(sA,p)\n",
                "        return itr_attn\n",
                "\n",
                "class fuse_gate(nn.Module):\n",
                '    """[summary]\n',
                "    Fuse gate is used to provide a Skip connection for the encoding and the attended output.\n",
                "    The author uses:\n",
                "    zi = tanh(W1 * [P:P_att]+b1)\n",
                "    ri = Sigmoid(W2 * [P:P_att]+b2)\n",
                "    fi = Sigmoid(W3 * [P:P_att]+b3)\n",
                "    P_new  = r dot P + fi dot zi\n",
                "\n",
                "    W1,W2,W3 = Linear(2d,d)\n",
                "\n",
                '    """\n',
                "    def __init__(self,conf):\n",
                "        super().__init__()\n",
                "        self.fc1 = nn.Linear(conf.hidden_size*2,conf.hidden_size)\n",
                "        self.fc2 = nn.Linear(conf.hidden_size*2,conf.hidden_size)\n",
                "        self.fc3 = nn.Linear(conf.hidden_size*2,conf.hidden_size)\n",
                "    def forward(self,p_hat_i,p_dash_i):\n",
                "        x = torch.cat([p_hat_i,p_dash_i],dim = 2)\n",
                "        z = torch.tanh(self.fc1(x))\n",
                "        r = torch.sigmoid(self.fc1(x))\n",
                "        f = torch.sigmoid(self.fc1(x))\n",
                "        enc = r * p_hat_i + f * z\n",
                "        return enc\n",
                "\n",
                "class interaction(nn.Module):\n",
                "    def __init__(self,conf):\n",
                "        super().__init__()\n",
                "    def forward(self,p,h):\n",
                "        p = p.unsqueeze(2)\n",
                "        h = h.unsqueeze(1)\n",
                "        return p*h\n",
                "\n",
                "class Dense_net_block(nn.Module):\n",
                "    def __init__(self, outChannels, growth_rate, kernel_size):\n",
                "        super(Dense_net_block, self).__init__()\n",
                "        self.conv = nn.Conv2d(outChannels, growth_rate, kernel_size=kernel_size, bias=False, padding=1)\n",
                "\n",
                "    def forward(self, x):\n",
                "        ft = F.relu(self.conv(x))\n",
                "        out = torch.cat((x, ft), dim=1)\n",
                "        return out\n",
                "\n",
                "class Dense_net_transition(nn.Module):\n",
                "    def __init__(self, nChannels, outChannels):\n",
                "        super(Dense_net_transition, self).__init__()\n",
                "        self.conv = nn.Conv2d(nChannels, outChannels, kernel_size=1, bias=False)\n",
                "\n",
                "    def forward(self, x):\n",
                "        out = self.conv(x)\n",
                "        out = F.max_pool2d(out, (2,2), (2,2), padding=0)\n",
                "        return out\n",
                "\n",
                "class DenseNet(nn.Module):\n",
                "    def __init__(self, nChannels, growthRate, reduction, nDenseBlocks, kernel_size):\n",
                "        super(DenseNet, self).__init__()\n",
                "        self.dense1 = self._make_dense(nChannels, growthRate, nDenseBlocks, kernel_size)\n",
                "        nChannels += nDenseBlocks*growthRate\n",
                "        nOutChannels = int(math.floor(nChannels*reduction))\n",
                "        self.trans1 = Dense_net_transition(nChannels, nOutChannels)\n",
                "        nChannels = nOutChannels\n",
                "        \n",
                "        self.dense2 = self._make_dense(nChannels, growthRate, nDenseBlocks, kernel_size)\n",
                "        nChannels += nDenseBlocks*growthRate\n",
                "        nOutChannels = int(math.floor(nChannels*reduction))\n",
                "        self.trans2 = Dense_net_transition(nChannels, nOutChannels)\n",
                "        nChannels = nOutChannels\n",
                "       \n",
                "        self.dense3 = self._make_dense(nChannels, growthRate, nDenseBlocks, kernel_size)\n",
                "        nChannels += nDenseBlocks*growthRate\n",
                "        nOutChannels = int(math.floor(nChannels*reduction))\n",
                "        self.trans3 = Dense_net_transition(nChannels, nOutChannels)\n",
                "\n",
                "    def _make_dense(self, nChannels, growthRate, nDenseBlocks, kernel_size):\n",
                "        layers = []\n",
                "        for i in range(int(nDenseBlocks)):\n",
                "            layers.append(Dense_net_block(nChannels, growthRate, kernel_size))\n",
                "            nChannels += growthRate\n",
                "        return nn.Sequential(*layers)\n",
                "\n",
                "    def forward(self, x):\n",
                "        out = self.trans1(self.dense1(x))\n",
                "        out = self.trans2(self.dense2(out))\n",
                "        out = self.trans3(self.dense3(out))\n",
                "        return out\n",
                "\n",
                "\n",
                "class DIIN(nn.Module):\n",
                "    def __init__(self,conf):\n",
                "        super().__init__()\n",
                "        self.conf = conf\n",
                "        self.encoder = self.conf.encoder\n",
                "        self.encoder.requires_grad = conf.freeze_encoder\n",
                "        self.num_sent = conf.num_sent\n",
                "        self.translate = nn.Linear(800, self.conf.hidden_size)\n",
                "        self.highway = Highway(self.conf.hidden_size,conf.num_layers)\n",
                "        self.attn = self_attention(self.conf)\n",
                "        self.fuse = fuse_gate(self.conf)\n",
                "        self.interact = interaction(self.conf)\n",
                "        self.interaction_cnn = nn.Conv2d(self.conf.hidden_size, int(self.conf.hidden_size * self.conf.dense_net_first_scale_down_ratio), self.conf.first_scale_down_kernel, padding=0)\n",
                "        self.dense_net = DenseNet(int(self.conf.hidden_size * self.conf.dense_net_first_scale_down_ratio), self.conf.dense_net_growth_rate, self.conf.dense_net_transition_rate, self.conf.dense_net_layers, self.conf.dense_net_kernel_size)\n",
                "        self.fc1 = nn.Linear(21744,2)\n",
                "        self.template = nn.Parameter(torch.zeros((1)), requires_grad=True)\n",
                "\n",
                "    def encode(self,src):\n",
                "        batch_size = src.shape[0]\n",
                "\n",
                "        x = src.view(-1, self.num_sent)\n",
                "\n",
                "        x_padded_idx = x.sum(dim=1) != 0\n",
                "\n",
                "        x_enc = []\n",
                "\n",
                "        for sub_batch in x[x_padded_idx].split(64):\n",
                "            x_enc.append(self.encoder(sub_batch)[0])\n",
                "        x_enc = torch.cat(x_enc, dim=0)\n",
                "\n",
                "\n",
                "        x_enc_t = torch.zeros((batch_size * self.num_sent, x_enc.size(1))).to(\n",
                "            self.template.device\n",
                "        )\n",
                "        x_enc_t[x_padded_idx] = x_enc\n",
                "\n",
                "\n",
                "        x_enc_t = x_enc_t.view(batch_size, self.num_sent, -1)\n",
                "        return x_enc_t\n",
                "        \n",
                "\n",
                "    def encode_attn(self,x):\n",
                "        x = self.encode(x)\n",
                "        x = self.translate(x)\n",
                "        x = self.highway(x)\n",
                "        x_att = self.attn(x)\n",
                "        enc = self.fuse(x,x_att)\n",
                "        return enc\n",
                "\n",
                "    def forward(self,p_tok,h_tok):\n",
                "        batch_size = p_tok.shape[0]\n",
                "        p_enc = self.encode_attn(p_tok)\n",
                "        h_enc = self.encode_attn(h_tok)\n",
                "        intr = self.interact(p_enc,h_enc).permute(0,3,1,2)\n",
                "        fm = self.interaction_cnn(intr)\n",
                "        dense = self.dense_net(fm)\n",
                "        opt = self.fc1(dense.reshape(batch_size,-1))\n",
                "        return opt\n",
                "    \n",
                "\n",
                "\n",
                "conf = DIIN_conf(Lang,encoder)\n",
                "nov_model = DIIN(conf)",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "tensor([[7.6207e-03, 3.4370e-05],\n        [7.6193e-03, 3.2628e-05],\n        [7.6208e-03, 3.3253e-05],\n        [7.6201e-03, 3.3580e-05],\n        [7.6191e-03, 3.2801e-05],\n        [7.6173e-03, 3.3898e-05],\n        [7.6197e-03, 3.2307e-05],\n        [7.6187e-03, 3.3519e-05],\n        [7.6198e-03, 3.3301e-05],\n        [7.6205e-03, 3.1790e-05]], grad_fn=<AddmmBackward>)"
                    },
                    "metadata": {},
                    "execution_count": 5,
                }
            ],
            "source": ["nov_model(x,y)"],
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {"tags": []},
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "NameError",
                    "evalue": "name 'model' is not defined",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-6-dca4a60e1061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnov_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined",
                    ],
                }
            ],
            "source": [
                "nov_model.cuda()\n",
                "data_module.batch_size = 30\n",
                "for x,y,z in data_module.val_dataloader():\n",
                "    print(x.shape,y.shape,z.shape)\n",
                "    print(nov_model(x.cuda(),y.cuda()).shape)\n",
                "    break",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {"tags": []},
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": "GPU available: True, used: True\nTPU available: False, using: 0 TPU cores\nCUDA_VISIBLE_DEVICES: [0]\n\n  | Name  | Type | Params\n-------------------------------\n0 | model | DIIN | 18 M  \n",
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "ee1d9d9965014cb2b5fe0760287f41dc",
                        },
                    },
                    "metadata": {},
                },
                {"output_type": "stream", "name": "stdout", "text": ""},
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "ba97a31339474879a139c74c0fe3aa2a",
                        },
                    },
                    "metadata": {},
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": "Saving latest checkpoint..\n\n",
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "32f1f58f356e491d82060b2c4e07606b",
                        },
                    },
                    "metadata": {},
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_acc': tensor(0.4324), 'test_loss': tensor(2546.5288, device='cuda:0')}\n--------------------------------------------------------------------------------\n\n",
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "[{'test_acc': 0.43239668011665344, 'test_loss': 2546.52880859375}]"
                    },
                    "metadata": {},
                    "execution_count": 6,
                },
            ],
            "source": [
                "\n",
                'model = Novelty_CNN_model(DIIN,conf,{"optim": "adamw",\n',
                '        "lr": 0.000630957344480193,\n',
                '        "scheduler":"lambda"})\n',
                "data_module.batch_size = 25\n",
                'tensorboard_logger = TensorBoardLogger("lightning_logs")\n',
                "EPOCHS = 10\n",
                'lr_logger = LearningRateLogger(logging_interval="step")\n',
                "trainer = pl.Trainer(\n",
                "    gpus=1,\n",
                "    max_epochs=EPOCHS,\n",
                "    progress_bar_refresh_rate=10,\n",
                "    profiler=False,\n",
                "    auto_lr_find=False,\n",
                "    callbacks=[lr_logger],\n",
                "    logger=[tensorboard_logger],\n",
                "    row_log_interval=2,\n",
                ")\n",
                "trainer.fit(model, data_module)\n",
                "trainer.test(model, datamodule=data_module)\n",
                "\n",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [],
        },
    ],
}
