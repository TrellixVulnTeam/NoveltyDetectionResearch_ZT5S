{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAN_conf:\n",
    "    num_sent = 100\n",
    "    sent_len = 100\n",
    "    encoder_dim = 400\n",
    "    hidden_size = 400\n",
    "    activation = 'relu'\n",
    "    dropout = 0.3\n",
    "\n",
    "    def __init__(self, num_sent, encoder, **kwargs):\n",
    "        self.num_sent = num_sent\n",
    "        self.encoder = encoder\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "class DAN(nn.Module):\n",
    "    def __init__(self,conf):\n",
    "        super(DAN,self).__init__()\n",
    "        self.conf = conf\n",
    "        self.sent_len = conf.sent_len\n",
    "        self.num_sent = conf.num_sent\n",
    "        self.encoder = conf.encoder\n",
    "        del self.conf.encoder\n",
    "        self.translate = nn.Linear(2 * self.conf.encoder_dim, self.conf.hidden_size)\n",
    "        self.template = nn.Parameter(torch.zeros((1)), requires_grad=True)\n",
    "        if self.conf.activation.lower() == \"relu\".lower():\n",
    "            self.act = nn.ReLU()\n",
    "        elif self.conf.activation.lower() == \"tanh\".lower():\n",
    "            self.act = nn.Tanh()\n",
    "        elif self.conf.activation.lower() == \"leakyrelu\".lower():\n",
    "            self.act = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(conf.dropout)\n",
    "\n",
    "        self.mlp_f = nn.Linear(self.conf.hidden_size, self.conf.hidden_size)\n",
    "        self.mlp_g = nn.Linear(2*self.conf.hidden_size, self.conf.hidden_size)\n",
    "        self.mlp_h = nn.Linear(2*self.conf.hidden_size, self.conf.hidden_size)\n",
    "        self.linear = nn.Linear(self.conf.hidden_size,2)\n",
    "\n",
    "    def encode_sent(self,inp):\n",
    "        batch_size,_,_ = inp.shape\n",
    "        x = inp.view(-1,self.sent_len)\n",
    "\n",
    "        x_padded_idx = x.sum(dim=1) != 0    \n",
    "        x_enc = []\n",
    "        for sub_batch in x[x_padded_idx].split(64):\n",
    "            x_enc.append(self.encoder(sub_batch)[0])\n",
    "        x_enc = torch.cat(x_enc, dim=0)\n",
    "\n",
    "        x_enc_t = torch.zeros((batch_size * self.num_sent, x_enc.size(1))).to(\n",
    "            self.template.device\n",
    "        )\n",
    "\n",
    "        x_enc_t[x_padded_idx] = x_enc\n",
    "        x_enc_t = x_enc_t.view(batch_size, self.num_sent, -1)\n",
    "    \n",
    "        embedded = self.dropout(self.translate(x_enc_t))\n",
    "        embedded = self.act(embedded)\n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        return embedded\n",
    "\n",
    "\n",
    "    def forward(self,x0,x1):\n",
    "        x0_enc = self.encode_sent(x0).permute(1,0,2)\n",
    "        x1_enc = self.encode_sent(x1).permute(1,0,2)\n",
    "\n",
    "        f1 = self.act(self.dropout(self.mlp_f(x0_enc)))\n",
    "        f2 = self.act(self.dropout(self.mlp_f(x1_enc)))\n",
    "\n",
    "        score1 = torch.bmm(f1, torch.transpose(f2, 1, 2))\n",
    "        prob1 = F.softmax(score1.view(-1, self.num_sent)).view(-1, self.num_sent, self.num_sent)\n",
    "\n",
    "        score2 = torch.transpose(score1.contiguous(), 1, 2)\n",
    "        score2 = score2.contiguous()\n",
    "\n",
    "        prob2 = F.softmax(score2.view(-1, self.num_sent)).view(-1, self.num_sent, self.num_sent)\n",
    "\n",
    "        sent1_combine = torch.cat((x0_enc, torch.bmm(prob1, x1_enc)), 2)\n",
    "        sent2_combine = torch.cat((x1_enc, torch.bmm(prob2, x0_enc)), 2)\n",
    "\n",
    "        \n",
    "\n",
    "        g1 = self.act(self.dropout(self.mlp_g(sent1_combine)))\n",
    "        g2 = self.act(self.dropout(self.mlp_g(sent2_combine)))\n",
    "\n",
    "        sent1_output = torch.sum(g1, 1)  \n",
    "        sent1_output = torch.squeeze(sent1_output, 1)\n",
    "    \n",
    "        sent2_output = torch.sum(g2, 1)  \n",
    "        sent2_output = torch.squeeze(sent2_output, 1)\n",
    "\n",
    "\n",
    "        input_combine = torch.cat((sent1_output * sent2_output, torch.abs(sent1_output - sent2_output)), 1)\n",
    "        \n",
    "        h = self.act(self.dropout(self.mlp_h(input_combine)))\n",
    "        opt = self.linear(h)\n",
    "        return opt\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load_models import load_bilstm_encoder, load_attn_encoder\n",
    "from utils.helpers import seed_torch\n",
    "\n",
    "encoder, Lang = load_attn_encoder(\"SNLI-12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conf = DAN_conf(20, encoder)\n",
    "model = DAN(model_conf)\n",
    "\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0,10000,[32,20,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([32, 20, 20]) torch.Size([32, 20, 20])\ntorch.Size([32, 20, 800]) torch.Size([32, 20, 800])\ntorch.Size([32, 20, 400]) torch.Size([32, 20, 400])\ntorch.Size([32, 400]) torch.Size([32, 400])\n"
     ]
    }
   ],
   "source": [
    "opt = model(x.cuda(),x.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "print(opt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(-1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([640, 100])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_padded_idx = x.sum(dim=1) != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([640])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "x_padded_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([640, 100])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "x[x_padded_idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}