{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "import joblib\n",
    "import pickle\n",
    "import argparse\n",
    "from lang import *\n",
    "from snli.bilstm.bilstm import *\n",
    "from snli.attn_enc.attn_enc import *\n",
    "from joblib import Memory\n",
    "import shutil\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateLogger\n",
    "from pytorch_lightning.profiler import AdvancedProfiler\n",
    "from pytorch_lightning.loggers import NeptuneLogger, TensorBoardLogger\n",
    "from pytorch_lightning.metrics import Accuracy\n",
    "from utils.load_models import load_bilstm_encoder, load_attn_encoder\n",
    "from utils.save_models import save_model, save_model_neptune\n",
    "from novelty.train_utils import *\n",
    "from datamodule import *\n",
    "import os\n",
    "from utils.keys import NEPTUNE_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"SNLI-12\"\n",
    "encoder, Lang = load_attn_encoder(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = dlnd_data_module(Lang, use_nltk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Transformer_conf:\n",
    "    num_sent = 100\n",
    "    sent_len = 100\n",
    "    encoder_dim = 400\n",
    "    hidden_size = 768\n",
    "    activation = \"relu\"\n",
    "    dropout = 0.3\n",
    "    transformer_max_len = num_sent * 2 + 1\n",
    "    n_heads = 6\n",
    "    sub_enc_layer = 1\n",
    "\n",
    "    def __init__(self, num_sent, encoder, **kwargs):\n",
    "        self.num_sent = num_sent\n",
    "        self.encoder = encoder\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "\n",
    "class Transformer_novelty(nn.Module):\n",
    "    def __init__(self, conf):\n",
    "        super(Transformer_novelty, self).__init__()\n",
    "        self.conf = conf\n",
    "        self.sent_len = conf.sent_len\n",
    "        self.num_sent = conf.num_sent\n",
    "        self.encoder = conf.encoder\n",
    "        del self.conf.encoder\n",
    "        self.translate = nn.Linear(2 * self.conf.encoder_dim, self.conf.hidden_size)\n",
    "        self.template = nn.Parameter(torch.zeros((1)), requires_grad=True)\n",
    "        if self.conf.activation.lower() == \"relu\".lower():\n",
    "            self.act = nn.ReLU()\n",
    "        elif self.conf.activation.lower() == \"tanh\".lower():\n",
    "            self.act = nn.Tanh()\n",
    "        elif self.conf.activation.lower() == \"leakyrelu\".lower():\n",
    "            self.act = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(conf.dropout)\n",
    "\n",
    "        self.pos_embedding = nn.Embedding(\n",
    "            num_embeddings=self.conf.transformer_max_len,\n",
    "            embedding_dim=self.conf.hidden_size,\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"position_ids\", torch.arange(self.conf.transformer_max_len).expand((1, -1))\n",
    "        )\n",
    "\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=self.conf.hidden_size, nhead=self.conf.n_heads\n",
    "            ),\n",
    "            self.conf.sub_enc_layer,\n",
    "        )\n",
    "\n",
    "        self.LayerNorm = nn.LayerNorm(self.conf.hidden_size)\n",
    "        self.pooler = nn.Linear(self.conf.hidden_size, self.conf.hidden_size)\n",
    "\n",
    "        self.translate_trans = nn.Linear(self.conf.hidden_size, self.conf.hidden_size)\n",
    "        self.template = nn.Parameter(torch.zeros((1)), requires_grad=True)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.cls = nn.Linear(self.conf.hidden_size, 2)\n",
    "\n",
    "    def encode_sent(self, inp):\n",
    "        batch_size, _, _ = inp.shape\n",
    "        x = inp.view(-1, self.sent_len)\n",
    "\n",
    "        x_padded_idx = x.sum(dim=1) != 0\n",
    "        x_enc = []\n",
    "        for sub_batch in x[x_padded_idx].split(64):\n",
    "            x_enc.append(self.encoder(sub_batch)[0])\n",
    "        x_enc = torch.cat(x_enc, dim=0)\n",
    "        encoder_dim = x_enc.shape[0]\n",
    "\n",
    "        x_enc = x_enc.view(batch_size,-1,encoder_dim)\n",
    "        print(x_enc.shape)\n",
    "\n",
    "\n",
    "    def forward(self, x0, x1):\n",
    "        batch_size, _, _ = x0.shape\n",
    "        x0_enc = self.encode_sent(x0).permute(1, 0, 2)\n",
    "        sep_token = torch.zeros((batch_size, 1, self.conf.hidden_size)).to(\n",
    "            self.template.device\n",
    "        )\n",
    "        x1_enc = self.encode_sent(x1).permute(1, 0, 2)\n",
    "        emb = torch.cat([x0_enc, sep_token, x1_enc], dim=1)\n",
    "        emb = emb.permute(1, 0, 2)\n",
    "        # print(emb.shape)\n",
    "\n",
    "        position_ids = self.position_ids.expand(batch_size, -1).transpose(0, 1)\n",
    "        # print(position_ids.shape)\n",
    "\n",
    "        pos_embedding = self.pos_embedding(position_ids)\n",
    "        # print(pos_embedding.shape)\n",
    "        emb = emb + pos_embedding\n",
    "\n",
    "        emb = self.LayerNorm(emb)\n",
    "        emb = self.dropout(emb)\n",
    "\n",
    "        opt = self.transformer(emb)[:1, :, :]\n",
    "        opt = self.pooler(opt)\n",
    "        opt = self.dropout(F.tanh(opt))\n",
    "        opt = self.translate_trans(opt)\n",
    "        opt = self.cls(opt)\n",
    "        opt = opt.permute(1, 0, 2)\n",
    "        return opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"encoder_dim\": encoder.conf.hidden_size,\n",
    "        \"dropout\": 0.3,\n",
    "        \"activation\": \"tanh\",\n",
    "        \"optim\": \"adamw\",\n",
    "        \"weight_decay\": 0.1,\n",
    "        \"lr\": 0.00010869262115700171,\n",
    "        \"scheduler\": \"lambda\",\n",
    "    }\n",
    "\n",
    "model_conf = Transformer_conf(100, encoder, **params)\n",
    "model = Transformer_novelty(model_conf)\n",
    "# model = Novelty_model(Transformer_novelty, model_conf, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([32, 25, 406])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'permute'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9a70d714cccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-de6d56bca95c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x0, x1)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mx0_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_sent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         sep_token = torch.zeros((batch_size, 1, self.conf.hidden_size)).to(\n\u001b[1;32m     85\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'permute'"
     ]
    }
   ],
   "source": [
    "dl = data_module.train_dataloader()\n",
    "for i in dl:\n",
    "    a,b,c,d = i\n",
    "    break\n",
    "model.cuda()\n",
    "a=a.cuda()\n",
    "b=b.cuda()\n",
    "model(a,b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                | Params\n",
      "----------------------------------------------\n",
      "0 | model | Transformer_novelty | 32 M  \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce4db04e6b0d4f4590f871ab6e703ad1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ""
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81e3267f1b114c28a7d3b983b97bad3a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "135068734327447f8719bbaceb66533f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c72170a4a424d24971cd5f9cf24b1b5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9638cca72f6347c4ace3bf05612bcd22"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Saving latest checkpoint..\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20834a5258b04af6ba885739c32c4492"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_acc': tensor(0.8111),\n 'test_f1': tensor(0.8040),\n 'test_loss': tensor(0.5277, device='cuda:0'),\n 'test_prec': tensor(0.8127),\n 'test_recall': tensor(0.8134)}\n--------------------------------------------------------------------------------\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'test_acc': 0.8110613822937012,\n",
       "  'test_f1': 0.8040344715118408,\n",
       "  'test_loss': 0.5276749730110168,\n",
       "  'test_prec': 0.8127212524414062,\n",
       "  'test_recall': 0.8134458661079407}]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "tensorboard_logger = TensorBoardLogger(\"lightning_logs\")\n",
    "\n",
    "loggers = [tensorboard_logger]\n",
    "\n",
    "lr_logger = LearningRateLogger(logging_interval=\"step\")\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=EPOCHS,\n",
    "    progress_bar_refresh_rate=10,\n",
    "    profiler=False,\n",
    "    auto_lr_find=False,\n",
    "    callbacks=[lr_logger],\n",
    "    logger=loggers,\n",
    "    row_log_interval=2,\n",
    ")\n",
    "trainer.fit(model, data_module)\n",
    "trainer.test(model, datamodule=data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.zeros((32,1,400))\n",
    "q = torch.zeros((32,100,400))\n",
    "r = torch.zeros((32,100,400))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([32, 201, 400])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "torch.cat([q,p,r],dim = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}