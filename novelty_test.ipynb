{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.defaults import *\n",
    "from src.datasets.novelty import *\n",
    "import sys\n",
    "old_stdout = sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_nli = 'NLI-92'\n",
    "\n",
    "download_models_from_neptune(load_nli)\n",
    "field = load_field(load_nli)\n",
    "# field = None\n",
    "\n",
    "\n",
    "dataset_conf = {'dataset': 'dlnd', 'max_num_sent': 60,\"sent_tokenizer\":\"spacy\",\"batch_size\":4,\"device\":\"cuda\"}\n",
    "# dataset_conf = {'dataset': 'dlnd', 'max_num_sent': 50,\"sent_tokenizer\":\"spacy\", \"tokenizer\":'spacy',\"max_len\":50,\"batch_size\":32,\"device\":\"cuda\"}\n",
    "model_conf = {'results_dir': 'results', 'device': 'cuda', 'dropout': 0.2, 'dataset': 'dlnd', 'hidden_size': 150, 'use_glove': False,\"num_filters\":95,\"filter_sizes\":[3,5,9],\"max_num_sent\":60,\"prune_p\":50,\"prune_q\":10,\"attention_layer_param\":150,\"attention_hops\":5,\"num_layers\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dlnd(dataset_conf,sentence_field = field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n[torchtext.data.batch.Batch of size 4]\n\t[.source]:[torch.cuda.LongTensor of size 4x60x50 (GPU 0)]\n\t[.target]:[torch.cuda.LongTensor of size 4x60x50 (GPU 0)]\n\t[.label]:[torch.cuda.LongTensor of size 4 (GPU 0)]\n"
     ]
    }
   ],
   "source": [
    "for i in data.train_iter:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.nli_models import *\n",
    "from src.model.novelty_models import *\n",
    "\n",
    "def load_encoder(enc_data):\n",
    "    if enc_data['options'].get(\"attention_layer_param\",0)==0:\n",
    "        model = bilstm_snli(enc_data[\"options\"])\n",
    "    elif enc_data['options'].get(\"r\",0)==0:\n",
    "        model = attn_bilstm_snli(enc_data[\"options\"])\n",
    "    else:\n",
    "        model = struc_attn_snli(enc_data[\"options\"])\n",
    "    return model\n",
    "\n",
    "nli_model_data = load_encoder_data(load_nli)\n",
    "nli_model_data['options'][\"use_glove\"] = False\n",
    "encoder = load_encoder(nli_model_data).encoder\n",
    "model_conf[\"encoder_dim\"] = nli_model_data[\"options\"][\"hidden_size\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class concat_attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.Wc1 = nn.Linear(2 * hidden_size, hidden_size, bias=False)\n",
    "        self.Wc2 = nn.Linear(2 * hidden_size, hidden_size, bias=False)\n",
    "        self.vc = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        _s1 = self.Wc1(x).unsqueeze(1)\n",
    "        _s2 = self.Wc2(y).unsqueeze(2)\n",
    "        sjt = self.vc(torch.tanh(_s1 + _s2)).squeeze()\n",
    "        ait = F.softmax(sjt, 2)\n",
    "        qtc = ait.bmm(x)\n",
    "        return qtc\n",
    "\n",
    "\n",
    "class bilinear_attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.Wb = nn.Linear(2 * hidden_size, 2 * hidden_size, bias=False)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        _s1 = self.Wb(x).transpose(2, 1)\n",
    "        sjt = y.bmm(_s1)\n",
    "        ait = F.softmax(sjt, 2)\n",
    "        qtb = ait.bmm(x)\n",
    "        return qtb\n",
    "\n",
    "\n",
    "class dot_attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.Wd = nn.Linear(2 * hidden_size, hidden_size, bias=False)\n",
    "        self.vd = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        _s1 = x.unsqueeze(1)\n",
    "        _s2 = y.unsqueeze(2)\n",
    "        sjt = self.vd(torch.tanh(self.Wd(_s1 * _s2))).squeeze()\n",
    "        ait = F.softmax(sjt, 2)\n",
    "        qtd = ait.bmm(x)\n",
    "        return qtd\n",
    "\n",
    "\n",
    "class minus_attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.Wm = nn.Linear(2 * hidden_size, hidden_size, bias=False)\n",
    "        self.vm = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "        self.Ws = nn.Linear(2 * hidden_size, hidden_size, bias=False)\n",
    "        self.vs = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        _s1 = x.unsqueeze(1)\n",
    "        _s2 = y.unsqueeze(2)\n",
    "        sjt = self.vm(torch.tanh(self.Wm(_s1 - _s2))).squeeze()\n",
    "        ait = F.softmax(sjt, 2)\n",
    "        qtm = ait.bmm(x)\n",
    "        return qtm\n",
    "\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, conf):\n",
    "        super(Attention, self).__init__()\n",
    "        self.Ws = nn.Linear(\n",
    "            2 * conf[\"hidden_size\"],\n",
    "            conf[\"attention_layer_param\"],\n",
    "            bias=False,\n",
    "        )\n",
    "        self.Wa = nn.Linear(conf[\"attention_layer_param\"], 1, bias=False)\n",
    "\n",
    "    def forward(self, hid):\n",
    "        opt = self.Ws(hid)\n",
    "        opt = torch.tanh(opt)\n",
    "        opt = self.Wa(opt)\n",
    "        opt = F.softmax(opt, dim=1)\n",
    "        return opt\n",
    "\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, conf):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.ut_dense = nn.Linear(2 * conf[\"hidden_size\"],conf[\"attention_layer_param\"],bias = False)\n",
    "        self.et_dense = nn.Linear(conf[\"attention_layer_param\"],conf[\"attention_hops\"],bias = False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, num_sent, embedding_width]\n",
    "        # ut shape: [batch_size, num_sent, att_unit]\n",
    "        ut = self.ut_dense(x)\n",
    "        ut = torch.tanh(ut)\n",
    "        # et shape: [batch_size, num_sent, att_hops]\n",
    "        et = self.et_dense(ut)\n",
    "\n",
    "        # att shape: [batch_size,  att_hops, seq_len]\n",
    "        att = F.softmax(et)\n",
    "        # output shape [batch_size, att_hops, embedding_width]\n",
    "        output = torch.bmm(att.permute(0, 2, 1), x).squeeze(1)\n",
    "        return output, att\n",
    "\n",
    "\n",
    "class HAN_DOC(nn.Module):\n",
    "    def __init__(self, conf, encoder):\n",
    "        super(HAN_DOC, self).__init__()\n",
    "        self.conf = conf\n",
    "        self.encoder = encoder\n",
    "\n",
    "        self.translate = nn.Linear(\n",
    "            2 * self.conf[\"encoder_dim\"], self.conf[\"hidden_size\"]\n",
    "        )\n",
    "        self.act = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(conf[\"dropout\"])\n",
    "        self.template = nn.Parameter(torch.zeros((1)), requires_grad=True)\n",
    "        self.lstm_layer = nn.LSTM(\n",
    "            input_size=self.conf[\"hidden_size\"],\n",
    "            hidden_size=self.conf[\"hidden_size\"],\n",
    "            num_layers=self.conf[\"num_layers\"],\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.attention = SelfAttention(conf)\n",
    "\n",
    "        self.prune_p = nn.Linear(2*self.conf[\"hidden_size\"],self.conf[\"prune_p\"])\n",
    "        self.prune_q = nn.Linear(self.conf[\"attention_hops\"],self.conf[\"prune_q\"])\n",
    "\n",
    "    def forward(self, inp):\n",
    "        batch_size, num_sent, max_len = inp.shape\n",
    "        x = inp.view(-1, max_len)\n",
    "\n",
    "        x_padded_idx = x.sum(dim=1) != 0\n",
    "        x_enc = []\n",
    "        for sub_batch in x[x_padded_idx].split(64):\n",
    "            x_enc.append(self.encoder(sub_batch, None))\n",
    "        x_enc = torch.cat(x_enc, dim=0)\n",
    "\n",
    "        x_enc_t = torch.zeros((batch_size * num_sent, x_enc.size(1))).to(\n",
    "            self.template.device\n",
    "        )\n",
    "\n",
    "        x_enc_t[x_padded_idx] = x_enc\n",
    "        x_enc_t = x_enc_t.view(batch_size, num_sent, -1)\n",
    "\n",
    "        embedded = self.dropout(self.translate(x_enc_t))\n",
    "        embedded = self.act(embedded)\n",
    "\n",
    "        all_, (_, _) = self.lstm_layer(embedded)\n",
    "\n",
    "        # opt: [batch, att_hops, hidden_size]\n",
    "        opt,attn = self.attention(all_)\n",
    "        \n",
    "\n",
    "        # p_section: [batch, att_hops, prune_p]\n",
    "        p_section = self.prune_p(opt)\n",
    "        # q_section: [batch, hidden_size, prune_q]\n",
    "\n",
    "        q_section = self.prune_q(opt.permute(0,2,1))\n",
    "        \n",
    "\n",
    "        encoded = torch.cat([p_section.view(batch_size,-1),q_section.view(batch_size,-1)],dim=1)\n",
    "        \n",
    "        return encoded\n",
    "\n",
    "\n",
    "class tester(nn.Module):\n",
    "    def __init__(self, conf, encoder, doc_enc=None):\n",
    "        super(tester, self).__init__()\n",
    "        self.conf = conf\n",
    "        if doc_enc == None:\n",
    "            self.encoder = HAN_DOC(conf, encoder)\n",
    "        elif encoder == None:\n",
    "            self.encoder = doc_enc\n",
    "        self.act = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(conf[\"dropout\"])\n",
    "\n",
    "        fc_in_dim = self.conf[\"attention_hops\"]*self.conf[\"prune_p\"] + 2*self.conf[\"hidden_size\"]*self.conf[\"prune_q\"]\n",
    "\n",
    "        self.fc = nn.Linear(4*fc_in_dim, 2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x0,x1 = inputs\n",
    "        x0_enc = self.encoder(x0)\n",
    "        x1_enc = self.encoder(x1)\n",
    "        # print(x0_enc.shape)\n",
    "        # print(x1_enc.shape)\n",
    "\n",
    "        cont = torch.cat(\n",
    "            [\n",
    "                x0_enc,\n",
    "                x1_enc,\n",
    "                torch.abs(x0_enc - x1_enc),\n",
    "                x0_enc * x1_enc,\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        cont = self.dropout(self.act(cont))\n",
    "        cont = self.fc(cont)\n",
    "        return cont\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tester(\n",
       "  (encoder): HAN_DOC(\n",
       "    (encoder): BiLSTM_encoder(\n",
       "      (embedding): Embedding(33934, 300, padding_idx=1)\n",
       "      (projection): Linear(in_features=300, out_features=400, bias=True)\n",
       "      (lstm): LSTM(400, 400, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (translate): Linear(in_features=800, out_features=150, bias=True)\n",
       "    (act): ReLU()\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (lstm_layer): LSTM(150, 150, bidirectional=True)\n",
       "    (attention): SelfAttention(\n",
       "      (ut_dense): Linear(in_features=300, out_features=150, bias=False)\n",
       "      (et_dense): Linear(in_features=150, out_features=5, bias=False)\n",
       "    )\n",
       "    (prune_p): Linear(in_features=300, out_features=50, bias=True)\n",
       "    (prune_q): Linear(in_features=5, out_features=10, bias=True)\n",
       "  )\n",
       "  (act): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=6500, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 202
    }
   ],
   "source": [
    "model = tester(model_conf,encoder)\n",
    "model.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Parameters: 13.4M\n"
     ]
    }
   ],
   "source": [
    "trainloader,valloader,testloader = data.get_dataloaders()\n",
    "import ballpark\n",
    "print(\"Model Parameters:\",ballpark.business(sum(p.numel() for p in model.parameters() if p.requires_grad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.0707, -0.2080],\n        [ 0.0649, -0.3061],\n        [ 0.0080, -0.3542],\n        [-0.0220, -0.2619]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "i,l = next(iter(trainloader))\n",
    "opt = model(i)\n",
    "print(opt)\n",
    "trainloader,valloader,testloader = data.get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Acc 53.44545666900257\n",
      "Loss: 755.272955738008\n",
      "-------------\n",
      "Val Acc 55.03731343283582\n",
      "Val Loss: 92.16557067632675\n",
      "-------------\n",
      "Train Acc 64.12053258584443\n",
      "Loss: 697.0707288980484\n",
      "-------------\n",
      "Val Acc 68.47014925373135\n",
      "Val Loss: 82.14385944604874\n",
      "-------------\n",
      "Train Acc 73.67437514599392\n",
      "Loss: 585.704736797139\n",
      "-------------\n",
      "Val Acc 76.30597014925372\n",
      "Val Loss: 66.0655355155468\n",
      "-------------\n",
      "Train Acc 80.892314879701\n",
      "Loss: 467.5735091175884\n",
      "-------------\n",
      "Val Acc 79.2910447761194\n",
      "Val Loss: 63.57440869510174\n",
      "-------------\n",
      "Train Acc 84.79327259985985\n",
      "Loss: 390.52157745929435\n",
      "-------------\n",
      "Val Acc 79.4776119402985\n",
      "Val Loss: 65.49550592154264\n",
      "-------------\n",
      "Train Acc 87.47956085026863\n",
      "Loss: 339.86118906363845\n",
      "-------------\n",
      "Val Acc 80.78358208955224\n",
      "Val Loss: 59.70144883915782\n",
      "-------------\n",
      "Train Acc 89.20812894183602\n",
      "Loss: 285.7252041818356\n",
      "-------------\n",
      "Val Acc 79.1044776119403\n",
      "Val Loss: 58.688639322295785\n",
      "-------------\n",
      "Val Acc 83.3644859813084\n",
      "Val Loss: 54.29779403586872\n",
      "-------------\n",
      "This run of test ran for 0:12:22 and logs are available locally at: /root/.hyperdash/logs/test/test_2021-02-25t22-51-03-614876.log\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from hyperdash import Experiment\n",
    "\n",
    "sys.stdout = old_stdout\n",
    "\n",
    "exp = Experiment(\"test\",api_key_getter = get_hyperdash_api)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def train(model,dl,optimizer,criterion):\n",
    "    model.train()\n",
    "    n_correct, n_total,running_loss = 0, 0,0\n",
    "    for i, data in enumerate(dl, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = [x.to(device) for x in inputs], labels.to(device)\n",
    "        batch_size = labels.shape[0]\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        n_correct += ((torch.max(F.softmax(outputs, dim=1), 1)[1].view(labels.size())== labels).sum().item())\n",
    "        n_total += batch_size\n",
    "\n",
    "        exp.metric('train loss',loss.item(),log=False)\n",
    "        print(f\"loss = {loss.item()}\",end = '\\r')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_total\n",
    "    print(\"Train Acc\",acc)\n",
    "    exp.metric('train acc',acc,log=False)\n",
    "    exp.metric('train running loss',running_loss,log=False)\n",
    "    print('Loss: {}'.format(running_loss))\n",
    "    print(\"-------------\")\n",
    "\n",
    "\n",
    "def validate(model,dl,criterion):\n",
    "    \n",
    "    n_correct, n_total,running_loss = 0, 0,0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dl, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = [x.to(device) for x in inputs], labels.to(device)\n",
    "            batch_size = labels.shape[0]\n",
    "            # forward \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            n_correct += ((torch.max(F.softmax(outputs, dim=1), 1)[1].view(labels.size())== labels).sum().item())\n",
    "            n_total += batch_size\n",
    "\n",
    "            exp.metric('val loss',loss.item(),log=False)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "        acc = 100.0 * n_correct / n_total\n",
    "        print(\"Val Acc\",acc)\n",
    "        exp.metric('val acc',acc, log=False)\n",
    "        exp.metric('val running loss',running_loss, log=False)\n",
    "        print('Val Loss: {}'.format(running_loss))\n",
    "        print(\"-------------\")\n",
    "\n",
    "try:\n",
    "\n",
    "    # loop over the dataset multiple times\n",
    "    for epoch in range(7):\n",
    "        train(model,trainloader,optimizer,criterion)\n",
    "        validate(model,valloader,criterion)\n",
    "    validate(model,testloader,criterion)\n",
    "    exp.end()\n",
    "    print('Finished Training')\n",
    "except KeyboardInterrupt:\n",
    "    validate(model,testloader,criterion)\n",
    "    exp.end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model,trainloader,valloader,testloader\n",
    "del optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 60, 3200])"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "opt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= [[0.0,0.5,0.5],\n",
    "    [0.5,0.0,0.5],\n",
    "    [0.5,0.5,0.0]]\n",
    "b= [[0.5,0.0,0.5],\n",
    "    [0.0,0.5,0.5],\n",
    "    [0.5,0.5,0.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.tensor(a)\n",
    "b= torch.tensor(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.5000, 0.5000, 0.5000, 0.0000, 0.5000, 0.5000, 0.5000, 0.0000])"
      ]
     },
     "metadata": {},
     "execution_count": 182
    }
   ],
   "source": [
    "a.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.7071, 0.7071],\n",
       "        [0.7071, 0.0000, 0.7071],\n",
       "        [0.7071, 0.7071, 0.0000]])"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "a_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.7071, 0.0000, 0.7071],\n",
       "        [0.0000, 0.7071, 0.7071],\n",
       "        [0.7071, 0.7071, 0.0000]])"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "b_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = torch.mm(a_norm, b_norm.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# optimizer = optim.Adadelta(model.parameters(),lr = 0.01,)\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(train_dl, val_loader=val_dl, end_lr=0.01, num_iter=100, step_mode=\"exp\")\n",
    "lr_finder.plot(log_lr=False)\n",
    "lr_finder.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.5000, 1.0000, 0.5000],\n",
       "        [1.0000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 1.0000]])"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[   2, 7341,    6,  ...,    1,    1,    1],\n",
       "         [   2,  136,  953,  ...,    1,    1,    1],\n",
       "         [   2,  631,   20,  ...,    1,    1,    1],\n",
       "         ...,\n",
       "         [   2,    6, 7020,  ...,    1,    1,    1],\n",
       "         [   2,  179, 1679,  ...,    1,    1,    1],\n",
       "         [   2,  136, 5916,  ...,    1,    1,    1]],\n",
       "\n",
       "        [[   2,    0,   18,  ...,   55,   11,    3],\n",
       "         [   2, 1602,    4,  ...,    1,    1,    1],\n",
       "         [   2,   31,    0,  ...,    1,    1,    1],\n",
       "         ...,\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1]],\n",
       "\n",
       "        [[   2,   20, 1532,  ...,    1,    1,    1],\n",
       "         [   2, 3071, 1848,  ...,    1,    1,    1],\n",
       "         [   2,    6,  176,  ...,    1,    1,    1],\n",
       "         ...,\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1]],\n",
       "\n",
       "        [[   2, 1669, 2364,  ...,    1,    1,    1],\n",
       "         [   2,    6, 8668,  ...,    1,    1,    1],\n",
       "         [   2,    4, 5424,  ...,    1,    1,    1],\n",
       "         ...,\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1]]])"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "bat = []\n",
    "for i in trainloader:\n",
    "    print(i)\n",
    "    bat.append(i)\n",
    "    c+=1\n",
    "    if c==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[tensor([[[    2,  1500,    63,  ...,     1,     1,     1],\n",
       "           [    2,    52,  5336,  ...,     1,     1,     1],\n",
       "           [    2,  6245,     0,  ...,  3033,     8,     3],\n",
       "           ...,\n",
       "           [    1,     1,     1,  ...,     1,     1,     1],\n",
       "           [    1,     1,     1,  ...,     1,     1,     1],\n",
       "           [    1,     1,     1,  ...,     1,     1,     1]],\n",
       "  \n",
       "          [[    2, 33131, 12758,  ...,     3,     1,     1],\n",
       "           [    2,     0,    18,  ...,     1,     1,     1],\n",
       "           [    2,     6,     0,  ...,     1,     1,     1],\n",
       "           ...,\n",
       "           [    1,     1,     1,  ...,     1,     1,     1],\n",
       "           [    1,     1,     1,  ...,     1,     1,     1],\n",
       "           [    1,     1,     1,  ...,     1,     1,     1]],\n",
       "  \n",
       "          [[    2,     0,   939,  ...,     1,     1,     1],\n",
       "           [    2,     6, 13524,  ...,     1,     1,     1],\n",
       "           [    2,     6,  9296,  ...,     1,     1,     1],\n",
       "           ...,\n",
       "           [    2, 20408,  1966,  ...,     1,     1,     1],\n",
       "           [    2,  1326,  4527,  ...,     1,     1,     1],\n",
       "           [    2,  8261,    13,  ...,     1,     1,     1]],\n",
       "  \n",
       "          [[    2,  1660,    13,  ...,     1,     1,     1],\n",
       "           [    2,    16,    17,  ...,     1,     1,     1],\n",
       "           [    2,     6,  1783,  ...,     1,     1,     1],\n",
       "           ...,\n",
       "           [    1,     1,     1,  ...,     1,     1,     1],\n",
       "           [    1,     1,     1,  ...,     1,     1,     1],\n",
       "           [    1,     1,     1,  ...,     1,     1,     1]]]),\n",
       "  tensor([[[    2,     6, 33129,  ...,     1,     1,     1],\n",
       "           [    2,     6,  8169,  ...,     1,     1,     1],\n",
       "           [    2,     4, 33129,  ...,     1,     1,     1],\n",
       "           ...,\n",
       "           [    1,     1,     1,  ...,     1,     1,     1],\n",
       "           [    1,     1,     1,  ...,     1,     1,     1],\n",
       "           [    1,     1,     1,  ...,     1,     1,     1]],\n",
       "  \n",
       "          [[    2, 33131, 12758,  ...,     1,     1,     1],\n",
       "           [    2,     6,   999,  ...,     1,     1,     1],\n",
       "           [    2,  6485,   223,  ...,   750,  5514,     3],\n",
       "           ...,\n",
       "           [    1,     1,     1,  ...,     1,     1,     1],\n",
       "           [    1,     1,     1,  ...,     1,     1,     1],\n",
       "           [    1,     1,     1,  ...,     1,     1,     1]],\n",
       "  \n",
       "          [[    2,  2662,   695,  ...,     5,     3,     1],\n",
       "           [    2,   179,  4734,  ...,     1,     1,     1],\n",
       "           [    2,   136,   240,  ...,     1,     1,     1],\n",
       "           ...,\n",
       "           [    1,     1,     1,  ...,     1,     1,     1],\n",
       "           [    1,     1,     1,  ...,     1,     1,     1],\n",
       "           [    1,     1,     1,  ...,     1,     1,     1]],\n",
       "  \n",
       "          [[    2,    20,  1532,  ...,     1,     1,     1],\n",
       "           [    2,    16,    17,  ...,     1,     1,     1],\n",
       "           [    2,     6,   259,  ...,     0,   926,     3],\n",
       "           ...,\n",
       "           [    1,     1,     1,  ...,     1,     1,     1],\n",
       "           [    1,     1,     1,  ...,     1,     1,     1],\n",
       "           [    1,     1,     1,  ...,     1,     1,     1]]])],\n",
       " tensor([0, 0, 0, 0])]"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "bat[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.train_iter:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[    2,     6,     0,  ...,     1,     1,     1],\n",
       "         [    2,  2401,     0,  ...,     1,     1,     1],\n",
       "         [    2,   254, 10884,  ...,     1,     1,     1],\n",
       "         ...,\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1]],\n",
       "\n",
       "        [[    2,     4,   596,  ...,     1,     1,     1],\n",
       "         [    2,   223,     8,  ...,     1,     1,     1],\n",
       "         [    2,    31,     6,  ...,     1,     1,     1],\n",
       "         ...,\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1]],\n",
       "\n",
       "        [[    2,   286,  7310,  ...,     1,     1,     1],\n",
       "         [    2,   179, 13320,  ...,     6,  1675,     3],\n",
       "         [    2,     4,   152,  ...,     1,     1,     1],\n",
       "         ...,\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1]],\n",
       "\n",
       "        [[    2,  1153, 17330,  ...,     1,     1,     1],\n",
       "         [    2,     0,     0,  ...,     1,     1,     1],\n",
       "         [    2,   635,    19,  ...,     1,     1,     1],\n",
       "         ...,\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1]]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "i.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DLND_Dataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.fields = self.data.fields\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        source = (\n",
    "            self.fields[\"source\"].process([self.data.examples[idx].source]).squeeze()\n",
    "        )\n",
    "\n",
    "        target = (\n",
    "            self.fields[\"target\"].process([self.data.examples[idx].target]).squeeze()\n",
    "        )\n",
    "        label = self.fields[\"label\"].process([self.data.examples[idx].label]).squeeze()\n",
    "\n",
    "        return [source, target], label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = DLND_Dataset(data.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([tensor([[   2,    0,   18,  ...,    1,    1,    1],\n",
       "          [   2,  136,  939,  ...,    1,    1,    1],\n",
       "          [   2, 5873,  256,  ...,    1,    1,    1],\n",
       "          ...,\n",
       "          [   2,   10, 2178,  ...,    1,    1,    1],\n",
       "          [   2,  223,  240,  ...,    1,    1,    1],\n",
       "          [   1,    1,    1,  ...,    1,    1,    1]]),\n",
       "  tensor([[    2,  8261,     0,  ...,     3,     1,     1],\n",
       "          [    2,   302, 13160,  ...,     1,     1,     1],\n",
       "          [    2,  5900,     0,  ...,  5935,  9162,     3],\n",
       "          ...,\n",
       "          [    1,     1,     1,  ...,     1,     1,     1],\n",
       "          [    1,     1,     1,  ...,     1,     1,     1],\n",
       "          [    1,     1,     1,  ...,     1,     1,     1]])],\n",
       " tensor(0))"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "new_data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "data.train.fields[\"label\"].process([data.train.examples[1].label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-ca82b3ae088c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'Non-Novel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(5000):\n",
    "    if data.train.examples[i].label!='Non-Novel':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for i in data.train_iter:\n",
    "    print(i.label)\n",
    "    c+=1\n",
    "    if c==10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 1], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "source": [
    "i.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i.label for i in data.train.examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2243"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "a.count('Non-Novel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2038"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "a.count('Novel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}