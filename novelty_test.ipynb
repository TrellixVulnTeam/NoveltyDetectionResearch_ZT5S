{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.defaults import *\n",
    "from src.datasets.novelty import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_models_from_neptune(\"NLI-81\")\n",
    "field = load_field('NLI-81')\n",
    "# field = None\n",
    "\n",
    "\n",
    "dataset_conf = {'dataset': 'dlnd', 'max_num_sent': 60,\"sent_tokenizer\":\"spacy\",\"batch_size\":4,\"device\":\"cuda\"}\n",
    "# dataset_conf = {'dataset': 'dlnd', 'max_num_sent': 50,\"sent_tokenizer\":\"spacy\", \"tokenizer\":'spacy',\"max_len\":50,\"batch_size\":32,\"device\":\"cuda\"}\n",
    "model_conf = {'results_dir': 'results', 'device': 'cuda', 'dropout': 0.3, 'dataset': 'dlnd', 'hidden_size': 400, 'use_glove': False, \"max_num_sent\": 60}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dlnd(dataset_conf,sentence_field = field)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n[torchtext.data.batch.Batch of size 4]\n\t[.source]:[torch.cuda.LongTensor of size 4x60x50 (GPU 0)]\n\t[.target]:[torch.cuda.LongTensor of size 4x60x50 (GPU 0)]\n\t[.label]:[torch.cuda.LongTensor of size 4 (GPU 0)]\n"
     ]
    }
   ],
   "source": [
    "for i in data.train_iter:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.nli_models import *\n",
    "from src.model.novelty_models import *\n",
    "\n",
    "\n",
    "\n",
    "def load_encoder1(enc_data):\n",
    "    if enc_data['options'].get(\"attention_layer_param\",0)==0:\n",
    "        model = bilstm_snli(enc_data[\"options\"])\n",
    "    elif enc_data['options'].get(\"r\",0)==0:\n",
    "        model = attn_bilstm_snli(enc_data[\"options\"])\n",
    "    else:\n",
    "        model = struc_attn_snli(enc_data[\"options\"])\n",
    "    return model\n",
    "\n",
    "def load_encoder(_id):\n",
    "    model_path = os.path.join('./results/',_id,\"model.pt\")\n",
    "    model_data = torch.load(model_path)\n",
    "    return model_data\n",
    "\n",
    "model_data = load_encoder('NLI-81')\n",
    "\n",
    "model_conf[\"encoder_dim\"] = model_data[\"options\"][\"hidden_size\"]\n",
    "model_data['options'][\"use_glove\"] = False\n",
    "\n",
    "model = attn_bilstm_snli(model_data['options'])\n",
    "\n",
    "# dan = DAN(model_conf,model.encoder)\n",
    "\n",
    "# dan = dan.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = FusionClassifier_novelty(estimator=DAN,n_estimators=2,cuda=True,estimator_args={\"conf\":model_conf,\"encoder\":model.encoder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens.set_optimizer(\"Adam\", lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Log will be saved in '/content/NoveltyDetectionResearch/logs'.\n",
      "Start logging into file /content/NoveltyDetectionResearch/logs/ensemble_dev-2021_02_16_00_57.log...\n",
      "2021-02-16 00:57:49,585 - INFO: Epoch: 000 | Batch: 000 | Loss: 0.74848 | Correct: 1/4\n",
      "2021-02-16 00:58:13,109 - INFO: Epoch: 000 | Batch: 100 | Loss: 0.65103 | Correct: 3/4\n",
      "2021-02-16 00:58:36,602 - INFO: Epoch: 000 | Batch: 200 | Loss: 0.68120 | Correct: 2/4\n",
      "2021-02-16 00:59:00,119 - INFO: Epoch: 000 | Batch: 300 | Loss: 0.69258 | Correct: 3/4\n",
      "2021-02-16 00:59:23,627 - INFO: Epoch: 000 | Batch: 400 | Loss: 0.71224 | Correct: 0/4\n",
      "2021-02-16 00:59:47,094 - INFO: Epoch: 000 | Batch: 500 | Loss: 0.68313 | Correct: 3/4\n",
      "2021-02-16 01:00:10,633 - INFO: Epoch: 000 | Batch: 600 | Loss: 0.66220 | Correct: 3/4\n",
      "2021-02-16 01:00:34,178 - INFO: Epoch: 000 | Batch: 700 | Loss: 0.69657 | Correct: 2/4\n",
      "2021-02-16 01:00:57,686 - INFO: Epoch: 000 | Batch: 800 | Loss: 0.69475 | Correct: 2/4\n",
      "2021-02-16 01:01:21,197 - INFO: Epoch: 000 | Batch: 900 | Loss: 0.72893 | Correct: 1/4\n",
      "2021-02-16 01:01:44,696 - INFO: Epoch: 000 | Batch: 1000 | Loss: 0.69214 | Correct: 2/4\n",
      "2021-02-16 01:02:11,753 - INFO: Saving the model to `./FusionClassifier_novelty_DAN_2_ckpt.pth`\n",
      "2021-02-16 01:02:11,901 - INFO: Epoch: 000 | Validation Acc: 52.425 % | Historical Best: 52.425 %\n",
      "2021-02-16 01:02:12,148 - INFO: Epoch: 001 | Batch: 000 | Loss: 0.69024 | Correct: 2/4\n",
      "2021-02-16 01:02:35,683 - INFO: Epoch: 001 | Batch: 100 | Loss: 0.70058 | Correct: 2/4\n",
      "2021-02-16 01:02:59,225 - INFO: Epoch: 001 | Batch: 200 | Loss: 0.69476 | Correct: 2/4\n",
      "2021-02-16 01:03:22,746 - INFO: Epoch: 001 | Batch: 300 | Loss: 0.73657 | Correct: 0/4\n",
      "2021-02-16 01:03:46,310 - INFO: Epoch: 001 | Batch: 400 | Loss: 0.70703 | Correct: 1/4\n",
      "2021-02-16 01:04:09,892 - INFO: Epoch: 001 | Batch: 500 | Loss: 0.69469 | Correct: 2/4\n",
      "2021-02-16 01:04:33,408 - INFO: Epoch: 001 | Batch: 600 | Loss: 0.69283 | Correct: 2/4\n",
      "2021-02-16 01:04:56,917 - INFO: Epoch: 001 | Batch: 700 | Loss: 0.69565 | Correct: 2/4\n",
      "2021-02-16 01:05:20,431 - INFO: Epoch: 001 | Batch: 800 | Loss: 0.67527 | Correct: 3/4\n",
      "2021-02-16 01:05:43,991 - INFO: Epoch: 001 | Batch: 900 | Loss: 0.67526 | Correct: 3/4\n",
      "2021-02-16 01:06:07,386 - INFO: Epoch: 001 | Batch: 1000 | Loss: 0.75911 | Correct: 0/1\n",
      "2021-02-16 01:06:34,560 - INFO: Epoch: 001 | Validation Acc: 52.425 % | Historical Best: 52.425 %\n"
     ]
    }
   ],
   "source": [
    "train_loader = data.train_iter\n",
    "val_loader = data.val_iter\n",
    "set_logger(\"ensemble_dev\")\n",
    "ens.fit(train_loader,\n",
    "          epochs=2,\n",
    "          test_loader=val_loader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchensemble._base import BaseModule, torchensemble_model_doc\n",
    "from torchensemble.utils import io\n",
    "from torchensemble.utils import set_module\n",
    "from torchensemble.utils import operator as op\n",
    "from torchensemble.utils.logging import set_logger\n",
    "\n",
    "\n",
    "@torchensemble_model_doc(\"\"\"Implementation on the FusionClassifier.\"\"\", \"model\")\n",
    "class FusionClassifier_novelty(BaseModule):\n",
    "    def _forward(self, x, y):\n",
    "        \"\"\"\n",
    "        Implementation on the internal data forwarding in FusionClassifier.\n",
    "        \"\"\"\n",
    "        # Average\n",
    "        outputs = [estimator(x, y) for estimator in self.estimators_]\n",
    "        output = op.average(outputs)\n",
    "\n",
    "        return output\n",
    "\n",
    "    @torchensemble_model_doc(\n",
    "        \"\"\"Implementation on the data forwarding in FusionClassifier.\"\"\",\n",
    "        \"classifier_forward\",\n",
    "    )\n",
    "    def forward(self, x, y):\n",
    "        output = self._forward(x, y)\n",
    "        proba = F.softmax(output, dim=1)\n",
    "\n",
    "        return proba\n",
    "\n",
    "    @torchensemble_model_doc(\n",
    "        \"\"\"Set the attributes on optimizer for FusionClassifier.\"\"\", \"set_optimizer\"\n",
    "    )\n",
    "    def set_optimizer(self, optimizer_name, **kwargs):\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.optimizer_args = kwargs\n",
    "\n",
    "    @torchensemble_model_doc(\n",
    "        \"\"\"Set the attributes on scheduler for FusionClassifier.\"\"\", \"set_scheduler\"\n",
    "    )\n",
    "    def set_scheduler(self, scheduler_name, **kwargs):\n",
    "        self.scheduler_name = scheduler_name\n",
    "        self.scheduler_args = kwargs\n",
    "        self.use_scheduler_ = True\n",
    "\n",
    "    @torchensemble_model_doc(\n",
    "        \"\"\"Implementation on the training stage of FusionClassifier.\"\"\", \"fit\"\n",
    "    )\n",
    "    def fit(\n",
    "        self,\n",
    "        train_loader,\n",
    "        epochs=100,\n",
    "        log_interval=100,\n",
    "        test_loader=None,\n",
    "        save_model=True,\n",
    "        save_dir=None,\n",
    "    ):\n",
    "\n",
    "        # Instantiate base estimators and set attributes\n",
    "        for _ in range(self.n_estimators):\n",
    "            self.estimators_.append(self._make_estimator())\n",
    "        self._validate_parameters(epochs, log_interval)\n",
    "        self.n_outputs = 2\n",
    "        optimizer = set_module.set_optimizer(\n",
    "            self, self.optimizer_name, **self.optimizer_args\n",
    "        )\n",
    "\n",
    "        # Set the scheduler if `set_scheduler` was called before\n",
    "        if self.use_scheduler_:\n",
    "            self.scheduler_ = set_module.set_scheduler(\n",
    "                optimizer, self.scheduler_name, **self.scheduler_args\n",
    "            )\n",
    "\n",
    "        # Utils\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        best_acc = 0.0\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            for batch_idx, (batch) in enumerate(train_loader):\n",
    "\n",
    "                source, target, label = (\n",
    "                    batch.source.to(self.device),\n",
    "                    batch.target.to(self.device),\n",
    "                    batch.label.to(self.device),\n",
    "                )\n",
    "\n",
    "                # data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = self._forward(source, target)\n",
    "                loss = criterion(output, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Print training status\n",
    "                if batch_idx % log_interval == 0:\n",
    "                    with torch.no_grad():\n",
    "                        _, predicted = torch.max(output.data, 1)\n",
    "                        correct = (predicted == label).sum().item()\n",
    "\n",
    "                        msg = (\n",
    "                            \"Epoch: {:03d} | Batch: {:03d} | Loss:\"\n",
    "                            \" {:.5f} | Correct: {:d}/{:d}\"\n",
    "                        )\n",
    "                        self.logger.info(\n",
    "                            msg.format(epoch, batch_idx, loss, correct, label.size(0))\n",
    "                        )\n",
    "\n",
    "            # Validation\n",
    "            if test_loader:\n",
    "                self.eval()\n",
    "                with torch.no_grad():\n",
    "                    correct = 0\n",
    "                    total = 0\n",
    "                    for _, (batch) in enumerate(test_loader):\n",
    "\n",
    "                        source, target, label = (\n",
    "                            batch.source.to(self.device),\n",
    "                            batch.target.to(self.device),\n",
    "                            batch.label.to(self.device),\n",
    "                        )\n",
    "\n",
    "                        output = self.forward(source, target)\n",
    "                        _, predicted = torch.max(output.data, 1)\n",
    "                        correct += (predicted == label).sum().item()\n",
    "                        total += label.size(0)\n",
    "                    acc = 100 * correct / total\n",
    "\n",
    "                    if acc > best_acc:\n",
    "                        best_acc = acc\n",
    "                        if save_model:\n",
    "                            io.save(self, save_dir, self.logger)\n",
    "\n",
    "                    msg = (\n",
    "                        \"Epoch: {:03d} | Validation Acc: {:.3f}\"\n",
    "                        \" % | Historical Best: {:.3f} %\"\n",
    "                    )\n",
    "                    self.logger.info(msg.format(epoch, acc, best_acc))\n",
    "\n",
    "            # Update the scheduler\n",
    "            if hasattr(self, \"scheduler_\"):\n",
    "                self.scheduler_.step()\n",
    "\n",
    "        if save_model and not test_loader:\n",
    "            io.save(self, save_dir, self.logger)\n",
    "\n",
    "    @torchensemble_model_doc(\n",
    "        \"\"\"Implementation on the evaluating stage of FusionClassifier.\"\"\",\n",
    "        \"classifier_predict\",\n",
    "    )\n",
    "    def predict(self, test_loader):\n",
    "        self.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for _, (batch) in enumerate(test_loader):\n",
    "            source, target, label = (\n",
    "                batch.source.to(self.device),\n",
    "                batch.target.to(self.device),\n",
    "                batch.label.to(self.device),\n",
    "            )\n",
    "            output = self.forward(source,target)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += (predicted == label).sum().item()\n",
    "            total += label.size(0)\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "\n",
    "        return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../Dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5065ba1c99594a65a4402fb269baba27"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ../../Dataset/MNIST/raw/train-images-idx3-ubyte.gz to ../../Dataset/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../Dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfeabe4a10744e07806f26faa641d809"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ../../Dataset/MNIST/raw/train-labels-idx1-ubyte.gz to ../../Dataset/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../Dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69810fac352f4320b3ca81f37aec4d1f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ../../Dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../Dataset/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../Dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb62aff5749447ed827b255fe77f57d9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ../../Dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../Dataset/MNIST/raw\n",
      "Processing...\n",
      "Done!\n",
      "\n",
      "\n",
      "\n",
      "Log will be saved in '/content/NoveltyDetectionResearch/logs'.\n",
      "Create folder 'logs/'\n",
      "Start logging into file /content/NoveltyDetectionResearch/logs/classification_mnist_mlp-2021_02_15_21_55.log...\n",
      "Estimator: 000 | Epoch: 000 | Batch: 000 | Loss: 2.30158 | Correct: 18/128\n",
      "Estimator: 000 | Epoch: 000 | Batch: 100 | Loss: 0.51601 | Correct: 105/128\n",
      "Estimator: 000 | Epoch: 000 | Batch: 200 | Loss: 0.33963 | Correct: 113/128\n",
      "Estimator: 000 | Epoch: 000 | Batch: 300 | Loss: 0.33299 | Correct: 119/128\n",
      "Estimator: 000 | Epoch: 000 | Batch: 400 | Loss: 0.18297 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 000 | Loss: 2.31871 | Correct: 13/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 100 | Loss: 0.47951 | Correct: 108/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 200 | Loss: 0.47146 | Correct: 108/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 300 | Loss: 0.26730 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 400 | Loss: 0.29705 | Correct: 118/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 000 | Loss: 2.28342 | Correct: 22/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 100 | Loss: 0.43572 | Correct: 118/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 200 | Loss: 0.39784 | Correct: 112/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 300 | Loss: 0.25536 | Correct: 118/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 400 | Loss: 0.30465 | Correct: 119/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 000 | Loss: 2.32273 | Correct: 12/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 100 | Loss: 0.57814 | Correct: 104/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 200 | Loss: 0.44676 | Correct: 109/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 300 | Loss: 0.27341 | Correct: 118/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 400 | Loss: 0.21910 | Correct: 119/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 000 | Loss: 2.32285 | Correct: 11/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 100 | Loss: 0.50080 | Correct: 111/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 200 | Loss: 0.37689 | Correct: 116/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 300 | Loss: 0.25339 | Correct: 118/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 400 | Loss: 0.38014 | Correct: 115/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 000 | Loss: 2.30575 | Correct: 18/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 100 | Loss: 0.35796 | Correct: 116/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 200 | Loss: 0.34261 | Correct: 117/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 300 | Loss: 0.34955 | Correct: 113/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 400 | Loss: 0.24513 | Correct: 116/128\n",
      "Estimator: 006 | Epoch: 000 | Batch: 000 | Loss: 2.31007 | Correct: 11/128\n",
      "Estimator: 006 | Epoch: 000 | Batch: 100 | Loss: 0.31933 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 000 | Batch: 200 | Loss: 0.30226 | Correct: 118/128\n",
      "Estimator: 006 | Epoch: 000 | Batch: 300 | Loss: 0.34624 | Correct: 114/128\n",
      "Estimator: 006 | Epoch: 000 | Batch: 400 | Loss: 0.28026 | Correct: 117/128\n",
      "Estimator: 007 | Epoch: 000 | Batch: 000 | Loss: 2.30595 | Correct: 16/128\n",
      "Estimator: 007 | Epoch: 000 | Batch: 100 | Loss: 0.35490 | Correct: 117/128\n",
      "Estimator: 007 | Epoch: 000 | Batch: 200 | Loss: 0.26915 | Correct: 115/128\n",
      "Estimator: 007 | Epoch: 000 | Batch: 300 | Loss: 0.39017 | Correct: 116/128\n",
      "Estimator: 007 | Epoch: 000 | Batch: 400 | Loss: 0.21074 | Correct: 117/128\n",
      "Estimator: 008 | Epoch: 000 | Batch: 000 | Loss: 2.32907 | Correct: 10/128\n",
      "Estimator: 008 | Epoch: 000 | Batch: 100 | Loss: 0.49228 | Correct: 105/128\n",
      "Estimator: 008 | Epoch: 000 | Batch: 200 | Loss: 0.39667 | Correct: 111/128\n",
      "Estimator: 008 | Epoch: 000 | Batch: 300 | Loss: 0.33917 | Correct: 113/128\n",
      "Estimator: 008 | Epoch: 000 | Batch: 400 | Loss: 0.21717 | Correct: 118/128\n",
      "Estimator: 009 | Epoch: 000 | Batch: 000 | Loss: 2.32768 | Correct: 9/128\n",
      "Estimator: 009 | Epoch: 000 | Batch: 100 | Loss: 0.60169 | Correct: 102/128\n",
      "Estimator: 009 | Epoch: 000 | Batch: 200 | Loss: 0.32673 | Correct: 116/128\n",
      "Estimator: 009 | Epoch: 000 | Batch: 300 | Loss: 0.26448 | Correct: 120/128\n",
      "Estimator: 009 | Epoch: 000 | Batch: 400 | Loss: 0.18744 | Correct: 122/128\n",
      "2021-02-15 21:56:47,797 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2021-02-15 21:56:47,809 - INFO: Epoch: 000 | Validation Acc: 95.160 % | Historical Best: 95.160 %\n",
      "Estimator: 000 | Epoch: 001 | Batch: 000 | Loss: 0.32784 | Correct: 114/128\n",
      "Estimator: 000 | Epoch: 001 | Batch: 100 | Loss: 0.24209 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 001 | Batch: 200 | Loss: 0.22252 | Correct: 118/128\n",
      "Estimator: 000 | Epoch: 001 | Batch: 300 | Loss: 0.31285 | Correct: 116/128\n",
      "Estimator: 000 | Epoch: 001 | Batch: 400 | Loss: 0.23298 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 001 | Batch: 000 | Loss: 0.14999 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 001 | Batch: 100 | Loss: 0.22867 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 001 | Batch: 200 | Loss: 0.23588 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 001 | Batch: 300 | Loss: 0.25868 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 001 | Batch: 400 | Loss: 0.20427 | Correct: 118/128\n",
      "Estimator: 002 | Epoch: 001 | Batch: 000 | Loss: 0.29090 | Correct: 116/128\n",
      "Estimator: 002 | Epoch: 001 | Batch: 100 | Loss: 0.29713 | Correct: 116/128\n",
      "Estimator: 002 | Epoch: 001 | Batch: 200 | Loss: 0.21217 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 001 | Batch: 300 | Loss: 0.30041 | Correct: 116/128\n",
      "Estimator: 002 | Epoch: 001 | Batch: 400 | Loss: 0.23407 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 001 | Batch: 000 | Loss: 0.15221 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 001 | Batch: 100 | Loss: 0.31887 | Correct: 117/128\n",
      "Estimator: 003 | Epoch: 001 | Batch: 200 | Loss: 0.18371 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 001 | Batch: 300 | Loss: 0.39258 | Correct: 109/128\n",
      "Estimator: 003 | Epoch: 001 | Batch: 400 | Loss: 0.26908 | Correct: 116/128\n",
      "Estimator: 004 | Epoch: 001 | Batch: 000 | Loss: 0.19404 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 001 | Batch: 100 | Loss: 0.26562 | Correct: 117/128\n",
      "Estimator: 004 | Epoch: 001 | Batch: 200 | Loss: 0.25965 | Correct: 118/128\n",
      "Estimator: 004 | Epoch: 001 | Batch: 300 | Loss: 0.14323 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 001 | Batch: 400 | Loss: 0.18464 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 001 | Batch: 000 | Loss: 0.20693 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 001 | Batch: 100 | Loss: 0.24227 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 001 | Batch: 200 | Loss: 0.28051 | Correct: 117/128\n",
      "Estimator: 005 | Epoch: 001 | Batch: 300 | Loss: 0.15506 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 001 | Batch: 400 | Loss: 0.15420 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 001 | Batch: 000 | Loss: 0.21641 | Correct: 119/128\n",
      "Estimator: 006 | Epoch: 001 | Batch: 100 | Loss: 0.16272 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 001 | Batch: 200 | Loss: 0.13251 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 001 | Batch: 300 | Loss: 0.25891 | Correct: 119/128\n",
      "Estimator: 006 | Epoch: 001 | Batch: 400 | Loss: 0.19059 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 001 | Batch: 000 | Loss: 0.24150 | Correct: 118/128\n",
      "Estimator: 007 | Epoch: 001 | Batch: 100 | Loss: 0.34176 | Correct: 118/128\n",
      "Estimator: 007 | Epoch: 001 | Batch: 200 | Loss: 0.16919 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 001 | Batch: 300 | Loss: 0.15793 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 001 | Batch: 400 | Loss: 0.14383 | Correct: 120/128\n",
      "Estimator: 008 | Epoch: 001 | Batch: 000 | Loss: 0.29640 | Correct: 115/128\n",
      "Estimator: 008 | Epoch: 001 | Batch: 100 | Loss: 0.40681 | Correct: 111/128\n",
      "Estimator: 008 | Epoch: 001 | Batch: 200 | Loss: 0.29245 | Correct: 117/128\n",
      "Estimator: 008 | Epoch: 001 | Batch: 300 | Loss: 0.31544 | Correct: 119/128\n",
      "Estimator: 008 | Epoch: 001 | Batch: 400 | Loss: 0.32120 | Correct: 114/128\n",
      "Estimator: 009 | Epoch: 001 | Batch: 000 | Loss: 0.18687 | Correct: 119/128\n",
      "Estimator: 009 | Epoch: 001 | Batch: 100 | Loss: 0.20180 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 001 | Batch: 200 | Loss: 0.27477 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 001 | Batch: 300 | Loss: 0.12629 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 001 | Batch: 400 | Loss: 0.17884 | Correct: 121/128\n",
      "2021-02-15 21:58:28,962 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2021-02-15 21:58:28,974 - INFO: Epoch: 001 | Validation Acc: 96.350 % | Historical Best: 96.350 %\n",
      "Estimator: 000 | Epoch: 002 | Batch: 000 | Loss: 0.29264 | Correct: 112/128\n",
      "Estimator: 000 | Epoch: 002 | Batch: 100 | Loss: 0.22779 | Correct: 119/128\n",
      "Estimator: 000 | Epoch: 002 | Batch: 200 | Loss: 0.16147 | Correct: 120/128\n",
      "Estimator: 000 | Epoch: 002 | Batch: 300 | Loss: 0.18217 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 002 | Batch: 400 | Loss: 0.24060 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 002 | Batch: 000 | Loss: 0.29056 | Correct: 116/128\n",
      "Estimator: 001 | Epoch: 002 | Batch: 100 | Loss: 0.19272 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 002 | Batch: 200 | Loss: 0.18230 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 002 | Batch: 300 | Loss: 0.22204 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 002 | Batch: 400 | Loss: 0.26576 | Correct: 118/128\n",
      "Estimator: 002 | Epoch: 002 | Batch: 000 | Loss: 0.31451 | Correct: 114/128\n",
      "Estimator: 002 | Epoch: 002 | Batch: 100 | Loss: 0.16690 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 002 | Batch: 200 | Loss: 0.08300 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 002 | Batch: 300 | Loss: 0.19371 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 002 | Batch: 400 | Loss: 0.15713 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 002 | Batch: 000 | Loss: 0.14329 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 002 | Batch: 100 | Loss: 0.14350 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 002 | Batch: 200 | Loss: 0.29194 | Correct: 116/128\n",
      "Estimator: 003 | Epoch: 002 | Batch: 300 | Loss: 0.10256 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 002 | Batch: 400 | Loss: 0.15382 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 002 | Batch: 000 | Loss: 0.14294 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 002 | Batch: 100 | Loss: 0.14218 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 002 | Batch: 200 | Loss: 0.15857 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 002 | Batch: 300 | Loss: 0.09430 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 002 | Batch: 400 | Loss: 0.20556 | Correct: 117/128\n",
      "Estimator: 005 | Epoch: 002 | Batch: 000 | Loss: 0.21840 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 002 | Batch: 100 | Loss: 0.14943 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 002 | Batch: 200 | Loss: 0.15958 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 002 | Batch: 300 | Loss: 0.14256 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 002 | Batch: 400 | Loss: 0.15492 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 002 | Batch: 000 | Loss: 0.27306 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 002 | Batch: 100 | Loss: 0.24646 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 002 | Batch: 200 | Loss: 0.17662 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 002 | Batch: 300 | Loss: 0.26768 | Correct: 116/128\n",
      "Estimator: 006 | Epoch: 002 | Batch: 400 | Loss: 0.15027 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 002 | Batch: 000 | Loss: 0.21520 | Correct: 118/128\n",
      "Estimator: 007 | Epoch: 002 | Batch: 100 | Loss: 0.33078 | Correct: 113/128\n",
      "Estimator: 007 | Epoch: 002 | Batch: 200 | Loss: 0.08956 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 002 | Batch: 300 | Loss: 0.13195 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 002 | Batch: 400 | Loss: 0.22137 | Correct: 117/128\n",
      "Estimator: 008 | Epoch: 002 | Batch: 000 | Loss: 0.19731 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 002 | Batch: 100 | Loss: 0.16582 | Correct: 120/128\n",
      "Estimator: 008 | Epoch: 002 | Batch: 200 | Loss: 0.30512 | Correct: 118/128\n",
      "Estimator: 008 | Epoch: 002 | Batch: 300 | Loss: 0.17191 | Correct: 120/128\n",
      "Estimator: 008 | Epoch: 002 | Batch: 400 | Loss: 0.27978 | Correct: 119/128\n",
      "Estimator: 009 | Epoch: 002 | Batch: 000 | Loss: 0.20217 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 002 | Batch: 100 | Loss: 0.23275 | Correct: 120/128\n",
      "Estimator: 009 | Epoch: 002 | Batch: 200 | Loss: 0.18068 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 002 | Batch: 300 | Loss: 0.13375 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 002 | Batch: 400 | Loss: 0.24272 | Correct: 120/128\n",
      "2021-02-15 22:00:11,006 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2021-02-15 22:00:11,019 - INFO: Epoch: 002 | Validation Acc: 96.850 % | Historical Best: 96.850 %\n",
      "Estimator: 000 | Epoch: 003 | Batch: 000 | Loss: 0.16638 | Correct: 120/128\n",
      "Estimator: 000 | Epoch: 003 | Batch: 100 | Loss: 0.12383 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 003 | Batch: 200 | Loss: 0.21208 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 003 | Batch: 300 | Loss: 0.14682 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 003 | Batch: 400 | Loss: 0.13112 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 003 | Batch: 000 | Loss: 0.15071 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 003 | Batch: 100 | Loss: 0.20131 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 003 | Batch: 200 | Loss: 0.13040 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 003 | Batch: 300 | Loss: 0.20305 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 003 | Batch: 400 | Loss: 0.15681 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 003 | Batch: 000 | Loss: 0.20457 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 003 | Batch: 100 | Loss: 0.17977 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 003 | Batch: 200 | Loss: 0.15902 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 003 | Batch: 300 | Loss: 0.17553 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 003 | Batch: 400 | Loss: 0.09389 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 003 | Batch: 000 | Loss: 0.18653 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 003 | Batch: 100 | Loss: 0.09331 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 003 | Batch: 200 | Loss: 0.21194 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 003 | Batch: 300 | Loss: 0.18390 | Correct: 117/128\n",
      "Estimator: 003 | Epoch: 003 | Batch: 400 | Loss: 0.17889 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 003 | Batch: 000 | Loss: 0.17566 | Correct: 119/128\n",
      "Estimator: 004 | Epoch: 003 | Batch: 100 | Loss: 0.31235 | Correct: 119/128\n",
      "Estimator: 004 | Epoch: 003 | Batch: 200 | Loss: 0.14229 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 003 | Batch: 300 | Loss: 0.17261 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 003 | Batch: 400 | Loss: 0.15815 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 003 | Batch: 000 | Loss: 0.22396 | Correct: 119/128\n",
      "Estimator: 005 | Epoch: 003 | Batch: 100 | Loss: 0.21725 | Correct: 119/128\n",
      "Estimator: 005 | Epoch: 003 | Batch: 200 | Loss: 0.20622 | Correct: 119/128\n",
      "Estimator: 005 | Epoch: 003 | Batch: 300 | Loss: 0.21722 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 003 | Batch: 400 | Loss: 0.19077 | Correct: 119/128\n",
      "Estimator: 006 | Epoch: 003 | Batch: 000 | Loss: 0.22471 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 003 | Batch: 100 | Loss: 0.30157 | Correct: 118/128\n",
      "Estimator: 006 | Epoch: 003 | Batch: 200 | Loss: 0.14706 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 003 | Batch: 300 | Loss: 0.15492 | Correct: 119/128\n",
      "Estimator: 006 | Epoch: 003 | Batch: 400 | Loss: 0.18909 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 003 | Batch: 000 | Loss: 0.19516 | Correct: 118/128\n",
      "Estimator: 007 | Epoch: 003 | Batch: 100 | Loss: 0.16172 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 003 | Batch: 200 | Loss: 0.21096 | Correct: 118/128\n",
      "Estimator: 007 | Epoch: 003 | Batch: 300 | Loss: 0.15101 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 003 | Batch: 400 | Loss: 0.20928 | Correct: 118/128\n",
      "Estimator: 008 | Epoch: 003 | Batch: 000 | Loss: 0.19178 | Correct: 118/128\n",
      "Estimator: 008 | Epoch: 003 | Batch: 100 | Loss: 0.14702 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 003 | Batch: 200 | Loss: 0.17217 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 003 | Batch: 300 | Loss: 0.15615 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 003 | Batch: 400 | Loss: 0.15094 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 003 | Batch: 000 | Loss: 0.20043 | Correct: 120/128\n",
      "Estimator: 009 | Epoch: 003 | Batch: 100 | Loss: 0.18232 | Correct: 120/128\n",
      "Estimator: 009 | Epoch: 003 | Batch: 200 | Loss: 0.16830 | Correct: 120/128\n",
      "Estimator: 009 | Epoch: 003 | Batch: 300 | Loss: 0.08977 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 003 | Batch: 400 | Loss: 0.21382 | Correct: 120/128\n",
      "2021-02-15 22:01:51,675 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2021-02-15 22:01:51,687 - INFO: Epoch: 003 | Validation Acc: 97.140 % | Historical Best: 97.140 %\n",
      "Estimator: 000 | Epoch: 004 | Batch: 000 | Loss: 0.15010 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 004 | Batch: 100 | Loss: 0.11298 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 004 | Batch: 200 | Loss: 0.12916 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 004 | Batch: 300 | Loss: 0.29518 | Correct: 115/128\n",
      "Estimator: 000 | Epoch: 004 | Batch: 400 | Loss: 0.28791 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 004 | Batch: 000 | Loss: 0.19915 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 004 | Batch: 100 | Loss: 0.13966 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 004 | Batch: 200 | Loss: 0.16909 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 004 | Batch: 300 | Loss: 0.11053 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 004 | Batch: 400 | Loss: 0.22389 | Correct: 119/128\n",
      "Estimator: 002 | Epoch: 004 | Batch: 000 | Loss: 0.12943 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 004 | Batch: 100 | Loss: 0.21106 | Correct: 119/128\n",
      "Estimator: 002 | Epoch: 004 | Batch: 200 | Loss: 0.20037 | Correct: 119/128\n",
      "Estimator: 002 | Epoch: 004 | Batch: 300 | Loss: 0.12516 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 004 | Batch: 400 | Loss: 0.10930 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 004 | Batch: 000 | Loss: 0.21145 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 004 | Batch: 100 | Loss: 0.13974 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 004 | Batch: 200 | Loss: 0.26540 | Correct: 118/128\n",
      "Estimator: 003 | Epoch: 004 | Batch: 300 | Loss: 0.14470 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 004 | Batch: 400 | Loss: 0.10558 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 004 | Batch: 000 | Loss: 0.15481 | Correct: 119/128\n",
      "Estimator: 004 | Epoch: 004 | Batch: 100 | Loss: 0.11944 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 004 | Batch: 200 | Loss: 0.20946 | Correct: 119/128\n",
      "Estimator: 004 | Epoch: 004 | Batch: 300 | Loss: 0.08738 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 004 | Batch: 400 | Loss: 0.14526 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 004 | Batch: 000 | Loss: 0.12735 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 004 | Batch: 100 | Loss: 0.15258 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 004 | Batch: 200 | Loss: 0.15965 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 004 | Batch: 300 | Loss: 0.16976 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 004 | Batch: 400 | Loss: 0.12727 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 004 | Batch: 000 | Loss: 0.20117 | Correct: 117/128\n",
      "Estimator: 006 | Epoch: 004 | Batch: 100 | Loss: 0.18074 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 004 | Batch: 200 | Loss: 0.27132 | Correct: 118/128\n",
      "Estimator: 006 | Epoch: 004 | Batch: 300 | Loss: 0.11222 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 004 | Batch: 400 | Loss: 0.14649 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 004 | Batch: 000 | Loss: 0.15854 | Correct: 120/128\n",
      "Estimator: 007 | Epoch: 004 | Batch: 100 | Loss: 0.12307 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 004 | Batch: 200 | Loss: 0.26126 | Correct: 119/128\n",
      "Estimator: 007 | Epoch: 004 | Batch: 300 | Loss: 0.20908 | Correct: 120/128\n",
      "Estimator: 007 | Epoch: 004 | Batch: 400 | Loss: 0.12062 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 004 | Batch: 000 | Loss: 0.18068 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 004 | Batch: 100 | Loss: 0.19696 | Correct: 118/128\n",
      "Estimator: 008 | Epoch: 004 | Batch: 200 | Loss: 0.07493 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 004 | Batch: 300 | Loss: 0.17021 | Correct: 120/128\n",
      "Estimator: 008 | Epoch: 004 | Batch: 400 | Loss: 0.12102 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 004 | Batch: 000 | Loss: 0.17378 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 004 | Batch: 100 | Loss: 0.07934 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 004 | Batch: 200 | Loss: 0.16417 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 004 | Batch: 300 | Loss: 0.26156 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 004 | Batch: 400 | Loss: 0.17896 | Correct: 123/128\n",
      "2021-02-15 22:03:32,453 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2021-02-15 22:03:32,467 - INFO: Epoch: 004 | Validation Acc: 97.350 % | Historical Best: 97.350 %\n",
      "Estimator: 000 | Epoch: 005 | Batch: 000 | Loss: 0.20216 | Correct: 120/128\n",
      "Estimator: 000 | Epoch: 005 | Batch: 100 | Loss: 0.16879 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 005 | Batch: 200 | Loss: 0.08920 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 005 | Batch: 300 | Loss: 0.17225 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 005 | Batch: 400 | Loss: 0.17136 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 005 | Batch: 000 | Loss: 0.18491 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 005 | Batch: 100 | Loss: 0.21594 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 005 | Batch: 200 | Loss: 0.08337 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 005 | Batch: 300 | Loss: 0.10570 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 005 | Batch: 400 | Loss: 0.21056 | Correct: 119/128\n",
      "Estimator: 002 | Epoch: 005 | Batch: 000 | Loss: 0.18777 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 005 | Batch: 100 | Loss: 0.22493 | Correct: 119/128\n",
      "Estimator: 002 | Epoch: 005 | Batch: 200 | Loss: 0.17125 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 005 | Batch: 300 | Loss: 0.09080 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 005 | Batch: 400 | Loss: 0.10902 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 005 | Batch: 000 | Loss: 0.17251 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 005 | Batch: 100 | Loss: 0.11189 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 005 | Batch: 200 | Loss: 0.10218 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 005 | Batch: 300 | Loss: 0.11834 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 005 | Batch: 400 | Loss: 0.14081 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 005 | Batch: 000 | Loss: 0.19175 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 005 | Batch: 100 | Loss: 0.08607 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 005 | Batch: 200 | Loss: 0.15535 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 005 | Batch: 300 | Loss: 0.22181 | Correct: 119/128\n",
      "Estimator: 004 | Epoch: 005 | Batch: 400 | Loss: 0.17151 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 005 | Batch: 000 | Loss: 0.12117 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 005 | Batch: 100 | Loss: 0.13637 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 005 | Batch: 200 | Loss: 0.05119 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 005 | Batch: 300 | Loss: 0.14260 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 005 | Batch: 400 | Loss: 0.13376 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 005 | Batch: 000 | Loss: 0.14958 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 005 | Batch: 100 | Loss: 0.15903 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 005 | Batch: 200 | Loss: 0.10568 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 005 | Batch: 300 | Loss: 0.12888 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 005 | Batch: 400 | Loss: 0.09155 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 005 | Batch: 000 | Loss: 0.06130 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 005 | Batch: 100 | Loss: 0.09363 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 005 | Batch: 200 | Loss: 0.19197 | Correct: 119/128\n",
      "Estimator: 007 | Epoch: 005 | Batch: 300 | Loss: 0.12549 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 005 | Batch: 400 | Loss: 0.12466 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 005 | Batch: 000 | Loss: 0.12621 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 005 | Batch: 100 | Loss: 0.20928 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 005 | Batch: 200 | Loss: 0.17179 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 005 | Batch: 300 | Loss: 0.16257 | Correct: 119/128\n",
      "Estimator: 008 | Epoch: 005 | Batch: 400 | Loss: 0.08791 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 005 | Batch: 000 | Loss: 0.15024 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 005 | Batch: 100 | Loss: 0.12535 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 005 | Batch: 200 | Loss: 0.15161 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 005 | Batch: 300 | Loss: 0.21375 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 005 | Batch: 400 | Loss: 0.13996 | Correct: 120/128\n",
      "2021-02-15 22:05:12,576 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2021-02-15 22:05:12,590 - INFO: Epoch: 005 | Validation Acc: 97.470 % | Historical Best: 97.470 %\n",
      "Estimator: 000 | Epoch: 006 | Batch: 000 | Loss: 0.18395 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 006 | Batch: 100 | Loss: 0.16883 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 006 | Batch: 200 | Loss: 0.09707 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 006 | Batch: 300 | Loss: 0.27390 | Correct: 120/128\n",
      "Estimator: 000 | Epoch: 006 | Batch: 400 | Loss: 0.12745 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 006 | Batch: 000 | Loss: 0.14280 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 006 | Batch: 100 | Loss: 0.09756 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 006 | Batch: 200 | Loss: 0.22149 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 006 | Batch: 300 | Loss: 0.14206 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 006 | Batch: 400 | Loss: 0.08940 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 006 | Batch: 000 | Loss: 0.14291 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 006 | Batch: 100 | Loss: 0.22705 | Correct: 118/128\n",
      "Estimator: 002 | Epoch: 006 | Batch: 200 | Loss: 0.16351 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 006 | Batch: 300 | Loss: 0.16676 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 006 | Batch: 400 | Loss: 0.12112 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 006 | Batch: 000 | Loss: 0.13633 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 006 | Batch: 100 | Loss: 0.08675 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 006 | Batch: 200 | Loss: 0.09840 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 006 | Batch: 300 | Loss: 0.21219 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 006 | Batch: 400 | Loss: 0.04671 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 006 | Batch: 000 | Loss: 0.22114 | Correct: 119/128\n",
      "Estimator: 004 | Epoch: 006 | Batch: 100 | Loss: 0.20692 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 006 | Batch: 200 | Loss: 0.10590 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 006 | Batch: 300 | Loss: 0.16564 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 006 | Batch: 400 | Loss: 0.15797 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 006 | Batch: 000 | Loss: 0.08988 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 006 | Batch: 100 | Loss: 0.13301 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 006 | Batch: 200 | Loss: 0.15665 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 006 | Batch: 300 | Loss: 0.18983 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 006 | Batch: 400 | Loss: 0.14386 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 006 | Batch: 000 | Loss: 0.16160 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 006 | Batch: 100 | Loss: 0.10381 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 006 | Batch: 200 | Loss: 0.20225 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 006 | Batch: 300 | Loss: 0.09754 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 006 | Batch: 400 | Loss: 0.12791 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 006 | Batch: 000 | Loss: 0.20604 | Correct: 120/128\n",
      "Estimator: 007 | Epoch: 006 | Batch: 100 | Loss: 0.11495 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 006 | Batch: 200 | Loss: 0.06523 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 006 | Batch: 300 | Loss: 0.17141 | Correct: 119/128\n",
      "Estimator: 007 | Epoch: 006 | Batch: 400 | Loss: 0.21112 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 006 | Batch: 000 | Loss: 0.14813 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 006 | Batch: 100 | Loss: 0.14109 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 006 | Batch: 200 | Loss: 0.04252 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 006 | Batch: 300 | Loss: 0.16510 | Correct: 120/128\n",
      "Estimator: 008 | Epoch: 006 | Batch: 400 | Loss: 0.11097 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 006 | Batch: 000 | Loss: 0.14261 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 006 | Batch: 100 | Loss: 0.09388 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 006 | Batch: 200 | Loss: 0.22674 | Correct: 120/128\n",
      "Estimator: 009 | Epoch: 006 | Batch: 300 | Loss: 0.06646 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 006 | Batch: 400 | Loss: 0.12125 | Correct: 124/128\n",
      "2021-02-15 22:06:52,644 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2021-02-15 22:06:52,659 - INFO: Epoch: 006 | Validation Acc: 97.560 % | Historical Best: 97.560 %\n",
      "Estimator: 000 | Epoch: 007 | Batch: 000 | Loss: 0.08548 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 007 | Batch: 100 | Loss: 0.16659 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 007 | Batch: 200 | Loss: 0.12489 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 007 | Batch: 300 | Loss: 0.31257 | Correct: 115/128\n",
      "Estimator: 000 | Epoch: 007 | Batch: 400 | Loss: 0.13805 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 007 | Batch: 000 | Loss: 0.05080 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 007 | Batch: 100 | Loss: 0.04088 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 007 | Batch: 200 | Loss: 0.16869 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 007 | Batch: 300 | Loss: 0.07168 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 007 | Batch: 400 | Loss: 0.35499 | Correct: 118/128\n",
      "Estimator: 002 | Epoch: 007 | Batch: 000 | Loss: 0.24131 | Correct: 116/128\n",
      "Estimator: 002 | Epoch: 007 | Batch: 100 | Loss: 0.15434 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 007 | Batch: 200 | Loss: 0.15651 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 007 | Batch: 300 | Loss: 0.09532 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 007 | Batch: 400 | Loss: 0.13656 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 007 | Batch: 000 | Loss: 0.11897 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 007 | Batch: 100 | Loss: 0.12358 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 007 | Batch: 200 | Loss: 0.16422 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 007 | Batch: 300 | Loss: 0.04901 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 007 | Batch: 400 | Loss: 0.10063 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 007 | Batch: 000 | Loss: 0.10583 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 007 | Batch: 100 | Loss: 0.12458 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 007 | Batch: 200 | Loss: 0.14285 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 007 | Batch: 300 | Loss: 0.15658 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 007 | Batch: 400 | Loss: 0.10865 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 007 | Batch: 000 | Loss: 0.11888 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 007 | Batch: 100 | Loss: 0.17525 | Correct: 119/128\n",
      "Estimator: 005 | Epoch: 007 | Batch: 200 | Loss: 0.20470 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 007 | Batch: 300 | Loss: 0.15409 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 007 | Batch: 400 | Loss: 0.17068 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 007 | Batch: 000 | Loss: 0.06122 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 007 | Batch: 100 | Loss: 0.14642 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 007 | Batch: 200 | Loss: 0.14700 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 007 | Batch: 300 | Loss: 0.29351 | Correct: 116/128\n",
      "Estimator: 006 | Epoch: 007 | Batch: 400 | Loss: 0.24215 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 007 | Batch: 000 | Loss: 0.08457 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 007 | Batch: 100 | Loss: 0.18969 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 007 | Batch: 200 | Loss: 0.07526 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 007 | Batch: 300 | Loss: 0.12965 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 007 | Batch: 400 | Loss: 0.07469 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 007 | Batch: 000 | Loss: 0.07594 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 007 | Batch: 100 | Loss: 0.11918 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 007 | Batch: 200 | Loss: 0.12102 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 007 | Batch: 300 | Loss: 0.17655 | Correct: 119/128\n",
      "Estimator: 008 | Epoch: 007 | Batch: 400 | Loss: 0.06549 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 007 | Batch: 000 | Loss: 0.23834 | Correct: 119/128\n",
      "Estimator: 009 | Epoch: 007 | Batch: 100 | Loss: 0.14737 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 007 | Batch: 200 | Loss: 0.10931 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 007 | Batch: 300 | Loss: 0.11494 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 007 | Batch: 400 | Loss: 0.08553 | Correct: 122/128\n",
      "2021-02-15 22:08:33,119 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2021-02-15 22:08:33,133 - INFO: Epoch: 007 | Validation Acc: 97.580 % | Historical Best: 97.580 %\n",
      "Estimator: 000 | Epoch: 008 | Batch: 000 | Loss: 0.15987 | Correct: 119/128\n",
      "Estimator: 000 | Epoch: 008 | Batch: 100 | Loss: 0.10485 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 008 | Batch: 200 | Loss: 0.20848 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 008 | Batch: 300 | Loss: 0.10944 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 008 | Batch: 400 | Loss: 0.17584 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 008 | Batch: 000 | Loss: 0.13396 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 008 | Batch: 100 | Loss: 0.15572 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 008 | Batch: 200 | Loss: 0.15314 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 008 | Batch: 300 | Loss: 0.11216 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 008 | Batch: 400 | Loss: 0.21490 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 008 | Batch: 000 | Loss: 0.16503 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 008 | Batch: 100 | Loss: 0.23198 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 008 | Batch: 200 | Loss: 0.13992 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 008 | Batch: 300 | Loss: 0.14511 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 008 | Batch: 400 | Loss: 0.13530 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 008 | Batch: 000 | Loss: 0.11634 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 008 | Batch: 100 | Loss: 0.12150 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 008 | Batch: 200 | Loss: 0.09833 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 008 | Batch: 300 | Loss: 0.14374 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 008 | Batch: 400 | Loss: 0.11643 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 008 | Batch: 000 | Loss: 0.14059 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 008 | Batch: 100 | Loss: 0.13036 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 008 | Batch: 200 | Loss: 0.09865 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 008 | Batch: 300 | Loss: 0.19728 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 008 | Batch: 400 | Loss: 0.12341 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 008 | Batch: 000 | Loss: 0.27633 | Correct: 118/128\n",
      "Estimator: 005 | Epoch: 008 | Batch: 100 | Loss: 0.08850 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 008 | Batch: 200 | Loss: 0.16654 | Correct: 119/128\n",
      "Estimator: 005 | Epoch: 008 | Batch: 300 | Loss: 0.10481 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 008 | Batch: 400 | Loss: 0.10825 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 008 | Batch: 000 | Loss: 0.09932 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 008 | Batch: 100 | Loss: 0.05242 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 008 | Batch: 200 | Loss: 0.13555 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 008 | Batch: 300 | Loss: 0.17784 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 008 | Batch: 400 | Loss: 0.20943 | Correct: 118/128\n",
      "Estimator: 007 | Epoch: 008 | Batch: 000 | Loss: 0.15542 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 008 | Batch: 100 | Loss: 0.14842 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 008 | Batch: 200 | Loss: 0.17237 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 008 | Batch: 300 | Loss: 0.13920 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 008 | Batch: 400 | Loss: 0.15227 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 008 | Batch: 000 | Loss: 0.07293 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 008 | Batch: 100 | Loss: 0.08738 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 008 | Batch: 200 | Loss: 0.18718 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 008 | Batch: 300 | Loss: 0.13506 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 008 | Batch: 400 | Loss: 0.14601 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 008 | Batch: 000 | Loss: 0.14351 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 008 | Batch: 100 | Loss: 0.16587 | Correct: 120/128\n",
      "Estimator: 009 | Epoch: 008 | Batch: 200 | Loss: 0.07966 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 008 | Batch: 300 | Loss: 0.21687 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 008 | Batch: 400 | Loss: 0.11893 | Correct: 123/128\n",
      "2021-02-15 22:10:13,818 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2021-02-15 22:10:13,832 - INFO: Epoch: 008 | Validation Acc: 97.640 % | Historical Best: 97.640 %\n",
      "Estimator: 000 | Epoch: 009 | Batch: 000 | Loss: 0.13800 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 009 | Batch: 100 | Loss: 0.12623 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 009 | Batch: 200 | Loss: 0.15529 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 009 | Batch: 300 | Loss: 0.12269 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 009 | Batch: 400 | Loss: 0.18775 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 009 | Batch: 000 | Loss: 0.21334 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 009 | Batch: 100 | Loss: 0.10281 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 009 | Batch: 200 | Loss: 0.20737 | Correct: 118/128\n",
      "Estimator: 001 | Epoch: 009 | Batch: 300 | Loss: 0.13003 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 009 | Batch: 400 | Loss: 0.16223 | Correct: 118/128\n",
      "Estimator: 002 | Epoch: 009 | Batch: 000 | Loss: 0.11239 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 009 | Batch: 100 | Loss: 0.09014 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 009 | Batch: 200 | Loss: 0.07442 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 009 | Batch: 300 | Loss: 0.09452 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 009 | Batch: 400 | Loss: 0.15598 | Correct: 120/128\n",
      "Estimator: 003 | Epoch: 009 | Batch: 000 | Loss: 0.13046 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 009 | Batch: 100 | Loss: 0.11444 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 009 | Batch: 200 | Loss: 0.15946 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 009 | Batch: 300 | Loss: 0.04583 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 009 | Batch: 400 | Loss: 0.16088 | Correct: 117/128\n",
      "Estimator: 004 | Epoch: 009 | Batch: 000 | Loss: 0.18298 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 009 | Batch: 100 | Loss: 0.17906 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 009 | Batch: 200 | Loss: 0.08266 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 009 | Batch: 300 | Loss: 0.11206 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 009 | Batch: 400 | Loss: 0.10674 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 009 | Batch: 000 | Loss: 0.12752 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 009 | Batch: 100 | Loss: 0.22159 | Correct: 117/128\n",
      "Estimator: 005 | Epoch: 009 | Batch: 200 | Loss: 0.16456 | Correct: 119/128\n",
      "Estimator: 005 | Epoch: 009 | Batch: 300 | Loss: 0.09698 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 009 | Batch: 400 | Loss: 0.12032 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 009 | Batch: 000 | Loss: 0.04927 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 009 | Batch: 100 | Loss: 0.19850 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 009 | Batch: 200 | Loss: 0.17233 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 009 | Batch: 300 | Loss: 0.08553 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 009 | Batch: 400 | Loss: 0.12340 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 009 | Batch: 000 | Loss: 0.08155 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 009 | Batch: 100 | Loss: 0.18986 | Correct: 120/128\n",
      "Estimator: 007 | Epoch: 009 | Batch: 200 | Loss: 0.12497 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 009 | Batch: 300 | Loss: 0.05365 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 009 | Batch: 400 | Loss: 0.05926 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 009 | Batch: 000 | Loss: 0.06075 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 009 | Batch: 100 | Loss: 0.07793 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 009 | Batch: 200 | Loss: 0.08167 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 009 | Batch: 300 | Loss: 0.17707 | Correct: 119/128\n",
      "Estimator: 008 | Epoch: 009 | Batch: 400 | Loss: 0.18311 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 009 | Batch: 000 | Loss: 0.06995 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 009 | Batch: 100 | Loss: 0.17672 | Correct: 119/128\n",
      "Estimator: 009 | Epoch: 009 | Batch: 200 | Loss: 0.15725 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 009 | Batch: 300 | Loss: 0.14698 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 009 | Batch: 400 | Loss: 0.08691 | Correct: 124/128\n",
      "2021-02-15 22:11:54,253 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2021-02-15 22:11:54,266 - INFO: Epoch: 009 | Validation Acc: 97.760 % | Historical Best: 97.760 %\n",
      "Estimator: 000 | Epoch: 010 | Batch: 000 | Loss: 0.10145 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 010 | Batch: 100 | Loss: 0.23208 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 010 | Batch: 200 | Loss: 0.18637 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 010 | Batch: 300 | Loss: 0.11148 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 010 | Batch: 400 | Loss: 0.06826 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 010 | Batch: 000 | Loss: 0.10510 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 010 | Batch: 100 | Loss: 0.13040 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 010 | Batch: 200 | Loss: 0.17390 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 010 | Batch: 300 | Loss: 0.16828 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 010 | Batch: 400 | Loss: 0.11002 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 010 | Batch: 000 | Loss: 0.14976 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 010 | Batch: 100 | Loss: 0.07691 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 010 | Batch: 200 | Loss: 0.17256 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 010 | Batch: 300 | Loss: 0.20138 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 010 | Batch: 400 | Loss: 0.10712 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 010 | Batch: 000 | Loss: 0.11443 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 010 | Batch: 100 | Loss: 0.12385 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 010 | Batch: 200 | Loss: 0.11338 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 010 | Batch: 300 | Loss: 0.15942 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 010 | Batch: 400 | Loss: 0.16836 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 010 | Batch: 000 | Loss: 0.12598 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 010 | Batch: 100 | Loss: 0.03808 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 010 | Batch: 200 | Loss: 0.16009 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 010 | Batch: 300 | Loss: 0.11081 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 010 | Batch: 400 | Loss: 0.10465 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 010 | Batch: 000 | Loss: 0.15377 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 010 | Batch: 100 | Loss: 0.10520 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 010 | Batch: 200 | Loss: 0.08164 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 010 | Batch: 300 | Loss: 0.17949 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 010 | Batch: 400 | Loss: 0.06542 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 010 | Batch: 000 | Loss: 0.08438 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 010 | Batch: 100 | Loss: 0.14984 | Correct: 119/128\n",
      "Estimator: 006 | Epoch: 010 | Batch: 200 | Loss: 0.11177 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 010 | Batch: 300 | Loss: 0.18220 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 010 | Batch: 400 | Loss: 0.07647 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 010 | Batch: 000 | Loss: 0.18327 | Correct: 119/128\n",
      "Estimator: 007 | Epoch: 010 | Batch: 100 | Loss: 0.10863 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 010 | Batch: 200 | Loss: 0.13644 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 010 | Batch: 300 | Loss: 0.09150 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 010 | Batch: 400 | Loss: 0.19750 | Correct: 120/128\n",
      "Estimator: 008 | Epoch: 010 | Batch: 000 | Loss: 0.09814 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 010 | Batch: 100 | Loss: 0.16512 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 010 | Batch: 200 | Loss: 0.12275 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 010 | Batch: 300 | Loss: 0.08263 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 010 | Batch: 400 | Loss: 0.12756 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 010 | Batch: 000 | Loss: 0.15355 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 010 | Batch: 100 | Loss: 0.11098 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 010 | Batch: 200 | Loss: 0.15250 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 010 | Batch: 300 | Loss: 0.10340 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 010 | Batch: 400 | Loss: 0.14547 | Correct: 122/128\n",
      "2021-02-15 22:13:35,143 - INFO: Epoch: 010 | Validation Acc: 97.650 % | Historical Best: 97.760 %\n",
      "Estimator: 000 | Epoch: 011 | Batch: 000 | Loss: 0.12624 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 011 | Batch: 100 | Loss: 0.12181 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 011 | Batch: 200 | Loss: 0.14645 | Correct: 119/128\n",
      "Estimator: 000 | Epoch: 011 | Batch: 300 | Loss: 0.16608 | Correct: 120/128\n",
      "Estimator: 000 | Epoch: 011 | Batch: 400 | Loss: 0.16813 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 011 | Batch: 000 | Loss: 0.11735 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 011 | Batch: 100 | Loss: 0.22698 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 011 | Batch: 200 | Loss: 0.10363 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 011 | Batch: 300 | Loss: 0.09149 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 011 | Batch: 400 | Loss: 0.10334 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 011 | Batch: 000 | Loss: 0.09238 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 011 | Batch: 100 | Loss: 0.14815 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 011 | Batch: 200 | Loss: 0.10107 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 011 | Batch: 300 | Loss: 0.12952 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 011 | Batch: 400 | Loss: 0.20842 | Correct: 120/128\n",
      "Estimator: 003 | Epoch: 011 | Batch: 000 | Loss: 0.23718 | Correct: 119/128\n",
      "Estimator: 003 | Epoch: 011 | Batch: 100 | Loss: 0.12815 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 011 | Batch: 200 | Loss: 0.17446 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 011 | Batch: 300 | Loss: 0.09931 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 011 | Batch: 400 | Loss: 0.14656 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 011 | Batch: 000 | Loss: 0.08655 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 011 | Batch: 100 | Loss: 0.11318 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 011 | Batch: 200 | Loss: 0.13382 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 011 | Batch: 300 | Loss: 0.19213 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 011 | Batch: 400 | Loss: 0.05651 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 011 | Batch: 000 | Loss: 0.11568 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 011 | Batch: 100 | Loss: 0.13549 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 011 | Batch: 200 | Loss: 0.09872 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 011 | Batch: 300 | Loss: 0.03470 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 011 | Batch: 400 | Loss: 0.18343 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 011 | Batch: 000 | Loss: 0.17367 | Correct: 119/128\n",
      "Estimator: 006 | Epoch: 011 | Batch: 100 | Loss: 0.17847 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 011 | Batch: 200 | Loss: 0.16833 | Correct: 118/128\n",
      "Estimator: 006 | Epoch: 011 | Batch: 300 | Loss: 0.06110 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 011 | Batch: 400 | Loss: 0.07334 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 011 | Batch: 000 | Loss: 0.09083 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 011 | Batch: 100 | Loss: 0.18262 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 011 | Batch: 200 | Loss: 0.15158 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 011 | Batch: 300 | Loss: 0.15927 | Correct: 119/128\n",
      "Estimator: 007 | Epoch: 011 | Batch: 400 | Loss: 0.14283 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 011 | Batch: 000 | Loss: 0.13972 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 011 | Batch: 100 | Loss: 0.11979 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 011 | Batch: 200 | Loss: 0.14085 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 011 | Batch: 300 | Loss: 0.16125 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 011 | Batch: 400 | Loss: 0.11201 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 011 | Batch: 000 | Loss: 0.08057 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 011 | Batch: 100 | Loss: 0.17052 | Correct: 119/128\n",
      "Estimator: 009 | Epoch: 011 | Batch: 200 | Loss: 0.15252 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 011 | Batch: 300 | Loss: 0.15303 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 011 | Batch: 400 | Loss: 0.09856 | Correct: 125/128\n",
      "2021-02-15 22:15:15,527 - INFO: Epoch: 011 | Validation Acc: 97.700 % | Historical Best: 97.760 %\n",
      "Estimator: 000 | Epoch: 012 | Batch: 000 | Loss: 0.09604 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 012 | Batch: 100 | Loss: 0.09607 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 012 | Batch: 200 | Loss: 0.28194 | Correct: 120/128\n",
      "Estimator: 000 | Epoch: 012 | Batch: 300 | Loss: 0.20288 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 012 | Batch: 400 | Loss: 0.18374 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 012 | Batch: 000 | Loss: 0.14231 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 012 | Batch: 100 | Loss: 0.16925 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 012 | Batch: 200 | Loss: 0.11266 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 012 | Batch: 300 | Loss: 0.14201 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 012 | Batch: 400 | Loss: 0.07564 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 012 | Batch: 000 | Loss: 0.09632 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 012 | Batch: 100 | Loss: 0.04920 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 012 | Batch: 200 | Loss: 0.19870 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 012 | Batch: 300 | Loss: 0.13868 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 012 | Batch: 400 | Loss: 0.09085 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 012 | Batch: 000 | Loss: 0.09241 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 012 | Batch: 100 | Loss: 0.11203 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 012 | Batch: 200 | Loss: 0.05187 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 012 | Batch: 300 | Loss: 0.07819 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 012 | Batch: 400 | Loss: 0.08628 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 012 | Batch: 000 | Loss: 0.17377 | Correct: 119/128\n",
      "Estimator: 004 | Epoch: 012 | Batch: 100 | Loss: 0.14134 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 012 | Batch: 200 | Loss: 0.07556 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 012 | Batch: 300 | Loss: 0.16167 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 012 | Batch: 400 | Loss: 0.12725 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 012 | Batch: 000 | Loss: 0.09538 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 012 | Batch: 100 | Loss: 0.15381 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 012 | Batch: 200 | Loss: 0.07696 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 012 | Batch: 300 | Loss: 0.12666 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 012 | Batch: 400 | Loss: 0.13207 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 012 | Batch: 000 | Loss: 0.13192 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 012 | Batch: 100 | Loss: 0.10342 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 012 | Batch: 200 | Loss: 0.07667 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 012 | Batch: 300 | Loss: 0.11250 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 012 | Batch: 400 | Loss: 0.07179 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 012 | Batch: 000 | Loss: 0.08382 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 012 | Batch: 100 | Loss: 0.11156 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 012 | Batch: 200 | Loss: 0.12138 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 012 | Batch: 300 | Loss: 0.17841 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 012 | Batch: 400 | Loss: 0.13804 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 012 | Batch: 000 | Loss: 0.11476 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 012 | Batch: 100 | Loss: 0.08611 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 012 | Batch: 200 | Loss: 0.15719 | Correct: 119/128\n",
      "Estimator: 008 | Epoch: 012 | Batch: 300 | Loss: 0.06528 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 012 | Batch: 400 | Loss: 0.15250 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 012 | Batch: 000 | Loss: 0.10612 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 012 | Batch: 100 | Loss: 0.08775 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 012 | Batch: 200 | Loss: 0.07428 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 012 | Batch: 300 | Loss: 0.10743 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 012 | Batch: 400 | Loss: 0.12813 | Correct: 123/128\n",
      "2021-02-15 22:16:56,387 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2021-02-15 22:16:56,402 - INFO: Epoch: 012 | Validation Acc: 97.810 % | Historical Best: 97.810 %\n",
      "Estimator: 000 | Epoch: 013 | Batch: 000 | Loss: 0.10056 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 013 | Batch: 100 | Loss: 0.07833 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 013 | Batch: 200 | Loss: 0.07942 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 013 | Batch: 300 | Loss: 0.17171 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 013 | Batch: 400 | Loss: 0.14773 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 013 | Batch: 000 | Loss: 0.14920 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 013 | Batch: 100 | Loss: 0.15142 | Correct: 118/128\n",
      "Estimator: 001 | Epoch: 013 | Batch: 200 | Loss: 0.09057 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 013 | Batch: 300 | Loss: 0.14102 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 013 | Batch: 400 | Loss: 0.18671 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 013 | Batch: 000 | Loss: 0.10188 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 013 | Batch: 100 | Loss: 0.13304 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 013 | Batch: 200 | Loss: 0.06497 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 013 | Batch: 300 | Loss: 0.20908 | Correct: 119/128\n",
      "Estimator: 002 | Epoch: 013 | Batch: 400 | Loss: 0.14038 | Correct: 120/128\n",
      "Estimator: 003 | Epoch: 013 | Batch: 000 | Loss: 0.28668 | Correct: 120/128\n",
      "Estimator: 003 | Epoch: 013 | Batch: 100 | Loss: 0.16975 | Correct: 120/128\n",
      "Estimator: 003 | Epoch: 013 | Batch: 200 | Loss: 0.10527 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 013 | Batch: 300 | Loss: 0.11804 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 013 | Batch: 400 | Loss: 0.13173 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 013 | Batch: 000 | Loss: 0.09394 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 013 | Batch: 100 | Loss: 0.23510 | Correct: 119/128\n",
      "Estimator: 004 | Epoch: 013 | Batch: 200 | Loss: 0.11276 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 013 | Batch: 300 | Loss: 0.20242 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 013 | Batch: 400 | Loss: 0.12677 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 013 | Batch: 000 | Loss: 0.11715 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 013 | Batch: 100 | Loss: 0.13897 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 013 | Batch: 200 | Loss: 0.07983 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 013 | Batch: 300 | Loss: 0.12562 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 013 | Batch: 400 | Loss: 0.09391 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 013 | Batch: 000 | Loss: 0.13402 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 013 | Batch: 100 | Loss: 0.10183 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 013 | Batch: 200 | Loss: 0.11461 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 013 | Batch: 300 | Loss: 0.04957 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 013 | Batch: 400 | Loss: 0.06027 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 013 | Batch: 000 | Loss: 0.10796 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 013 | Batch: 100 | Loss: 0.14188 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 013 | Batch: 200 | Loss: 0.16142 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 013 | Batch: 300 | Loss: 0.08235 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 013 | Batch: 400 | Loss: 0.17798 | Correct: 119/128\n",
      "Estimator: 008 | Epoch: 013 | Batch: 000 | Loss: 0.12469 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 013 | Batch: 100 | Loss: 0.20631 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 013 | Batch: 200 | Loss: 0.13130 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 013 | Batch: 300 | Loss: 0.05913 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 013 | Batch: 400 | Loss: 0.07917 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 013 | Batch: 000 | Loss: 0.11690 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 013 | Batch: 100 | Loss: 0.12035 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 013 | Batch: 200 | Loss: 0.05302 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 013 | Batch: 300 | Loss: 0.07403 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 013 | Batch: 400 | Loss: 0.11862 | Correct: 125/128\n",
      "2021-02-15 22:18:37,679 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2021-02-15 22:18:37,693 - INFO: Epoch: 013 | Validation Acc: 97.860 % | Historical Best: 97.860 %\n",
      "Estimator: 000 | Epoch: 014 | Batch: 000 | Loss: 0.14614 | Correct: 120/128\n",
      "Estimator: 000 | Epoch: 014 | Batch: 100 | Loss: 0.07247 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 014 | Batch: 200 | Loss: 0.08017 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 014 | Batch: 300 | Loss: 0.12944 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 014 | Batch: 400 | Loss: 0.07938 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 014 | Batch: 000 | Loss: 0.06769 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 014 | Batch: 100 | Loss: 0.05101 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 014 | Batch: 200 | Loss: 0.15357 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 014 | Batch: 300 | Loss: 0.06934 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 014 | Batch: 400 | Loss: 0.19985 | Correct: 119/128\n",
      "Estimator: 002 | Epoch: 014 | Batch: 000 | Loss: 0.16064 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 014 | Batch: 100 | Loss: 0.12595 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 014 | Batch: 200 | Loss: 0.13175 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 014 | Batch: 300 | Loss: 0.11161 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 014 | Batch: 400 | Loss: 0.12652 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 014 | Batch: 000 | Loss: 0.13128 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 014 | Batch: 100 | Loss: 0.08709 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 014 | Batch: 200 | Loss: 0.04953 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 014 | Batch: 300 | Loss: 0.05916 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 014 | Batch: 400 | Loss: 0.12626 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 014 | Batch: 000 | Loss: 0.18505 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 014 | Batch: 100 | Loss: 0.20114 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 014 | Batch: 200 | Loss: 0.08639 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 014 | Batch: 300 | Loss: 0.11685 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 014 | Batch: 400 | Loss: 0.20653 | Correct: 119/128\n",
      "Estimator: 005 | Epoch: 014 | Batch: 000 | Loss: 0.11843 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 014 | Batch: 100 | Loss: 0.11833 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 014 | Batch: 200 | Loss: 0.13398 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 014 | Batch: 300 | Loss: 0.13618 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 014 | Batch: 400 | Loss: 0.11285 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 014 | Batch: 000 | Loss: 0.10435 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 014 | Batch: 100 | Loss: 0.20516 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 014 | Batch: 200 | Loss: 0.14683 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 014 | Batch: 300 | Loss: 0.08773 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 014 | Batch: 400 | Loss: 0.07622 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 014 | Batch: 000 | Loss: 0.11913 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 014 | Batch: 100 | Loss: 0.05256 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 014 | Batch: 200 | Loss: 0.12266 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 014 | Batch: 300 | Loss: 0.18081 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 014 | Batch: 400 | Loss: 0.07796 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 014 | Batch: 000 | Loss: 0.11299 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 014 | Batch: 100 | Loss: 0.06499 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 014 | Batch: 200 | Loss: 0.16311 | Correct: 120/128\n",
      "Estimator: 008 | Epoch: 014 | Batch: 300 | Loss: 0.12919 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 014 | Batch: 400 | Loss: 0.15059 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 014 | Batch: 000 | Loss: 0.07576 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 014 | Batch: 100 | Loss: 0.13665 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 014 | Batch: 200 | Loss: 0.09361 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 014 | Batch: 300 | Loss: 0.05622 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 014 | Batch: 400 | Loss: 0.18796 | Correct: 123/128\n",
      "2021-02-15 22:20:19,720 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2021-02-15 22:20:19,733 - INFO: Epoch: 014 | Validation Acc: 97.920 % | Historical Best: 97.920 %\n",
      "Estimator: 000 | Epoch: 015 | Batch: 000 | Loss: 0.15944 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 015 | Batch: 100 | Loss: 0.05025 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 015 | Batch: 200 | Loss: 0.05050 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 015 | Batch: 300 | Loss: 0.08962 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 015 | Batch: 400 | Loss: 0.16179 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 015 | Batch: 000 | Loss: 0.17216 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 015 | Batch: 100 | Loss: 0.19275 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 015 | Batch: 200 | Loss: 0.13120 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 015 | Batch: 300 | Loss: 0.04447 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 015 | Batch: 400 | Loss: 0.13625 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 015 | Batch: 000 | Loss: 0.09416 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 015 | Batch: 100 | Loss: 0.13460 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 015 | Batch: 200 | Loss: 0.04558 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 015 | Batch: 300 | Loss: 0.07517 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 015 | Batch: 400 | Loss: 0.14229 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 015 | Batch: 000 | Loss: 0.20009 | Correct: 120/128\n",
      "Estimator: 003 | Epoch: 015 | Batch: 100 | Loss: 0.12111 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 015 | Batch: 200 | Loss: 0.04361 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 015 | Batch: 300 | Loss: 0.09461 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 015 | Batch: 400 | Loss: 0.11399 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 015 | Batch: 000 | Loss: 0.10933 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 015 | Batch: 100 | Loss: 0.10739 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 015 | Batch: 200 | Loss: 0.07689 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 015 | Batch: 300 | Loss: 0.07838 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 015 | Batch: 400 | Loss: 0.16508 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 015 | Batch: 000 | Loss: 0.07181 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 015 | Batch: 100 | Loss: 0.11209 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 015 | Batch: 200 | Loss: 0.16513 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 015 | Batch: 300 | Loss: 0.12618 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 015 | Batch: 400 | Loss: 0.11964 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 015 | Batch: 000 | Loss: 0.09970 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 015 | Batch: 100 | Loss: 0.03147 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 015 | Batch: 200 | Loss: 0.06658 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 015 | Batch: 300 | Loss: 0.15647 | Correct: 118/128\n",
      "Estimator: 006 | Epoch: 015 | Batch: 400 | Loss: 0.08976 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 015 | Batch: 000 | Loss: 0.07346 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 015 | Batch: 100 | Loss: 0.08092 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 015 | Batch: 200 | Loss: 0.14769 | Correct: 120/128\n",
      "Estimator: 007 | Epoch: 015 | Batch: 300 | Loss: 0.14528 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 015 | Batch: 400 | Loss: 0.13098 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 015 | Batch: 000 | Loss: 0.13292 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 015 | Batch: 100 | Loss: 0.13154 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 015 | Batch: 200 | Loss: 0.09985 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 015 | Batch: 300 | Loss: 0.13733 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 015 | Batch: 400 | Loss: 0.12324 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 015 | Batch: 000 | Loss: 0.16313 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 015 | Batch: 100 | Loss: 0.05836 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 015 | Batch: 200 | Loss: 0.24366 | Correct: 116/128\n",
      "Estimator: 009 | Epoch: 015 | Batch: 300 | Loss: 0.09991 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 015 | Batch: 400 | Loss: 0.08637 | Correct: 126/128\n",
      "2021-02-15 22:22:01,240 - INFO: Epoch: 015 | Validation Acc: 97.910 % | Historical Best: 97.920 %\n",
      "Estimator: 000 | Epoch: 016 | Batch: 000 | Loss: 0.08823 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 016 | Batch: 100 | Loss: 0.04602 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 016 | Batch: 200 | Loss: 0.08422 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 016 | Batch: 300 | Loss: 0.09578 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 016 | Batch: 400 | Loss: 0.22472 | Correct: 118/128\n",
      "Estimator: 001 | Epoch: 016 | Batch: 000 | Loss: 0.09890 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 016 | Batch: 100 | Loss: 0.06095 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 016 | Batch: 200 | Loss: 0.13676 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 016 | Batch: 300 | Loss: 0.07723 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 016 | Batch: 400 | Loss: 0.12656 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 016 | Batch: 000 | Loss: 0.09341 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 016 | Batch: 100 | Loss: 0.12282 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 016 | Batch: 200 | Loss: 0.15782 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 016 | Batch: 300 | Loss: 0.23719 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 016 | Batch: 400 | Loss: 0.13585 | Correct: 120/128\n",
      "Estimator: 003 | Epoch: 016 | Batch: 000 | Loss: 0.09166 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 016 | Batch: 100 | Loss: 0.20899 | Correct: 120/128\n",
      "Estimator: 003 | Epoch: 016 | Batch: 200 | Loss: 0.12960 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 016 | Batch: 300 | Loss: 0.12063 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 016 | Batch: 400 | Loss: 0.07534 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 016 | Batch: 000 | Loss: 0.12099 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 016 | Batch: 100 | Loss: 0.13441 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 016 | Batch: 200 | Loss: 0.07755 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 016 | Batch: 300 | Loss: 0.06513 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 016 | Batch: 400 | Loss: 0.16627 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 016 | Batch: 000 | Loss: 0.11241 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 016 | Batch: 100 | Loss: 0.05505 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 016 | Batch: 200 | Loss: 0.13655 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 016 | Batch: 300 | Loss: 0.19793 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 016 | Batch: 400 | Loss: 0.15218 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 016 | Batch: 000 | Loss: 0.08674 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 016 | Batch: 100 | Loss: 0.09984 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 016 | Batch: 200 | Loss: 0.07268 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 016 | Batch: 300 | Loss: 0.15647 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 016 | Batch: 400 | Loss: 0.12148 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 016 | Batch: 000 | Loss: 0.13367 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 016 | Batch: 100 | Loss: 0.10574 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 016 | Batch: 200 | Loss: 0.13331 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 016 | Batch: 300 | Loss: 0.07822 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 016 | Batch: 400 | Loss: 0.15220 | Correct: 120/128\n",
      "Estimator: 008 | Epoch: 016 | Batch: 000 | Loss: 0.21894 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 016 | Batch: 100 | Loss: 0.10677 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 016 | Batch: 200 | Loss: 0.07768 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 016 | Batch: 300 | Loss: 0.14796 | Correct: 120/128\n",
      "Estimator: 008 | Epoch: 016 | Batch: 400 | Loss: 0.09116 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 016 | Batch: 000 | Loss: 0.08700 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 016 | Batch: 100 | Loss: 0.11691 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 016 | Batch: 200 | Loss: 0.13747 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 016 | Batch: 300 | Loss: 0.20456 | Correct: 119/128\n",
      "Estimator: 009 | Epoch: 016 | Batch: 400 | Loss: 0.08022 | Correct: 126/128\n",
      "2021-02-15 22:23:43,168 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2021-02-15 22:23:43,182 - INFO: Epoch: 016 | Validation Acc: 97.950 % | Historical Best: 97.950 %\n",
      "Estimator: 000 | Epoch: 017 | Batch: 000 | Loss: 0.08749 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 017 | Batch: 100 | Loss: 0.09474 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 017 | Batch: 200 | Loss: 0.11212 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 017 | Batch: 300 | Loss: 0.12152 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 017 | Batch: 400 | Loss: 0.11473 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 017 | Batch: 000 | Loss: 0.16964 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 017 | Batch: 100 | Loss: 0.06654 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 017 | Batch: 200 | Loss: 0.17001 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 017 | Batch: 300 | Loss: 0.10972 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 017 | Batch: 400 | Loss: 0.13854 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 017 | Batch: 000 | Loss: 0.05572 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 017 | Batch: 100 | Loss: 0.13715 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 017 | Batch: 200 | Loss: 0.11862 | Correct: 119/128\n",
      "Estimator: 002 | Epoch: 017 | Batch: 300 | Loss: 0.08356 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 017 | Batch: 400 | Loss: 0.19758 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 017 | Batch: 000 | Loss: 0.06099 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 017 | Batch: 100 | Loss: 0.15659 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 017 | Batch: 200 | Loss: 0.12714 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 017 | Batch: 300 | Loss: 0.11823 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 017 | Batch: 400 | Loss: 0.21741 | Correct: 119/128\n",
      "Estimator: 004 | Epoch: 017 | Batch: 000 | Loss: 0.14307 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 017 | Batch: 100 | Loss: 0.11316 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 017 | Batch: 200 | Loss: 0.14538 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 017 | Batch: 300 | Loss: 0.06807 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 017 | Batch: 400 | Loss: 0.17448 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 017 | Batch: 000 | Loss: 0.13208 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 017 | Batch: 100 | Loss: 0.09460 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 017 | Batch: 200 | Loss: 0.16374 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 017 | Batch: 300 | Loss: 0.13378 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 017 | Batch: 400 | Loss: 0.14283 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 017 | Batch: 000 | Loss: 0.04219 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 017 | Batch: 100 | Loss: 0.09497 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 017 | Batch: 200 | Loss: 0.10455 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 017 | Batch: 300 | Loss: 0.07260 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 017 | Batch: 400 | Loss: 0.18697 | Correct: 120/128\n",
      "Estimator: 007 | Epoch: 017 | Batch: 000 | Loss: 0.14378 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 017 | Batch: 100 | Loss: 0.09417 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 017 | Batch: 200 | Loss: 0.10075 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 017 | Batch: 300 | Loss: 0.10114 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 017 | Batch: 400 | Loss: 0.09341 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 017 | Batch: 000 | Loss: 0.07461 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 017 | Batch: 100 | Loss: 0.14340 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 017 | Batch: 200 | Loss: 0.02897 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 017 | Batch: 300 | Loss: 0.11770 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 017 | Batch: 400 | Loss: 0.17311 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 017 | Batch: 000 | Loss: 0.20733 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 017 | Batch: 100 | Loss: 0.11278 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 017 | Batch: 200 | Loss: 0.10329 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 017 | Batch: 300 | Loss: 0.13565 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 017 | Batch: 400 | Loss: 0.08162 | Correct: 122/128\n",
      "2021-02-15 22:25:24,474 - INFO: Epoch: 017 | Validation Acc: 97.920 % | Historical Best: 97.950 %\n",
      "Estimator: 000 | Epoch: 018 | Batch: 000 | Loss: 0.11007 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 018 | Batch: 100 | Loss: 0.13894 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 018 | Batch: 200 | Loss: 0.11763 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 018 | Batch: 300 | Loss: 0.13538 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 018 | Batch: 400 | Loss: 0.14449 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 018 | Batch: 000 | Loss: 0.12996 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 018 | Batch: 100 | Loss: 0.13689 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 018 | Batch: 200 | Loss: 0.11464 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 018 | Batch: 300 | Loss: 0.16675 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 018 | Batch: 400 | Loss: 0.08731 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 018 | Batch: 000 | Loss: 0.10301 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 018 | Batch: 100 | Loss: 0.09247 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 018 | Batch: 200 | Loss: 0.04623 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 018 | Batch: 300 | Loss: 0.08145 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 018 | Batch: 400 | Loss: 0.09447 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 018 | Batch: 000 | Loss: 0.17976 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 018 | Batch: 100 | Loss: 0.06766 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 018 | Batch: 200 | Loss: 0.09587 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 018 | Batch: 300 | Loss: 0.06948 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 018 | Batch: 400 | Loss: 0.15078 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 018 | Batch: 000 | Loss: 0.13277 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 018 | Batch: 100 | Loss: 0.13249 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 018 | Batch: 200 | Loss: 0.11767 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 018 | Batch: 300 | Loss: 0.12005 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 018 | Batch: 400 | Loss: 0.20096 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 018 | Batch: 000 | Loss: 0.17945 | Correct: 118/128\n",
      "Estimator: 005 | Epoch: 018 | Batch: 100 | Loss: 0.06741 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 018 | Batch: 200 | Loss: 0.24433 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 018 | Batch: 300 | Loss: 0.08001 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 018 | Batch: 400 | Loss: 0.06547 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 018 | Batch: 000 | Loss: 0.10145 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 018 | Batch: 100 | Loss: 0.11083 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 018 | Batch: 200 | Loss: 0.04682 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 018 | Batch: 300 | Loss: 0.11351 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 018 | Batch: 400 | Loss: 0.12972 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 018 | Batch: 000 | Loss: 0.10501 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 018 | Batch: 100 | Loss: 0.17523 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 018 | Batch: 200 | Loss: 0.08765 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 018 | Batch: 300 | Loss: 0.03923 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 018 | Batch: 400 | Loss: 0.08461 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 018 | Batch: 000 | Loss: 0.08153 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 018 | Batch: 100 | Loss: 0.10651 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 018 | Batch: 200 | Loss: 0.18321 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 018 | Batch: 300 | Loss: 0.24329 | Correct: 118/128\n",
      "Estimator: 008 | Epoch: 018 | Batch: 400 | Loss: 0.14728 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 018 | Batch: 000 | Loss: 0.10570 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 018 | Batch: 100 | Loss: 0.23862 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 018 | Batch: 200 | Loss: 0.19809 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 018 | Batch: 300 | Loss: 0.16490 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 018 | Batch: 400 | Loss: 0.08897 | Correct: 125/128\n",
      "2021-02-15 22:27:04,921 - INFO: Epoch: 018 | Validation Acc: 97.810 % | Historical Best: 97.950 %\n",
      "Estimator: 000 | Epoch: 019 | Batch: 000 | Loss: 0.03152 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 019 | Batch: 100 | Loss: 0.11847 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 019 | Batch: 200 | Loss: 0.07363 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 019 | Batch: 300 | Loss: 0.05584 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 019 | Batch: 400 | Loss: 0.15933 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 019 | Batch: 000 | Loss: 0.08756 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 019 | Batch: 100 | Loss: 0.08193 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 019 | Batch: 200 | Loss: 0.10726 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 019 | Batch: 300 | Loss: 0.14683 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 019 | Batch: 400 | Loss: 0.15050 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 019 | Batch: 000 | Loss: 0.08936 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 019 | Batch: 100 | Loss: 0.07509 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 019 | Batch: 200 | Loss: 0.05410 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 019 | Batch: 300 | Loss: 0.13730 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 019 | Batch: 400 | Loss: 0.11940 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 019 | Batch: 000 | Loss: 0.06910 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 019 | Batch: 100 | Loss: 0.19562 | Correct: 120/128\n",
      "Estimator: 003 | Epoch: 019 | Batch: 200 | Loss: 0.06385 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 019 | Batch: 300 | Loss: 0.23625 | Correct: 120/128\n",
      "Estimator: 003 | Epoch: 019 | Batch: 400 | Loss: 0.16788 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 019 | Batch: 000 | Loss: 0.04940 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 019 | Batch: 100 | Loss: 0.07899 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 019 | Batch: 200 | Loss: 0.17205 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 019 | Batch: 300 | Loss: 0.24035 | Correct: 118/128\n",
      "Estimator: 004 | Epoch: 019 | Batch: 400 | Loss: 0.06334 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 019 | Batch: 000 | Loss: 0.08326 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 019 | Batch: 100 | Loss: 0.18372 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 019 | Batch: 200 | Loss: 0.11785 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 019 | Batch: 300 | Loss: 0.14277 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 019 | Batch: 400 | Loss: 0.22181 | Correct: 118/128\n",
      "Estimator: 006 | Epoch: 019 | Batch: 000 | Loss: 0.11645 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 019 | Batch: 100 | Loss: 0.08662 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 019 | Batch: 200 | Loss: 0.07491 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 019 | Batch: 300 | Loss: 0.13182 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 019 | Batch: 400 | Loss: 0.15334 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 019 | Batch: 000 | Loss: 0.10959 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 019 | Batch: 100 | Loss: 0.26760 | Correct: 120/128\n",
      "Estimator: 007 | Epoch: 019 | Batch: 200 | Loss: 0.11763 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 019 | Batch: 300 | Loss: 0.08295 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 019 | Batch: 400 | Loss: 0.20826 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 019 | Batch: 000 | Loss: 0.10544 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 019 | Batch: 100 | Loss: 0.11212 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 019 | Batch: 200 | Loss: 0.19136 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 019 | Batch: 300 | Loss: 0.08046 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 019 | Batch: 400 | Loss: 0.05611 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 019 | Batch: 000 | Loss: 0.08979 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 019 | Batch: 100 | Loss: 0.12965 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 019 | Batch: 200 | Loss: 0.09339 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 019 | Batch: 300 | Loss: 0.12472 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 019 | Batch: 400 | Loss: 0.16276 | Correct: 121/128\n",
      "2021-02-15 22:28:45,921 - INFO: Epoch: 019 | Validation Acc: 97.940 % | Historical Best: 97.950 %\n",
      "Estimator: 000 | Epoch: 020 | Batch: 000 | Loss: 0.09524 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 020 | Batch: 100 | Loss: 0.09571 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 020 | Batch: 200 | Loss: 0.15401 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 020 | Batch: 300 | Loss: 0.07243 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 020 | Batch: 400 | Loss: 0.11156 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 020 | Batch: 000 | Loss: 0.17428 | Correct: 118/128\n",
      "Estimator: 001 | Epoch: 020 | Batch: 100 | Loss: 0.11239 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 020 | Batch: 200 | Loss: 0.04038 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 020 | Batch: 300 | Loss: 0.13037 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 020 | Batch: 400 | Loss: 0.12122 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 020 | Batch: 000 | Loss: 0.10148 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 020 | Batch: 100 | Loss: 0.06910 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 020 | Batch: 200 | Loss: 0.13845 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 020 | Batch: 300 | Loss: 0.10658 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 020 | Batch: 400 | Loss: 0.12056 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 020 | Batch: 000 | Loss: 0.15915 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 020 | Batch: 100 | Loss: 0.05472 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 020 | Batch: 200 | Loss: 0.04471 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 020 | Batch: 300 | Loss: 0.10438 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 020 | Batch: 400 | Loss: 0.24522 | Correct: 119/128\n",
      "Estimator: 004 | Epoch: 020 | Batch: 000 | Loss: 0.25138 | Correct: 115/128\n",
      "Estimator: 004 | Epoch: 020 | Batch: 100 | Loss: 0.11094 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 020 | Batch: 200 | Loss: 0.15366 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 020 | Batch: 300 | Loss: 0.07568 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 020 | Batch: 400 | Loss: 0.07926 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 020 | Batch: 000 | Loss: 0.05136 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 020 | Batch: 100 | Loss: 0.10076 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 020 | Batch: 200 | Loss: 0.13719 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 020 | Batch: 300 | Loss: 0.10985 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 020 | Batch: 400 | Loss: 0.16553 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 020 | Batch: 000 | Loss: 0.07256 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 020 | Batch: 100 | Loss: 0.11723 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 020 | Batch: 200 | Loss: 0.11799 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 020 | Batch: 300 | Loss: 0.07681 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 020 | Batch: 400 | Loss: 0.15458 | Correct: 120/128\n",
      "Estimator: 007 | Epoch: 020 | Batch: 000 | Loss: 0.04826 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 020 | Batch: 100 | Loss: 0.09269 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 020 | Batch: 200 | Loss: 0.05379 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 020 | Batch: 300 | Loss: 0.10082 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 020 | Batch: 400 | Loss: 0.16547 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 020 | Batch: 000 | Loss: 0.16629 | Correct: 119/128\n",
      "Estimator: 008 | Epoch: 020 | Batch: 100 | Loss: 0.12407 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 020 | Batch: 200 | Loss: 0.09220 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 020 | Batch: 300 | Loss: 0.12998 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 020 | Batch: 400 | Loss: 0.13454 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 020 | Batch: 000 | Loss: 0.12021 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 020 | Batch: 100 | Loss: 0.09835 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 020 | Batch: 200 | Loss: 0.09701 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 020 | Batch: 300 | Loss: 0.15795 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 020 | Batch: 400 | Loss: 0.06322 | Correct: 124/128\n",
      "2021-02-15 22:30:26,809 - INFO: Epoch: 020 | Validation Acc: 97.880 % | Historical Best: 97.950 %\n",
      "Estimator: 000 | Epoch: 021 | Batch: 000 | Loss: 0.16393 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 021 | Batch: 100 | Loss: 0.09161 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 021 | Batch: 200 | Loss: 0.07828 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 021 | Batch: 300 | Loss: 0.18603 | Correct: 120/128\n",
      "Estimator: 000 | Epoch: 021 | Batch: 400 | Loss: 0.15687 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 021 | Batch: 000 | Loss: 0.08822 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 021 | Batch: 100 | Loss: 0.03692 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 021 | Batch: 200 | Loss: 0.14980 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 021 | Batch: 300 | Loss: 0.18082 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 021 | Batch: 400 | Loss: 0.14986 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 021 | Batch: 000 | Loss: 0.09370 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 021 | Batch: 100 | Loss: 0.09245 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 021 | Batch: 200 | Loss: 0.14382 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 021 | Batch: 300 | Loss: 0.11881 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 021 | Batch: 400 | Loss: 0.08835 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 021 | Batch: 000 | Loss: 0.09074 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 021 | Batch: 100 | Loss: 0.19496 | Correct: 120/128\n",
      "Estimator: 003 | Epoch: 021 | Batch: 200 | Loss: 0.12723 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 021 | Batch: 300 | Loss: 0.06977 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 021 | Batch: 400 | Loss: 0.09780 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 021 | Batch: 000 | Loss: 0.10291 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 021 | Batch: 100 | Loss: 0.09090 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 021 | Batch: 200 | Loss: 0.08378 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 021 | Batch: 300 | Loss: 0.08115 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 021 | Batch: 400 | Loss: 0.17132 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 021 | Batch: 000 | Loss: 0.12444 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 021 | Batch: 100 | Loss: 0.12576 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 021 | Batch: 200 | Loss: 0.09243 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 021 | Batch: 300 | Loss: 0.14464 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 021 | Batch: 400 | Loss: 0.18049 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 021 | Batch: 000 | Loss: 0.07848 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 021 | Batch: 100 | Loss: 0.12354 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 021 | Batch: 200 | Loss: 0.05817 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 021 | Batch: 300 | Loss: 0.12805 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 021 | Batch: 400 | Loss: 0.15930 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 021 | Batch: 000 | Loss: 0.07388 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 021 | Batch: 100 | Loss: 0.12357 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 021 | Batch: 200 | Loss: 0.12935 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 021 | Batch: 300 | Loss: 0.08675 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 021 | Batch: 400 | Loss: 0.09261 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 021 | Batch: 000 | Loss: 0.07534 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 021 | Batch: 100 | Loss: 0.07048 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 021 | Batch: 200 | Loss: 0.19089 | Correct: 119/128\n",
      "Estimator: 008 | Epoch: 021 | Batch: 300 | Loss: 0.11943 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 021 | Batch: 400 | Loss: 0.19250 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 021 | Batch: 000 | Loss: 0.08791 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 021 | Batch: 100 | Loss: 0.14108 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 021 | Batch: 200 | Loss: 0.11395 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 021 | Batch: 300 | Loss: 0.10964 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 021 | Batch: 400 | Loss: 0.37886 | Correct: 118/128\n",
      "2021-02-15 22:32:07,918 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2021-02-15 22:32:07,932 - INFO: Epoch: 021 | Validation Acc: 98.150 % | Historical Best: 98.150 %\n",
      "Estimator: 000 | Epoch: 022 | Batch: 000 | Loss: 0.09644 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 022 | Batch: 100 | Loss: 0.15143 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 022 | Batch: 200 | Loss: 0.14644 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 022 | Batch: 300 | Loss: 0.11598 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 022 | Batch: 400 | Loss: 0.13103 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 022 | Batch: 000 | Loss: 0.20883 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 022 | Batch: 100 | Loss: 0.08852 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 022 | Batch: 200 | Loss: 0.24011 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 022 | Batch: 300 | Loss: 0.22110 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 022 | Batch: 400 | Loss: 0.16008 | Correct: 119/128\n",
      "Estimator: 002 | Epoch: 022 | Batch: 000 | Loss: 0.17051 | Correct: 118/128\n",
      "Estimator: 002 | Epoch: 022 | Batch: 100 | Loss: 0.15549 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 022 | Batch: 200 | Loss: 0.12489 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 022 | Batch: 300 | Loss: 0.09400 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 022 | Batch: 400 | Loss: 0.13270 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 022 | Batch: 000 | Loss: 0.06269 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 022 | Batch: 100 | Loss: 0.11329 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 022 | Batch: 200 | Loss: 0.15446 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 022 | Batch: 300 | Loss: 0.11114 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 022 | Batch: 400 | Loss: 0.24522 | Correct: 117/128\n",
      "Estimator: 004 | Epoch: 022 | Batch: 000 | Loss: 0.12330 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 022 | Batch: 100 | Loss: 0.09191 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 022 | Batch: 200 | Loss: 0.12877 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 022 | Batch: 300 | Loss: 0.04889 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 022 | Batch: 400 | Loss: 0.09523 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 022 | Batch: 000 | Loss: 0.05057 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 022 | Batch: 100 | Loss: 0.04721 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 022 | Batch: 200 | Loss: 0.16286 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 022 | Batch: 300 | Loss: 0.10895 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 022 | Batch: 400 | Loss: 0.10212 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 022 | Batch: 000 | Loss: 0.08768 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 022 | Batch: 100 | Loss: 0.08803 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 022 | Batch: 200 | Loss: 0.08069 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 022 | Batch: 300 | Loss: 0.03588 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 022 | Batch: 400 | Loss: 0.10817 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 022 | Batch: 000 | Loss: 0.08593 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 022 | Batch: 100 | Loss: 0.13514 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 022 | Batch: 200 | Loss: 0.10717 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 022 | Batch: 300 | Loss: 0.06877 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 022 | Batch: 400 | Loss: 0.13749 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 022 | Batch: 000 | Loss: 0.23228 | Correct: 120/128\n",
      "Estimator: 008 | Epoch: 022 | Batch: 100 | Loss: 0.03995 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 022 | Batch: 200 | Loss: 0.15245 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 022 | Batch: 300 | Loss: 0.09011 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 022 | Batch: 400 | Loss: 0.07871 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 022 | Batch: 000 | Loss: 0.16504 | Correct: 120/128\n",
      "Estimator: 009 | Epoch: 022 | Batch: 100 | Loss: 0.06042 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 022 | Batch: 200 | Loss: 0.07740 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 022 | Batch: 300 | Loss: 0.13283 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 022 | Batch: 400 | Loss: 0.18248 | Correct: 124/128\n",
      "2021-02-15 22:33:49,039 - INFO: Epoch: 022 | Validation Acc: 98.000 % | Historical Best: 98.150 %\n",
      "Estimator: 000 | Epoch: 023 | Batch: 000 | Loss: 0.11384 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 023 | Batch: 100 | Loss: 0.11419 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 023 | Batch: 200 | Loss: 0.06351 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 023 | Batch: 300 | Loss: 0.08453 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 023 | Batch: 400 | Loss: 0.14455 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 023 | Batch: 000 | Loss: 0.13333 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 023 | Batch: 100 | Loss: 0.15844 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 023 | Batch: 200 | Loss: 0.17031 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 023 | Batch: 300 | Loss: 0.13121 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 023 | Batch: 400 | Loss: 0.10447 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 023 | Batch: 000 | Loss: 0.07245 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 023 | Batch: 100 | Loss: 0.13862 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 023 | Batch: 200 | Loss: 0.07358 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 023 | Batch: 300 | Loss: 0.15109 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 023 | Batch: 400 | Loss: 0.06720 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 023 | Batch: 000 | Loss: 0.13736 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 023 | Batch: 100 | Loss: 0.09780 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 023 | Batch: 200 | Loss: 0.11724 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 023 | Batch: 300 | Loss: 0.10640 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 023 | Batch: 400 | Loss: 0.07612 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 023 | Batch: 000 | Loss: 0.04130 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 023 | Batch: 100 | Loss: 0.09359 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 023 | Batch: 200 | Loss: 0.12995 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 023 | Batch: 300 | Loss: 0.15646 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 023 | Batch: 400 | Loss: 0.10230 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 023 | Batch: 000 | Loss: 0.10572 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 023 | Batch: 100 | Loss: 0.09301 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 023 | Batch: 200 | Loss: 0.15305 | Correct: 119/128\n",
      "Estimator: 005 | Epoch: 023 | Batch: 300 | Loss: 0.12086 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 023 | Batch: 400 | Loss: 0.11724 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 023 | Batch: 000 | Loss: 0.07181 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 023 | Batch: 100 | Loss: 0.09085 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 023 | Batch: 200 | Loss: 0.15020 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 023 | Batch: 300 | Loss: 0.08319 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 023 | Batch: 400 | Loss: 0.08587 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 023 | Batch: 000 | Loss: 0.10466 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 023 | Batch: 100 | Loss: 0.12191 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 023 | Batch: 200 | Loss: 0.09911 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 023 | Batch: 300 | Loss: 0.16235 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 023 | Batch: 400 | Loss: 0.06526 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 023 | Batch: 000 | Loss: 0.07599 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 023 | Batch: 100 | Loss: 0.07751 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 023 | Batch: 200 | Loss: 0.07470 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 023 | Batch: 300 | Loss: 0.08768 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 023 | Batch: 400 | Loss: 0.15211 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 023 | Batch: 000 | Loss: 0.11346 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 023 | Batch: 100 | Loss: 0.13018 | Correct: 120/128\n",
      "Estimator: 009 | Epoch: 023 | Batch: 200 | Loss: 0.08730 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 023 | Batch: 300 | Loss: 0.03177 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 023 | Batch: 400 | Loss: 0.03223 | Correct: 127/128\n",
      "2021-02-15 22:35:29,726 - INFO: Epoch: 023 | Validation Acc: 98.140 % | Historical Best: 98.150 %\n",
      "Estimator: 000 | Epoch: 024 | Batch: 000 | Loss: 0.03691 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 024 | Batch: 100 | Loss: 0.13711 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 024 | Batch: 200 | Loss: 0.08411 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 024 | Batch: 300 | Loss: 0.14820 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 024 | Batch: 400 | Loss: 0.07031 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 024 | Batch: 000 | Loss: 0.11867 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 024 | Batch: 100 | Loss: 0.11222 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 024 | Batch: 200 | Loss: 0.13155 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 024 | Batch: 300 | Loss: 0.06516 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 024 | Batch: 400 | Loss: 0.24132 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 024 | Batch: 000 | Loss: 0.16869 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 024 | Batch: 100 | Loss: 0.16774 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 024 | Batch: 200 | Loss: 0.08823 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 024 | Batch: 300 | Loss: 0.17194 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 024 | Batch: 400 | Loss: 0.09738 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 024 | Batch: 000 | Loss: 0.10684 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 024 | Batch: 100 | Loss: 0.10241 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 024 | Batch: 200 | Loss: 0.12406 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 024 | Batch: 300 | Loss: 0.07809 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 024 | Batch: 400 | Loss: 0.08389 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 024 | Batch: 000 | Loss: 0.04880 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 024 | Batch: 100 | Loss: 0.12726 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 024 | Batch: 200 | Loss: 0.11613 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 024 | Batch: 300 | Loss: 0.05766 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 024 | Batch: 400 | Loss: 0.09117 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 024 | Batch: 000 | Loss: 0.07693 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 024 | Batch: 100 | Loss: 0.16902 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 024 | Batch: 200 | Loss: 0.10180 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 024 | Batch: 300 | Loss: 0.19435 | Correct: 119/128\n",
      "Estimator: 005 | Epoch: 024 | Batch: 400 | Loss: 0.11201 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 024 | Batch: 000 | Loss: 0.12070 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 024 | Batch: 100 | Loss: 0.08330 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 024 | Batch: 200 | Loss: 0.04782 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 024 | Batch: 300 | Loss: 0.14729 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 024 | Batch: 400 | Loss: 0.06700 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 024 | Batch: 000 | Loss: 0.12697 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 024 | Batch: 100 | Loss: 0.07759 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 024 | Batch: 200 | Loss: 0.11477 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 024 | Batch: 300 | Loss: 0.15378 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 024 | Batch: 400 | Loss: 0.10136 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 024 | Batch: 000 | Loss: 0.05906 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 024 | Batch: 100 | Loss: 0.09013 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 024 | Batch: 200 | Loss: 0.09521 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 024 | Batch: 300 | Loss: 0.07809 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 024 | Batch: 400 | Loss: 0.05631 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 024 | Batch: 000 | Loss: 0.14938 | Correct: 120/128\n",
      "Estimator: 009 | Epoch: 024 | Batch: 100 | Loss: 0.10496 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 024 | Batch: 200 | Loss: 0.21717 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 024 | Batch: 300 | Loss: 0.19067 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 024 | Batch: 400 | Loss: 0.14358 | Correct: 121/128\n",
      "2021-02-15 22:37:10,398 - INFO: Epoch: 024 | Validation Acc: 97.880 % | Historical Best: 98.150 %\n",
      "Estimator: 000 | Epoch: 025 | Batch: 000 | Loss: 0.12060 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 025 | Batch: 100 | Loss: 0.05798 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 025 | Batch: 200 | Loss: 0.12479 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 025 | Batch: 300 | Loss: 0.16683 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 025 | Batch: 400 | Loss: 0.13897 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 025 | Batch: 000 | Loss: 0.09977 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 025 | Batch: 100 | Loss: 0.06437 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 025 | Batch: 200 | Loss: 0.07251 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 025 | Batch: 300 | Loss: 0.14355 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 025 | Batch: 400 | Loss: 0.15966 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 025 | Batch: 000 | Loss: 0.10919 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 025 | Batch: 100 | Loss: 0.13014 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 025 | Batch: 200 | Loss: 0.06328 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 025 | Batch: 300 | Loss: 0.11016 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 025 | Batch: 400 | Loss: 0.10624 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 025 | Batch: 000 | Loss: 0.09319 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 025 | Batch: 100 | Loss: 0.16982 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 025 | Batch: 200 | Loss: 0.11579 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 025 | Batch: 300 | Loss: 0.11694 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 025 | Batch: 400 | Loss: 0.17968 | Correct: 119/128\n",
      "Estimator: 004 | Epoch: 025 | Batch: 000 | Loss: 0.10870 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 025 | Batch: 100 | Loss: 0.14004 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 025 | Batch: 200 | Loss: 0.07063 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 025 | Batch: 300 | Loss: 0.06004 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 025 | Batch: 400 | Loss: 0.10226 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 025 | Batch: 000 | Loss: 0.13819 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 025 | Batch: 100 | Loss: 0.13690 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 025 | Batch: 200 | Loss: 0.04621 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 025 | Batch: 300 | Loss: 0.06176 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 025 | Batch: 400 | Loss: 0.08490 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 025 | Batch: 000 | Loss: 0.14673 | Correct: 119/128\n",
      "Estimator: 006 | Epoch: 025 | Batch: 100 | Loss: 0.21054 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 025 | Batch: 200 | Loss: 0.11746 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 025 | Batch: 300 | Loss: 0.14691 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 025 | Batch: 400 | Loss: 0.06177 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 025 | Batch: 000 | Loss: 0.10082 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 025 | Batch: 100 | Loss: 0.08791 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 025 | Batch: 200 | Loss: 0.09129 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 025 | Batch: 300 | Loss: 0.10992 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 025 | Batch: 400 | Loss: 0.12655 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 025 | Batch: 000 | Loss: 0.15076 | Correct: 120/128\n",
      "Estimator: 008 | Epoch: 025 | Batch: 100 | Loss: 0.05420 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 025 | Batch: 200 | Loss: 0.11494 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 025 | Batch: 300 | Loss: 0.17260 | Correct: 120/128\n",
      "Estimator: 008 | Epoch: 025 | Batch: 400 | Loss: 0.07223 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 025 | Batch: 000 | Loss: 0.17202 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 025 | Batch: 100 | Loss: 0.21060 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 025 | Batch: 200 | Loss: 0.02509 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 025 | Batch: 300 | Loss: 0.26488 | Correct: 120/128\n",
      "Estimator: 009 | Epoch: 025 | Batch: 400 | Loss: 0.11378 | Correct: 122/128\n",
      "2021-02-15 22:38:51,321 - INFO: Epoch: 025 | Validation Acc: 98.010 % | Historical Best: 98.150 %\n",
      "Estimator: 000 | Epoch: 026 | Batch: 000 | Loss: 0.09182 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 026 | Batch: 100 | Loss: 0.02084 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 026 | Batch: 200 | Loss: 0.09878 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 026 | Batch: 300 | Loss: 0.15292 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 026 | Batch: 400 | Loss: 0.22405 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 026 | Batch: 000 | Loss: 0.08996 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 026 | Batch: 100 | Loss: 0.08504 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 026 | Batch: 200 | Loss: 0.17344 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 026 | Batch: 300 | Loss: 0.09399 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 026 | Batch: 400 | Loss: 0.31069 | Correct: 114/128\n",
      "Estimator: 002 | Epoch: 026 | Batch: 000 | Loss: 0.09223 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 026 | Batch: 100 | Loss: 0.04586 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 026 | Batch: 200 | Loss: 0.07923 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 026 | Batch: 300 | Loss: 0.12750 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 026 | Batch: 400 | Loss: 0.09327 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 026 | Batch: 000 | Loss: 0.14377 | Correct: 120/128\n",
      "Estimator: 003 | Epoch: 026 | Batch: 100 | Loss: 0.05651 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 026 | Batch: 200 | Loss: 0.10071 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 026 | Batch: 300 | Loss: 0.12308 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 026 | Batch: 400 | Loss: 0.17356 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 026 | Batch: 000 | Loss: 0.11232 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 026 | Batch: 100 | Loss: 0.09593 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 026 | Batch: 200 | Loss: 0.06878 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 026 | Batch: 300 | Loss: 0.20768 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 026 | Batch: 400 | Loss: 0.25585 | Correct: 118/128\n",
      "Estimator: 005 | Epoch: 026 | Batch: 000 | Loss: 0.19846 | Correct: 119/128\n",
      "Estimator: 005 | Epoch: 026 | Batch: 100 | Loss: 0.14153 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 026 | Batch: 200 | Loss: 0.09287 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 026 | Batch: 300 | Loss: 0.07447 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 026 | Batch: 400 | Loss: 0.08848 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 026 | Batch: 000 | Loss: 0.05047 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 026 | Batch: 100 | Loss: 0.14289 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 026 | Batch: 200 | Loss: 0.07986 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 026 | Batch: 300 | Loss: 0.29242 | Correct: 118/128\n",
      "Estimator: 006 | Epoch: 026 | Batch: 400 | Loss: 0.11993 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 026 | Batch: 000 | Loss: 0.07030 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 026 | Batch: 100 | Loss: 0.05698 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 026 | Batch: 200 | Loss: 0.11272 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 026 | Batch: 300 | Loss: 0.05941 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 026 | Batch: 400 | Loss: 0.18540 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 026 | Batch: 000 | Loss: 0.09764 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 026 | Batch: 100 | Loss: 0.10791 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 026 | Batch: 200 | Loss: 0.11390 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 026 | Batch: 300 | Loss: 0.16777 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 026 | Batch: 400 | Loss: 0.06269 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 026 | Batch: 000 | Loss: 0.13339 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 026 | Batch: 100 | Loss: 0.07685 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 026 | Batch: 200 | Loss: 0.12200 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 026 | Batch: 300 | Loss: 0.16897 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 026 | Batch: 400 | Loss: 0.08283 | Correct: 124/128\n",
      "2021-02-15 22:40:32,569 - INFO: Epoch: 026 | Validation Acc: 97.770 % | Historical Best: 98.150 %\n",
      "Estimator: 000 | Epoch: 027 | Batch: 000 | Loss: 0.09890 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 027 | Batch: 100 | Loss: 0.10185 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 027 | Batch: 200 | Loss: 0.09461 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 027 | Batch: 300 | Loss: 0.11599 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 027 | Batch: 400 | Loss: 0.10917 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 027 | Batch: 000 | Loss: 0.07727 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 027 | Batch: 100 | Loss: 0.10996 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 027 | Batch: 200 | Loss: 0.04507 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 027 | Batch: 300 | Loss: 0.06486 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 027 | Batch: 400 | Loss: 0.19176 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 027 | Batch: 000 | Loss: 0.10992 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 027 | Batch: 100 | Loss: 0.10251 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 027 | Batch: 200 | Loss: 0.08883 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 027 | Batch: 300 | Loss: 0.21003 | Correct: 119/128\n",
      "Estimator: 002 | Epoch: 027 | Batch: 400 | Loss: 0.05131 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 027 | Batch: 000 | Loss: 0.10441 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 027 | Batch: 100 | Loss: 0.09253 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 027 | Batch: 200 | Loss: 0.08295 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 027 | Batch: 300 | Loss: 0.13561 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 027 | Batch: 400 | Loss: 0.19703 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 027 | Batch: 000 | Loss: 0.24313 | Correct: 118/128\n",
      "Estimator: 004 | Epoch: 027 | Batch: 100 | Loss: 0.05326 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 027 | Batch: 200 | Loss: 0.14858 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 027 | Batch: 300 | Loss: 0.05552 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 027 | Batch: 400 | Loss: 0.21822 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 027 | Batch: 000 | Loss: 0.10915 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 027 | Batch: 100 | Loss: 0.13323 | Correct: 119/128\n",
      "Estimator: 005 | Epoch: 027 | Batch: 200 | Loss: 0.14859 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 027 | Batch: 300 | Loss: 0.07573 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 027 | Batch: 400 | Loss: 0.07046 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 027 | Batch: 000 | Loss: 0.08798 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 027 | Batch: 100 | Loss: 0.04791 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 027 | Batch: 200 | Loss: 0.10170 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 027 | Batch: 300 | Loss: 0.10787 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 027 | Batch: 400 | Loss: 0.07053 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 027 | Batch: 000 | Loss: 0.08308 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 027 | Batch: 100 | Loss: 0.16186 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 027 | Batch: 200 | Loss: 0.11443 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 027 | Batch: 300 | Loss: 0.08361 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 027 | Batch: 400 | Loss: 0.13087 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 027 | Batch: 000 | Loss: 0.09695 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 027 | Batch: 100 | Loss: 0.11166 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 027 | Batch: 200 | Loss: 0.09465 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 027 | Batch: 300 | Loss: 0.04918 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 027 | Batch: 400 | Loss: 0.13830 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 027 | Batch: 000 | Loss: 0.09158 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 027 | Batch: 100 | Loss: 0.07407 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 027 | Batch: 200 | Loss: 0.05700 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 027 | Batch: 300 | Loss: 0.10482 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 027 | Batch: 400 | Loss: 0.25985 | Correct: 119/128\n",
      "2021-02-15 22:42:13,503 - INFO: Epoch: 027 | Validation Acc: 97.940 % | Historical Best: 98.150 %\n",
      "Estimator: 000 | Epoch: 028 | Batch: 000 | Loss: 0.14928 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 028 | Batch: 100 | Loss: 0.12380 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 028 | Batch: 200 | Loss: 0.10358 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 028 | Batch: 300 | Loss: 0.12660 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 028 | Batch: 400 | Loss: 0.07979 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 028 | Batch: 000 | Loss: 0.06748 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 028 | Batch: 100 | Loss: 0.04613 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 028 | Batch: 200 | Loss: 0.10682 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 028 | Batch: 300 | Loss: 0.12580 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 028 | Batch: 400 | Loss: 0.20018 | Correct: 119/128\n",
      "Estimator: 002 | Epoch: 028 | Batch: 000 | Loss: 0.09768 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 028 | Batch: 100 | Loss: 0.18571 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 028 | Batch: 200 | Loss: 0.11965 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 028 | Batch: 300 | Loss: 0.12644 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 028 | Batch: 400 | Loss: 0.05714 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 028 | Batch: 000 | Loss: 0.13466 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 028 | Batch: 100 | Loss: 0.08554 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 028 | Batch: 200 | Loss: 0.16600 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 028 | Batch: 300 | Loss: 0.16820 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 028 | Batch: 400 | Loss: 0.13452 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 028 | Batch: 000 | Loss: 0.07632 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 028 | Batch: 100 | Loss: 0.09437 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 028 | Batch: 200 | Loss: 0.18808 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 028 | Batch: 300 | Loss: 0.28108 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 028 | Batch: 400 | Loss: 0.09176 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 028 | Batch: 000 | Loss: 0.23309 | Correct: 119/128\n",
      "Estimator: 005 | Epoch: 028 | Batch: 100 | Loss: 0.12020 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 028 | Batch: 200 | Loss: 0.05641 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 028 | Batch: 300 | Loss: 0.19640 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 028 | Batch: 400 | Loss: 0.07530 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 028 | Batch: 000 | Loss: 0.04137 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 028 | Batch: 100 | Loss: 0.16010 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 028 | Batch: 200 | Loss: 0.15944 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 028 | Batch: 300 | Loss: 0.07996 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 028 | Batch: 400 | Loss: 0.09917 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 028 | Batch: 000 | Loss: 0.09573 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 028 | Batch: 100 | Loss: 0.08153 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 028 | Batch: 200 | Loss: 0.16184 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 028 | Batch: 300 | Loss: 0.10729 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 028 | Batch: 400 | Loss: 0.13243 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 028 | Batch: 000 | Loss: 0.05130 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 028 | Batch: 100 | Loss: 0.17355 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 028 | Batch: 200 | Loss: 0.11679 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 028 | Batch: 300 | Loss: 0.16575 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 028 | Batch: 400 | Loss: 0.13612 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 028 | Batch: 000 | Loss: 0.04923 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 028 | Batch: 100 | Loss: 0.15009 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 028 | Batch: 200 | Loss: 0.15322 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 028 | Batch: 300 | Loss: 0.07676 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 028 | Batch: 400 | Loss: 0.08896 | Correct: 124/128\n",
      "2021-02-15 22:43:54,577 - INFO: Epoch: 028 | Validation Acc: 97.960 % | Historical Best: 98.150 %\n",
      "Estimator: 000 | Epoch: 029 | Batch: 000 | Loss: 0.08357 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 029 | Batch: 100 | Loss: 0.04121 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 029 | Batch: 200 | Loss: 0.07430 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 029 | Batch: 300 | Loss: 0.14395 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 029 | Batch: 400 | Loss: 0.11680 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 029 | Batch: 000 | Loss: 0.07830 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 029 | Batch: 100 | Loss: 0.15858 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 029 | Batch: 200 | Loss: 0.06889 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 029 | Batch: 300 | Loss: 0.13140 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 029 | Batch: 400 | Loss: 0.12859 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 029 | Batch: 000 | Loss: 0.07966 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 029 | Batch: 100 | Loss: 0.07659 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 029 | Batch: 200 | Loss: 0.11031 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 029 | Batch: 300 | Loss: 0.05484 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 029 | Batch: 400 | Loss: 0.05349 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 029 | Batch: 000 | Loss: 0.07431 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 029 | Batch: 100 | Loss: 0.07011 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 029 | Batch: 200 | Loss: 0.08436 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 029 | Batch: 300 | Loss: 0.14238 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 029 | Batch: 400 | Loss: 0.17305 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 029 | Batch: 000 | Loss: 0.10095 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 029 | Batch: 100 | Loss: 0.08497 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 029 | Batch: 200 | Loss: 0.12017 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 029 | Batch: 300 | Loss: 0.12627 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 029 | Batch: 400 | Loss: 0.11616 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 029 | Batch: 000 | Loss: 0.06163 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 029 | Batch: 100 | Loss: 0.08301 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 029 | Batch: 200 | Loss: 0.22207 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 029 | Batch: 300 | Loss: 0.08507 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 029 | Batch: 400 | Loss: 0.11634 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 029 | Batch: 000 | Loss: 0.13963 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 029 | Batch: 100 | Loss: 0.11997 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 029 | Batch: 200 | Loss: 0.08154 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 029 | Batch: 300 | Loss: 0.14121 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 029 | Batch: 400 | Loss: 0.07635 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 029 | Batch: 000 | Loss: 0.09993 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 029 | Batch: 100 | Loss: 0.12616 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 029 | Batch: 200 | Loss: 0.19246 | Correct: 119/128\n",
      "Estimator: 007 | Epoch: 029 | Batch: 300 | Loss: 0.08538 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 029 | Batch: 400 | Loss: 0.15828 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 029 | Batch: 000 | Loss: 0.04484 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 029 | Batch: 100 | Loss: 0.08727 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 029 | Batch: 200 | Loss: 0.19547 | Correct: 119/128\n",
      "Estimator: 008 | Epoch: 029 | Batch: 300 | Loss: 0.10504 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 029 | Batch: 400 | Loss: 0.12977 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 029 | Batch: 000 | Loss: 0.18302 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 029 | Batch: 100 | Loss: 0.08662 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 029 | Batch: 200 | Loss: 0.10817 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 029 | Batch: 300 | Loss: 0.15463 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 029 | Batch: 400 | Loss: 0.14619 | Correct: 123/128\n",
      "2021-02-15 22:45:35,358 - INFO: Epoch: 029 | Validation Acc: 97.990 % | Historical Best: 98.150 %\n",
      "Estimator: 000 | Epoch: 030 | Batch: 000 | Loss: 0.05830 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 030 | Batch: 100 | Loss: 0.15349 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 030 | Batch: 200 | Loss: 0.05720 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 030 | Batch: 300 | Loss: 0.12050 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 030 | Batch: 400 | Loss: 0.13133 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 030 | Batch: 000 | Loss: 0.07856 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 030 | Batch: 100 | Loss: 0.04373 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 030 | Batch: 200 | Loss: 0.07381 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 030 | Batch: 300 | Loss: 0.14105 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 030 | Batch: 400 | Loss: 0.13046 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 030 | Batch: 000 | Loss: 0.06940 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 030 | Batch: 100 | Loss: 0.06726 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 030 | Batch: 200 | Loss: 0.13763 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 030 | Batch: 300 | Loss: 0.05706 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 030 | Batch: 400 | Loss: 0.04737 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 030 | Batch: 000 | Loss: 0.10263 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 030 | Batch: 100 | Loss: 0.08784 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 030 | Batch: 200 | Loss: 0.02940 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 030 | Batch: 300 | Loss: 0.08465 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 030 | Batch: 400 | Loss: 0.06250 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 030 | Batch: 000 | Loss: 0.11782 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 030 | Batch: 100 | Loss: 0.09700 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 030 | Batch: 200 | Loss: 0.06906 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 030 | Batch: 300 | Loss: 0.14258 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 030 | Batch: 400 | Loss: 0.08884 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 030 | Batch: 000 | Loss: 0.05072 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 030 | Batch: 100 | Loss: 0.07454 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 030 | Batch: 200 | Loss: 0.12576 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 030 | Batch: 300 | Loss: 0.11079 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 030 | Batch: 400 | Loss: 0.09770 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 030 | Batch: 000 | Loss: 0.08411 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 030 | Batch: 100 | Loss: 0.08375 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 030 | Batch: 200 | Loss: 0.07452 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 030 | Batch: 300 | Loss: 0.18183 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 030 | Batch: 400 | Loss: 0.15107 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 030 | Batch: 000 | Loss: 0.15303 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 030 | Batch: 100 | Loss: 0.14460 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 030 | Batch: 200 | Loss: 0.14039 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 030 | Batch: 300 | Loss: 0.12588 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 030 | Batch: 400 | Loss: 0.13418 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 030 | Batch: 000 | Loss: 0.13789 | Correct: 120/128\n",
      "Estimator: 008 | Epoch: 030 | Batch: 100 | Loss: 0.11806 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 030 | Batch: 200 | Loss: 0.15425 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 030 | Batch: 300 | Loss: 0.23842 | Correct: 118/128\n",
      "Estimator: 008 | Epoch: 030 | Batch: 400 | Loss: 0.17984 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 030 | Batch: 000 | Loss: 0.21385 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 030 | Batch: 100 | Loss: 0.08373 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 030 | Batch: 200 | Loss: 0.18328 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 030 | Batch: 300 | Loss: 0.07242 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 030 | Batch: 400 | Loss: 0.08451 | Correct: 126/128\n",
      "2021-02-15 22:47:16,003 - INFO: Epoch: 030 | Validation Acc: 97.840 % | Historical Best: 98.150 %\n",
      "Estimator: 000 | Epoch: 031 | Batch: 000 | Loss: 0.10171 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 031 | Batch: 100 | Loss: 0.04437 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 031 | Batch: 200 | Loss: 0.07497 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 031 | Batch: 300 | Loss: 0.17913 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 031 | Batch: 400 | Loss: 0.14469 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 031 | Batch: 000 | Loss: 0.06956 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 031 | Batch: 100 | Loss: 0.20298 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 031 | Batch: 200 | Loss: 0.10141 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 031 | Batch: 300 | Loss: 0.18755 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 031 | Batch: 400 | Loss: 0.17693 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 031 | Batch: 000 | Loss: 0.16851 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 031 | Batch: 100 | Loss: 0.04004 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 031 | Batch: 200 | Loss: 0.09349 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 031 | Batch: 300 | Loss: 0.12752 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 031 | Batch: 400 | Loss: 0.05850 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 031 | Batch: 000 | Loss: 0.05732 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 031 | Batch: 100 | Loss: 0.10451 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 031 | Batch: 200 | Loss: 0.10205 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 031 | Batch: 300 | Loss: 0.15917 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 031 | Batch: 400 | Loss: 0.09411 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 031 | Batch: 000 | Loss: 0.12371 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 031 | Batch: 100 | Loss: 0.15281 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 031 | Batch: 200 | Loss: 0.06010 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 031 | Batch: 300 | Loss: 0.09135 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 031 | Batch: 400 | Loss: 0.17735 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 031 | Batch: 000 | Loss: 0.15635 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 031 | Batch: 100 | Loss: 0.10884 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 031 | Batch: 200 | Loss: 0.08481 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 031 | Batch: 300 | Loss: 0.06400 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 031 | Batch: 400 | Loss: 0.06148 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 031 | Batch: 000 | Loss: 0.19628 | Correct: 118/128\n",
      "Estimator: 006 | Epoch: 031 | Batch: 100 | Loss: 0.07741 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 031 | Batch: 200 | Loss: 0.07158 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 031 | Batch: 300 | Loss: 0.10607 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 031 | Batch: 400 | Loss: 0.13414 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 031 | Batch: 000 | Loss: 0.14746 | Correct: 120/128\n",
      "Estimator: 007 | Epoch: 031 | Batch: 100 | Loss: 0.12973 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 031 | Batch: 200 | Loss: 0.11777 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 031 | Batch: 300 | Loss: 0.16569 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 031 | Batch: 400 | Loss: 0.12115 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 031 | Batch: 000 | Loss: 0.07427 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 031 | Batch: 100 | Loss: 0.07529 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 031 | Batch: 200 | Loss: 0.08826 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 031 | Batch: 300 | Loss: 0.13069 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 031 | Batch: 400 | Loss: 0.15739 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 031 | Batch: 000 | Loss: 0.06131 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 031 | Batch: 100 | Loss: 0.13205 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 031 | Batch: 200 | Loss: 0.20465 | Correct: 118/128\n",
      "Estimator: 009 | Epoch: 031 | Batch: 300 | Loss: 0.17200 | Correct: 120/128\n",
      "Estimator: 009 | Epoch: 031 | Batch: 400 | Loss: 0.09964 | Correct: 124/128\n",
      "2021-02-15 22:48:56,859 - INFO: Epoch: 031 | Validation Acc: 98.020 % | Historical Best: 98.150 %\n",
      "Estimator: 000 | Epoch: 032 | Batch: 000 | Loss: 0.11308 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 032 | Batch: 100 | Loss: 0.14598 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 032 | Batch: 200 | Loss: 0.06891 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 032 | Batch: 300 | Loss: 0.13191 | Correct: 119/128\n",
      "Estimator: 000 | Epoch: 032 | Batch: 400 | Loss: 0.10729 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 032 | Batch: 000 | Loss: 0.07168 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 032 | Batch: 100 | Loss: 0.22419 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 032 | Batch: 200 | Loss: 0.11812 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 032 | Batch: 300 | Loss: 0.07856 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 032 | Batch: 400 | Loss: 0.12352 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 032 | Batch: 000 | Loss: 0.11785 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 032 | Batch: 100 | Loss: 0.06111 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 032 | Batch: 200 | Loss: 0.14378 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 032 | Batch: 300 | Loss: 0.14248 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 032 | Batch: 400 | Loss: 0.10033 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 032 | Batch: 000 | Loss: 0.21735 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 032 | Batch: 100 | Loss: 0.09253 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 032 | Batch: 200 | Loss: 0.05931 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 032 | Batch: 300 | Loss: 0.13701 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 032 | Batch: 400 | Loss: 0.11209 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 032 | Batch: 000 | Loss: 0.10467 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 032 | Batch: 100 | Loss: 0.17026 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 032 | Batch: 200 | Loss: 0.06743 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 032 | Batch: 300 | Loss: 0.09542 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 032 | Batch: 400 | Loss: 0.09089 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 032 | Batch: 000 | Loss: 0.03898 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 032 | Batch: 100 | Loss: 0.09679 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 032 | Batch: 200 | Loss: 0.10900 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 032 | Batch: 300 | Loss: 0.19829 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 032 | Batch: 400 | Loss: 0.13574 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 032 | Batch: 000 | Loss: 0.11774 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 032 | Batch: 100 | Loss: 0.05977 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 032 | Batch: 200 | Loss: 0.05560 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 032 | Batch: 300 | Loss: 0.07415 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 032 | Batch: 400 | Loss: 0.05424 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 032 | Batch: 000 | Loss: 0.07338 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 032 | Batch: 100 | Loss: 0.05984 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 032 | Batch: 200 | Loss: 0.13234 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 032 | Batch: 300 | Loss: 0.16664 | Correct: 119/128\n",
      "Estimator: 007 | Epoch: 032 | Batch: 400 | Loss: 0.14252 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 032 | Batch: 000 | Loss: 0.06289 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 032 | Batch: 100 | Loss: 0.13326 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 032 | Batch: 200 | Loss: 0.11159 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 032 | Batch: 300 | Loss: 0.10167 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 032 | Batch: 400 | Loss: 0.10969 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 032 | Batch: 000 | Loss: 0.07738 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 032 | Batch: 100 | Loss: 0.10151 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 032 | Batch: 200 | Loss: 0.02720 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 032 | Batch: 300 | Loss: 0.05898 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 032 | Batch: 400 | Loss: 0.11918 | Correct: 123/128\n",
      "2021-02-15 22:50:38,020 - INFO: Epoch: 032 | Validation Acc: 97.970 % | Historical Best: 98.150 %\n",
      "Estimator: 000 | Epoch: 033 | Batch: 000 | Loss: 0.15685 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 033 | Batch: 100 | Loss: 0.13967 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 033 | Batch: 200 | Loss: 0.07554 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 033 | Batch: 300 | Loss: 0.18089 | Correct: 120/128\n",
      "Estimator: 000 | Epoch: 033 | Batch: 400 | Loss: 0.13342 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 033 | Batch: 000 | Loss: 0.18295 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 033 | Batch: 100 | Loss: 0.06233 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 033 | Batch: 200 | Loss: 0.04603 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 033 | Batch: 300 | Loss: 0.13521 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 033 | Batch: 400 | Loss: 0.06208 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 033 | Batch: 000 | Loss: 0.18268 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 033 | Batch: 100 | Loss: 0.07808 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 033 | Batch: 200 | Loss: 0.19595 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 033 | Batch: 300 | Loss: 0.11621 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 033 | Batch: 400 | Loss: 0.10989 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 033 | Batch: 000 | Loss: 0.12154 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 033 | Batch: 100 | Loss: 0.15178 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 033 | Batch: 200 | Loss: 0.12963 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 033 | Batch: 300 | Loss: 0.10848 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 033 | Batch: 400 | Loss: 0.11574 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 033 | Batch: 000 | Loss: 0.11156 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 033 | Batch: 100 | Loss: 0.16884 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 033 | Batch: 200 | Loss: 0.04766 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 033 | Batch: 300 | Loss: 0.19348 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 033 | Batch: 400 | Loss: 0.05399 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 033 | Batch: 000 | Loss: 0.13723 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 033 | Batch: 100 | Loss: 0.17143 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 033 | Batch: 200 | Loss: 0.12399 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 033 | Batch: 300 | Loss: 0.10024 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 033 | Batch: 400 | Loss: 0.10810 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 033 | Batch: 000 | Loss: 0.08095 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 033 | Batch: 100 | Loss: 0.06829 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 033 | Batch: 200 | Loss: 0.15791 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 033 | Batch: 300 | Loss: 0.13392 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 033 | Batch: 400 | Loss: 0.04450 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 033 | Batch: 000 | Loss: 0.14057 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 033 | Batch: 100 | Loss: 0.06980 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 033 | Batch: 200 | Loss: 0.08530 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 033 | Batch: 300 | Loss: 0.07565 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 033 | Batch: 400 | Loss: 0.07888 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 033 | Batch: 000 | Loss: 0.11531 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 033 | Batch: 100 | Loss: 0.07187 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 033 | Batch: 200 | Loss: 0.10318 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 033 | Batch: 300 | Loss: 0.10910 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 033 | Batch: 400 | Loss: 0.07320 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 033 | Batch: 000 | Loss: 0.04879 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 033 | Batch: 100 | Loss: 0.09696 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 033 | Batch: 200 | Loss: 0.12397 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 033 | Batch: 300 | Loss: 0.10240 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 033 | Batch: 400 | Loss: 0.06401 | Correct: 125/128\n",
      "2021-02-15 22:52:19,836 - INFO: Epoch: 033 | Validation Acc: 98.030 % | Historical Best: 98.150 %\n",
      "Estimator: 000 | Epoch: 034 | Batch: 000 | Loss: 0.07840 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 034 | Batch: 100 | Loss: 0.09872 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 034 | Batch: 200 | Loss: 0.04631 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 034 | Batch: 300 | Loss: 0.13274 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 034 | Batch: 400 | Loss: 0.17887 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 034 | Batch: 000 | Loss: 0.09305 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 034 | Batch: 100 | Loss: 0.13352 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 034 | Batch: 200 | Loss: 0.09707 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 034 | Batch: 300 | Loss: 0.16986 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 034 | Batch: 400 | Loss: 0.13324 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 034 | Batch: 000 | Loss: 0.14428 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 034 | Batch: 100 | Loss: 0.08274 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 034 | Batch: 200 | Loss: 0.12536 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 034 | Batch: 300 | Loss: 0.13694 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 034 | Batch: 400 | Loss: 0.10075 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 034 | Batch: 000 | Loss: 0.12802 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 034 | Batch: 100 | Loss: 0.04274 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 034 | Batch: 200 | Loss: 0.06249 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 034 | Batch: 300 | Loss: 0.06744 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 034 | Batch: 400 | Loss: 0.10583 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 034 | Batch: 000 | Loss: 0.15644 | Correct: 118/128\n",
      "Estimator: 004 | Epoch: 034 | Batch: 100 | Loss: 0.10423 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 034 | Batch: 200 | Loss: 0.10374 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 034 | Batch: 300 | Loss: 0.22052 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 034 | Batch: 400 | Loss: 0.05899 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 034 | Batch: 000 | Loss: 0.07395 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 034 | Batch: 100 | Loss: 0.08237 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 034 | Batch: 200 | Loss: 0.07157 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 034 | Batch: 300 | Loss: 0.14026 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 034 | Batch: 400 | Loss: 0.14240 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 034 | Batch: 000 | Loss: 0.17892 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 034 | Batch: 100 | Loss: 0.10164 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 034 | Batch: 200 | Loss: 0.09769 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 034 | Batch: 300 | Loss: 0.04888 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 034 | Batch: 400 | Loss: 0.10050 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 034 | Batch: 000 | Loss: 0.05898 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 034 | Batch: 100 | Loss: 0.07041 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 034 | Batch: 200 | Loss: 0.12093 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 034 | Batch: 300 | Loss: 0.15368 | Correct: 119/128\n",
      "Estimator: 007 | Epoch: 034 | Batch: 400 | Loss: 0.15503 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 034 | Batch: 000 | Loss: 0.03380 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 034 | Batch: 100 | Loss: 0.06432 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 034 | Batch: 200 | Loss: 0.09849 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 034 | Batch: 300 | Loss: 0.08924 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 034 | Batch: 400 | Loss: 0.12429 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 034 | Batch: 000 | Loss: 0.05763 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 034 | Batch: 100 | Loss: 0.09542 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 034 | Batch: 200 | Loss: 0.03869 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 034 | Batch: 300 | Loss: 0.15118 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 034 | Batch: 400 | Loss: 0.12183 | Correct: 123/128\n",
      "2021-02-15 22:54:01,594 - INFO: Epoch: 034 | Validation Acc: 98.020 % | Historical Best: 98.150 %\n",
      "Estimator: 000 | Epoch: 035 | Batch: 000 | Loss: 0.12219 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 035 | Batch: 100 | Loss: 0.07964 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 035 | Batch: 200 | Loss: 0.14014 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 035 | Batch: 300 | Loss: 0.07915 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 035 | Batch: 400 | Loss: 0.16697 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 035 | Batch: 000 | Loss: 0.09136 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 035 | Batch: 100 | Loss: 0.13160 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 035 | Batch: 200 | Loss: 0.15287 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 035 | Batch: 300 | Loss: 0.16122 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 035 | Batch: 400 | Loss: 0.14450 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 035 | Batch: 000 | Loss: 0.10023 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 035 | Batch: 100 | Loss: 0.12663 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 035 | Batch: 200 | Loss: 0.07897 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 035 | Batch: 300 | Loss: 0.11641 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 035 | Batch: 400 | Loss: 0.04164 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 035 | Batch: 000 | Loss: 0.11684 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 035 | Batch: 100 | Loss: 0.08407 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 035 | Batch: 200 | Loss: 0.14268 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 035 | Batch: 300 | Loss: 0.08120 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 035 | Batch: 400 | Loss: 0.05348 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 035 | Batch: 000 | Loss: 0.07252 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 035 | Batch: 100 | Loss: 0.08539 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 035 | Batch: 200 | Loss: 0.17722 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 035 | Batch: 300 | Loss: 0.07506 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 035 | Batch: 400 | Loss: 0.23335 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 035 | Batch: 000 | Loss: 0.12910 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 035 | Batch: 100 | Loss: 0.13052 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 035 | Batch: 200 | Loss: 0.12591 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 035 | Batch: 300 | Loss: 0.14252 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 035 | Batch: 400 | Loss: 0.12361 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 035 | Batch: 000 | Loss: 0.08851 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 035 | Batch: 100 | Loss: 0.08040 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 035 | Batch: 200 | Loss: 0.06825 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 035 | Batch: 300 | Loss: 0.11197 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 035 | Batch: 400 | Loss: 0.13043 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 035 | Batch: 000 | Loss: 0.27486 | Correct: 120/128\n",
      "Estimator: 007 | Epoch: 035 | Batch: 100 | Loss: 0.07070 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 035 | Batch: 200 | Loss: 0.12354 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 035 | Batch: 300 | Loss: 0.16549 | Correct: 119/128\n",
      "Estimator: 007 | Epoch: 035 | Batch: 400 | Loss: 0.08231 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 035 | Batch: 000 | Loss: 0.20031 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 035 | Batch: 100 | Loss: 0.18624 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 035 | Batch: 200 | Loss: 0.09803 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 035 | Batch: 300 | Loss: 0.14976 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 035 | Batch: 400 | Loss: 0.04396 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 035 | Batch: 000 | Loss: 0.09625 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 035 | Batch: 100 | Loss: 0.08691 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 035 | Batch: 200 | Loss: 0.08448 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 035 | Batch: 300 | Loss: 0.10404 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 035 | Batch: 400 | Loss: 0.17797 | Correct: 120/128\n",
      "2021-02-15 22:55:44,070 - INFO: Epoch: 035 | Validation Acc: 98.030 % | Historical Best: 98.150 %\n",
      "Estimator: 000 | Epoch: 036 | Batch: 000 | Loss: 0.14120 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 036 | Batch: 100 | Loss: 0.06381 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 036 | Batch: 200 | Loss: 0.09561 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 036 | Batch: 300 | Loss: 0.13324 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 036 | Batch: 400 | Loss: 0.14118 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 036 | Batch: 000 | Loss: 0.05984 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 036 | Batch: 100 | Loss: 0.10922 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 036 | Batch: 200 | Loss: 0.12448 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 036 | Batch: 300 | Loss: 0.14595 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 036 | Batch: 400 | Loss: 0.12112 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 036 | Batch: 000 | Loss: 0.10634 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 036 | Batch: 100 | Loss: 0.10532 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 036 | Batch: 200 | Loss: 0.22345 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 036 | Batch: 300 | Loss: 0.19667 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 036 | Batch: 400 | Loss: 0.07873 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 036 | Batch: 000 | Loss: 0.12392 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 036 | Batch: 100 | Loss: 0.08859 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 036 | Batch: 200 | Loss: 0.10209 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 036 | Batch: 300 | Loss: 0.20624 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 036 | Batch: 400 | Loss: 0.05279 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 036 | Batch: 000 | Loss: 0.10896 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 036 | Batch: 100 | Loss: 0.08331 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 036 | Batch: 200 | Loss: 0.05466 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 036 | Batch: 300 | Loss: 0.06645 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 036 | Batch: 400 | Loss: 0.07964 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 036 | Batch: 000 | Loss: 0.04069 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 036 | Batch: 100 | Loss: 0.09904 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 036 | Batch: 200 | Loss: 0.15321 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 036 | Batch: 300 | Loss: 0.13390 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 036 | Batch: 400 | Loss: 0.11249 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 036 | Batch: 000 | Loss: 0.06532 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 036 | Batch: 100 | Loss: 0.08108 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 036 | Batch: 200 | Loss: 0.13297 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 036 | Batch: 300 | Loss: 0.09173 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 036 | Batch: 400 | Loss: 0.13412 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 036 | Batch: 000 | Loss: 0.20054 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 036 | Batch: 100 | Loss: 0.08480 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 036 | Batch: 200 | Loss: 0.11980 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 036 | Batch: 300 | Loss: 0.12928 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 036 | Batch: 400 | Loss: 0.08835 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 036 | Batch: 000 | Loss: 0.08280 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 036 | Batch: 100 | Loss: 0.14407 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 036 | Batch: 200 | Loss: 0.12884 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 036 | Batch: 300 | Loss: 0.10015 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 036 | Batch: 400 | Loss: 0.10357 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 036 | Batch: 000 | Loss: 0.05851 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 036 | Batch: 100 | Loss: 0.12323 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 036 | Batch: 200 | Loss: 0.06045 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 036 | Batch: 300 | Loss: 0.14949 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 036 | Batch: 400 | Loss: 0.06768 | Correct: 125/128\n",
      "2021-02-15 22:57:26,295 - INFO: Epoch: 036 | Validation Acc: 98.030 % | Historical Best: 98.150 %\n",
      "Estimator: 000 | Epoch: 037 | Batch: 000 | Loss: 0.06951 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 037 | Batch: 100 | Loss: 0.10985 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 037 | Batch: 200 | Loss: 0.14599 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 037 | Batch: 300 | Loss: 0.09365 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 037 | Batch: 400 | Loss: 0.08788 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 037 | Batch: 000 | Loss: 0.05540 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 037 | Batch: 100 | Loss: 0.10253 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 037 | Batch: 200 | Loss: 0.09434 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 037 | Batch: 300 | Loss: 0.15789 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 037 | Batch: 400 | Loss: 0.11571 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 037 | Batch: 000 | Loss: 0.12856 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 037 | Batch: 100 | Loss: 0.06230 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 037 | Batch: 200 | Loss: 0.06281 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 037 | Batch: 300 | Loss: 0.07306 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 037 | Batch: 400 | Loss: 0.07625 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 037 | Batch: 000 | Loss: 0.08089 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 037 | Batch: 100 | Loss: 0.17559 | Correct: 119/128\n",
      "Estimator: 003 | Epoch: 037 | Batch: 200 | Loss: 0.10463 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 037 | Batch: 300 | Loss: 0.05445 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 037 | Batch: 400 | Loss: 0.04469 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 037 | Batch: 000 | Loss: 0.21525 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 037 | Batch: 100 | Loss: 0.16225 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 037 | Batch: 200 | Loss: 0.06178 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 037 | Batch: 300 | Loss: 0.11959 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 037 | Batch: 400 | Loss: 0.11287 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 037 | Batch: 000 | Loss: 0.03442 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 037 | Batch: 100 | Loss: 0.04396 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 037 | Batch: 200 | Loss: 0.20422 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 037 | Batch: 300 | Loss: 0.19517 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 037 | Batch: 400 | Loss: 0.05224 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 037 | Batch: 000 | Loss: 0.05699 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 037 | Batch: 100 | Loss: 0.14255 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 037 | Batch: 200 | Loss: 0.03153 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 037 | Batch: 300 | Loss: 0.08106 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 037 | Batch: 400 | Loss: 0.11115 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 037 | Batch: 000 | Loss: 0.09921 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 037 | Batch: 100 | Loss: 0.15695 | Correct: 120/128\n",
      "Estimator: 007 | Epoch: 037 | Batch: 200 | Loss: 0.19343 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 037 | Batch: 300 | Loss: 0.14202 | Correct: 120/128\n",
      "Estimator: 007 | Epoch: 037 | Batch: 400 | Loss: 0.08880 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 037 | Batch: 000 | Loss: 0.09268 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 037 | Batch: 100 | Loss: 0.06534 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 037 | Batch: 200 | Loss: 0.11305 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 037 | Batch: 300 | Loss: 0.05014 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 037 | Batch: 400 | Loss: 0.16751 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 037 | Batch: 000 | Loss: 0.08250 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 037 | Batch: 100 | Loss: 0.09975 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 037 | Batch: 200 | Loss: 0.12954 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 037 | Batch: 300 | Loss: 0.10466 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 037 | Batch: 400 | Loss: 0.13502 | Correct: 121/128\n",
      "2021-02-15 22:59:08,092 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2021-02-15 22:59:08,108 - INFO: Epoch: 037 | Validation Acc: 98.180 % | Historical Best: 98.180 %\n",
      "Estimator: 000 | Epoch: 038 | Batch: 000 | Loss: 0.04398 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 038 | Batch: 100 | Loss: 0.08311 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 038 | Batch: 200 | Loss: 0.08285 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 038 | Batch: 300 | Loss: 0.07976 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 038 | Batch: 400 | Loss: 0.18901 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 038 | Batch: 000 | Loss: 0.05699 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 038 | Batch: 100 | Loss: 0.21739 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 038 | Batch: 200 | Loss: 0.06759 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 038 | Batch: 300 | Loss: 0.11247 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 038 | Batch: 400 | Loss: 0.33778 | Correct: 116/128\n",
      "Estimator: 002 | Epoch: 038 | Batch: 000 | Loss: 0.12898 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 038 | Batch: 100 | Loss: 0.05197 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 038 | Batch: 200 | Loss: 0.06306 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 038 | Batch: 300 | Loss: 0.04053 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 038 | Batch: 400 | Loss: 0.10147 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 038 | Batch: 000 | Loss: 0.09535 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 038 | Batch: 100 | Loss: 0.13999 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 038 | Batch: 200 | Loss: 0.12058 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 038 | Batch: 300 | Loss: 0.18953 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 038 | Batch: 400 | Loss: 0.09155 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 038 | Batch: 000 | Loss: 0.20216 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 038 | Batch: 100 | Loss: 0.19842 | Correct: 117/128\n",
      "Estimator: 004 | Epoch: 038 | Batch: 200 | Loss: 0.13132 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 038 | Batch: 300 | Loss: 0.13117 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 038 | Batch: 400 | Loss: 0.10974 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 038 | Batch: 000 | Loss: 0.09031 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 038 | Batch: 100 | Loss: 0.13095 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 038 | Batch: 200 | Loss: 0.08188 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 038 | Batch: 300 | Loss: 0.19303 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 038 | Batch: 400 | Loss: 0.15125 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 038 | Batch: 000 | Loss: 0.04183 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 038 | Batch: 100 | Loss: 0.07732 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 038 | Batch: 200 | Loss: 0.08186 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 038 | Batch: 300 | Loss: 0.09706 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 038 | Batch: 400 | Loss: 0.10376 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 038 | Batch: 000 | Loss: 0.08657 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 038 | Batch: 100 | Loss: 0.20052 | Correct: 115/128\n",
      "Estimator: 007 | Epoch: 038 | Batch: 200 | Loss: 0.09160 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 038 | Batch: 300 | Loss: 0.10249 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 038 | Batch: 400 | Loss: 0.14624 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 038 | Batch: 000 | Loss: 0.11827 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 038 | Batch: 100 | Loss: 0.16886 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 038 | Batch: 200 | Loss: 0.15367 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 038 | Batch: 300 | Loss: 0.07794 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 038 | Batch: 400 | Loss: 0.09937 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 038 | Batch: 000 | Loss: 0.06933 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 038 | Batch: 100 | Loss: 0.18500 | Correct: 120/128\n",
      "Estimator: 009 | Epoch: 038 | Batch: 200 | Loss: 0.15484 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 038 | Batch: 300 | Loss: 0.17342 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 038 | Batch: 400 | Loss: 0.23517 | Correct: 119/128\n",
      "2021-02-15 23:00:49,856 - INFO: Epoch: 038 | Validation Acc: 97.880 % | Historical Best: 98.180 %\n",
      "Estimator: 000 | Epoch: 039 | Batch: 000 | Loss: 0.06677 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 039 | Batch: 100 | Loss: 0.14568 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 039 | Batch: 200 | Loss: 0.06698 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 039 | Batch: 300 | Loss: 0.13358 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 039 | Batch: 400 | Loss: 0.20269 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 039 | Batch: 000 | Loss: 0.16698 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 039 | Batch: 100 | Loss: 0.14772 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 039 | Batch: 200 | Loss: 0.05726 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 039 | Batch: 300 | Loss: 0.17077 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 039 | Batch: 400 | Loss: 0.17656 | Correct: 119/128\n",
      "Estimator: 002 | Epoch: 039 | Batch: 000 | Loss: 0.14319 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 039 | Batch: 100 | Loss: 0.07466 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 039 | Batch: 200 | Loss: 0.02955 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 039 | Batch: 300 | Loss: 0.04343 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 039 | Batch: 400 | Loss: 0.12181 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 039 | Batch: 000 | Loss: 0.06913 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 039 | Batch: 100 | Loss: 0.08946 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 039 | Batch: 200 | Loss: 0.09217 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 039 | Batch: 300 | Loss: 0.07952 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 039 | Batch: 400 | Loss: 0.07063 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 039 | Batch: 000 | Loss: 0.10953 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 039 | Batch: 100 | Loss: 0.24255 | Correct: 119/128\n",
      "Estimator: 004 | Epoch: 039 | Batch: 200 | Loss: 0.08456 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 039 | Batch: 300 | Loss: 0.17735 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 039 | Batch: 400 | Loss: 0.13194 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 039 | Batch: 000 | Loss: 0.23959 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 039 | Batch: 100 | Loss: 0.07414 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 039 | Batch: 200 | Loss: 0.06912 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 039 | Batch: 300 | Loss: 0.11658 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 039 | Batch: 400 | Loss: 0.07355 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 039 | Batch: 000 | Loss: 0.10224 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 039 | Batch: 100 | Loss: 0.09302 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 039 | Batch: 200 | Loss: 0.10762 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 039 | Batch: 300 | Loss: 0.12887 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 039 | Batch: 400 | Loss: 0.11205 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 039 | Batch: 000 | Loss: 0.02775 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 039 | Batch: 100 | Loss: 0.16375 | Correct: 118/128\n",
      "Estimator: 007 | Epoch: 039 | Batch: 200 | Loss: 0.07754 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 039 | Batch: 300 | Loss: 0.13267 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 039 | Batch: 400 | Loss: 0.10396 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 039 | Batch: 000 | Loss: 0.05568 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 039 | Batch: 100 | Loss: 0.11084 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 039 | Batch: 200 | Loss: 0.16438 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 039 | Batch: 300 | Loss: 0.14730 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 039 | Batch: 400 | Loss: 0.08491 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 039 | Batch: 000 | Loss: 0.05438 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 039 | Batch: 100 | Loss: 0.07355 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 039 | Batch: 200 | Loss: 0.14160 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 039 | Batch: 300 | Loss: 0.05250 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 039 | Batch: 400 | Loss: 0.03103 | Correct: 127/128\n",
      "2021-02-15 23:02:30,591 - INFO: Epoch: 039 | Validation Acc: 97.950 % | Historical Best: 98.180 %\n",
      "Estimator: 000 | Epoch: 040 | Batch: 000 | Loss: 0.10677 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 040 | Batch: 100 | Loss: 0.12147 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 040 | Batch: 200 | Loss: 0.21839 | Correct: 119/128\n",
      "Estimator: 000 | Epoch: 040 | Batch: 300 | Loss: 0.15110 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 040 | Batch: 400 | Loss: 0.08592 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 040 | Batch: 000 | Loss: 0.14369 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 040 | Batch: 100 | Loss: 0.05309 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 040 | Batch: 200 | Loss: 0.12166 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 040 | Batch: 300 | Loss: 0.11902 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 040 | Batch: 400 | Loss: 0.11808 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 040 | Batch: 000 | Loss: 0.12353 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 040 | Batch: 100 | Loss: 0.10064 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 040 | Batch: 200 | Loss: 0.10196 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 040 | Batch: 300 | Loss: 0.15394 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 040 | Batch: 400 | Loss: 0.05363 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 040 | Batch: 000 | Loss: 0.11140 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 040 | Batch: 100 | Loss: 0.10485 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 040 | Batch: 200 | Loss: 0.06693 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 040 | Batch: 300 | Loss: 0.16240 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 040 | Batch: 400 | Loss: 0.10852 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 040 | Batch: 000 | Loss: 0.06125 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 040 | Batch: 100 | Loss: 0.15196 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 040 | Batch: 200 | Loss: 0.12621 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 040 | Batch: 300 | Loss: 0.11124 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 040 | Batch: 400 | Loss: 0.05969 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 040 | Batch: 000 | Loss: 0.06007 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 040 | Batch: 100 | Loss: 0.18960 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 040 | Batch: 200 | Loss: 0.05818 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 040 | Batch: 300 | Loss: 0.06975 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 040 | Batch: 400 | Loss: 0.10108 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 040 | Batch: 000 | Loss: 0.04262 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 040 | Batch: 100 | Loss: 0.16594 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 040 | Batch: 200 | Loss: 0.06812 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 040 | Batch: 300 | Loss: 0.10219 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 040 | Batch: 400 | Loss: 0.03308 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 040 | Batch: 000 | Loss: 0.13522 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 040 | Batch: 100 | Loss: 0.08337 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 040 | Batch: 200 | Loss: 0.10074 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 040 | Batch: 300 | Loss: 0.07950 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 040 | Batch: 400 | Loss: 0.07223 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 040 | Batch: 000 | Loss: 0.11770 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 040 | Batch: 100 | Loss: 0.11640 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 040 | Batch: 200 | Loss: 0.18794 | Correct: 119/128\n",
      "Estimator: 008 | Epoch: 040 | Batch: 300 | Loss: 0.09201 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 040 | Batch: 400 | Loss: 0.08667 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 040 | Batch: 000 | Loss: 0.11378 | Correct: 120/128\n",
      "Estimator: 009 | Epoch: 040 | Batch: 100 | Loss: 0.05277 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 040 | Batch: 200 | Loss: 0.09764 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 040 | Batch: 300 | Loss: 0.05966 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 040 | Batch: 400 | Loss: 0.08709 | Correct: 124/128\n",
      "2021-02-15 23:04:10,724 - INFO: Epoch: 040 | Validation Acc: 98.040 % | Historical Best: 98.180 %\n",
      "Estimator: 000 | Epoch: 041 | Batch: 000 | Loss: 0.20940 | Correct: 119/128\n",
      "Estimator: 000 | Epoch: 041 | Batch: 100 | Loss: 0.07264 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 041 | Batch: 200 | Loss: 0.12387 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 041 | Batch: 300 | Loss: 0.13042 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 041 | Batch: 400 | Loss: 0.12791 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 041 | Batch: 000 | Loss: 0.14782 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 041 | Batch: 100 | Loss: 0.19916 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 041 | Batch: 200 | Loss: 0.09426 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 041 | Batch: 300 | Loss: 0.06682 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 041 | Batch: 400 | Loss: 0.14391 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 041 | Batch: 000 | Loss: 0.10316 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 041 | Batch: 100 | Loss: 0.19266 | Correct: 119/128\n",
      "Estimator: 002 | Epoch: 041 | Batch: 200 | Loss: 0.07165 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 041 | Batch: 300 | Loss: 0.07380 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 041 | Batch: 400 | Loss: 0.10237 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 041 | Batch: 000 | Loss: 0.15739 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 041 | Batch: 100 | Loss: 0.06974 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 041 | Batch: 200 | Loss: 0.10281 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 041 | Batch: 300 | Loss: 0.11463 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 041 | Batch: 400 | Loss: 0.10079 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 041 | Batch: 000 | Loss: 0.05979 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 041 | Batch: 100 | Loss: 0.09283 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 041 | Batch: 200 | Loss: 0.12474 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 041 | Batch: 300 | Loss: 0.10690 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 041 | Batch: 400 | Loss: 0.11365 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 041 | Batch: 000 | Loss: 0.10735 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 041 | Batch: 100 | Loss: 0.16233 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 041 | Batch: 200 | Loss: 0.10564 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 041 | Batch: 300 | Loss: 0.11558 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 041 | Batch: 400 | Loss: 0.04647 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 041 | Batch: 000 | Loss: 0.11438 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 041 | Batch: 100 | Loss: 0.24813 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 041 | Batch: 200 | Loss: 0.10274 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 041 | Batch: 300 | Loss: 0.17212 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 041 | Batch: 400 | Loss: 0.10272 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 041 | Batch: 000 | Loss: 0.05056 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 041 | Batch: 100 | Loss: 0.06599 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 041 | Batch: 200 | Loss: 0.08530 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 041 | Batch: 300 | Loss: 0.10742 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 041 | Batch: 400 | Loss: 0.07593 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 041 | Batch: 000 | Loss: 0.10466 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 041 | Batch: 100 | Loss: 0.12659 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 041 | Batch: 200 | Loss: 0.08349 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 041 | Batch: 300 | Loss: 0.14974 | Correct: 119/128\n",
      "Estimator: 008 | Epoch: 041 | Batch: 400 | Loss: 0.14775 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 041 | Batch: 000 | Loss: 0.06759 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 041 | Batch: 100 | Loss: 0.09955 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 041 | Batch: 200 | Loss: 0.06213 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 041 | Batch: 300 | Loss: 0.08469 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 041 | Batch: 400 | Loss: 0.15761 | Correct: 121/128\n",
      "2021-02-15 23:05:51,490 - INFO: Epoch: 041 | Validation Acc: 98.040 % | Historical Best: 98.180 %\n",
      "Estimator: 000 | Epoch: 042 | Batch: 000 | Loss: 0.17090 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 042 | Batch: 100 | Loss: 0.15123 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 042 | Batch: 200 | Loss: 0.21729 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 042 | Batch: 300 | Loss: 0.07855 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 042 | Batch: 400 | Loss: 0.04597 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 042 | Batch: 000 | Loss: 0.11475 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 042 | Batch: 100 | Loss: 0.08677 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 042 | Batch: 200 | Loss: 0.07553 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 042 | Batch: 300 | Loss: 0.14670 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 042 | Batch: 400 | Loss: 0.12921 | Correct: 118/128\n",
      "Estimator: 002 | Epoch: 042 | Batch: 000 | Loss: 0.15857 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 042 | Batch: 100 | Loss: 0.06332 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 042 | Batch: 200 | Loss: 0.06505 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 042 | Batch: 300 | Loss: 0.07244 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 042 | Batch: 400 | Loss: 0.03123 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 042 | Batch: 000 | Loss: 0.11555 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 042 | Batch: 100 | Loss: 0.08754 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 042 | Batch: 200 | Loss: 0.07382 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 042 | Batch: 300 | Loss: 0.13474 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 042 | Batch: 400 | Loss: 0.18825 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 042 | Batch: 000 | Loss: 0.06691 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 042 | Batch: 100 | Loss: 0.10640 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 042 | Batch: 200 | Loss: 0.13660 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 042 | Batch: 300 | Loss: 0.14199 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 042 | Batch: 400 | Loss: 0.10166 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 042 | Batch: 000 | Loss: 0.07840 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 042 | Batch: 100 | Loss: 0.05087 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 042 | Batch: 200 | Loss: 0.11617 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 042 | Batch: 300 | Loss: 0.07969 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 042 | Batch: 400 | Loss: 0.07945 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 042 | Batch: 000 | Loss: 0.08156 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 042 | Batch: 100 | Loss: 0.14533 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 042 | Batch: 200 | Loss: 0.19553 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 042 | Batch: 300 | Loss: 0.09342 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 042 | Batch: 400 | Loss: 0.08779 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 042 | Batch: 000 | Loss: 0.17351 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 042 | Batch: 100 | Loss: 0.13582 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 042 | Batch: 200 | Loss: 0.12009 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 042 | Batch: 300 | Loss: 0.11832 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 042 | Batch: 400 | Loss: 0.17107 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 042 | Batch: 000 | Loss: 0.14041 | Correct: 120/128\n",
      "Estimator: 008 | Epoch: 042 | Batch: 100 | Loss: 0.10143 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 042 | Batch: 200 | Loss: 0.15755 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 042 | Batch: 300 | Loss: 0.06901 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 042 | Batch: 400 | Loss: 0.11372 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 042 | Batch: 000 | Loss: 0.10603 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 042 | Batch: 100 | Loss: 0.09156 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 042 | Batch: 200 | Loss: 0.09255 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 042 | Batch: 300 | Loss: 0.12298 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 042 | Batch: 400 | Loss: 0.14431 | Correct: 123/128\n",
      "2021-02-15 23:07:31,963 - INFO: Epoch: 042 | Validation Acc: 98.010 % | Historical Best: 98.180 %\n",
      "Estimator: 000 | Epoch: 043 | Batch: 000 | Loss: 0.06333 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 043 | Batch: 100 | Loss: 0.12385 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 043 | Batch: 200 | Loss: 0.08450 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 043 | Batch: 300 | Loss: 0.04807 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 043 | Batch: 400 | Loss: 0.10027 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 043 | Batch: 000 | Loss: 0.11700 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 043 | Batch: 100 | Loss: 0.11286 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 043 | Batch: 200 | Loss: 0.04908 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 043 | Batch: 300 | Loss: 0.20897 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 043 | Batch: 400 | Loss: 0.15364 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 043 | Batch: 000 | Loss: 0.16257 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 043 | Batch: 100 | Loss: 0.07425 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 043 | Batch: 200 | Loss: 0.12815 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 043 | Batch: 300 | Loss: 0.03806 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 043 | Batch: 400 | Loss: 0.05980 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 043 | Batch: 000 | Loss: 0.08876 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 043 | Batch: 100 | Loss: 0.25452 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 043 | Batch: 200 | Loss: 0.10727 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 043 | Batch: 300 | Loss: 0.22411 | Correct: 117/128\n",
      "Estimator: 003 | Epoch: 043 | Batch: 400 | Loss: 0.11947 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 043 | Batch: 000 | Loss: 0.19979 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 043 | Batch: 100 | Loss: 0.06328 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 043 | Batch: 200 | Loss: 0.07840 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 043 | Batch: 300 | Loss: 0.09086 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 043 | Batch: 400 | Loss: 0.11424 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 043 | Batch: 000 | Loss: 0.16777 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 043 | Batch: 100 | Loss: 0.11245 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 043 | Batch: 200 | Loss: 0.15432 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 043 | Batch: 300 | Loss: 0.16500 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 043 | Batch: 400 | Loss: 0.09865 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 043 | Batch: 000 | Loss: 0.06745 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 043 | Batch: 100 | Loss: 0.06299 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 043 | Batch: 200 | Loss: 0.10345 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 043 | Batch: 300 | Loss: 0.06987 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 043 | Batch: 400 | Loss: 0.18624 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 043 | Batch: 000 | Loss: 0.08009 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 043 | Batch: 100 | Loss: 0.11600 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 043 | Batch: 200 | Loss: 0.08917 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 043 | Batch: 300 | Loss: 0.06138 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 043 | Batch: 400 | Loss: 0.17380 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 043 | Batch: 000 | Loss: 0.11891 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 043 | Batch: 100 | Loss: 0.08162 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 043 | Batch: 200 | Loss: 0.10320 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 043 | Batch: 300 | Loss: 0.10037 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 043 | Batch: 400 | Loss: 0.21785 | Correct: 120/128\n",
      "Estimator: 009 | Epoch: 043 | Batch: 000 | Loss: 0.09403 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 043 | Batch: 100 | Loss: 0.14153 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 043 | Batch: 200 | Loss: 0.09934 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 043 | Batch: 300 | Loss: 0.07068 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 043 | Batch: 400 | Loss: 0.11011 | Correct: 123/128\n",
      "2021-02-15 23:09:12,119 - INFO: Epoch: 043 | Validation Acc: 98.050 % | Historical Best: 98.180 %\n",
      "Estimator: 000 | Epoch: 044 | Batch: 000 | Loss: 0.06928 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 044 | Batch: 100 | Loss: 0.15818 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 044 | Batch: 200 | Loss: 0.11006 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 044 | Batch: 300 | Loss: 0.13645 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 044 | Batch: 400 | Loss: 0.13673 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 044 | Batch: 000 | Loss: 0.07613 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 044 | Batch: 100 | Loss: 0.09363 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 044 | Batch: 200 | Loss: 0.11464 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 044 | Batch: 300 | Loss: 0.22046 | Correct: 118/128\n",
      "Estimator: 001 | Epoch: 044 | Batch: 400 | Loss: 0.08744 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 044 | Batch: 000 | Loss: 0.08846 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 044 | Batch: 100 | Loss: 0.09855 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 044 | Batch: 200 | Loss: 0.07910 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 044 | Batch: 300 | Loss: 0.14236 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 044 | Batch: 400 | Loss: 0.09684 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 044 | Batch: 000 | Loss: 0.06254 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 044 | Batch: 100 | Loss: 0.08601 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 044 | Batch: 200 | Loss: 0.13124 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 044 | Batch: 300 | Loss: 0.12096 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 044 | Batch: 400 | Loss: 0.09577 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 044 | Batch: 000 | Loss: 0.07120 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 044 | Batch: 100 | Loss: 0.15482 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 044 | Batch: 200 | Loss: 0.06006 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 044 | Batch: 300 | Loss: 0.08248 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 044 | Batch: 400 | Loss: 0.11547 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 044 | Batch: 000 | Loss: 0.10035 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 044 | Batch: 100 | Loss: 0.11358 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 044 | Batch: 200 | Loss: 0.15714 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 044 | Batch: 300 | Loss: 0.04794 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 044 | Batch: 400 | Loss: 0.11189 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 044 | Batch: 000 | Loss: 0.10296 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 044 | Batch: 100 | Loss: 0.05486 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 044 | Batch: 200 | Loss: 0.04850 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 044 | Batch: 300 | Loss: 0.13829 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 044 | Batch: 400 | Loss: 0.09990 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 044 | Batch: 000 | Loss: 0.02040 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 044 | Batch: 100 | Loss: 0.10468 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 044 | Batch: 200 | Loss: 0.09080 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 044 | Batch: 300 | Loss: 0.08800 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 044 | Batch: 400 | Loss: 0.07342 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 044 | Batch: 000 | Loss: 0.05990 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 044 | Batch: 100 | Loss: 0.11081 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 044 | Batch: 200 | Loss: 0.12581 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 044 | Batch: 300 | Loss: 0.07945 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 044 | Batch: 400 | Loss: 0.09461 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 044 | Batch: 000 | Loss: 0.08236 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 044 | Batch: 100 | Loss: 0.09664 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 044 | Batch: 200 | Loss: 0.11332 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 044 | Batch: 300 | Loss: 0.15529 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 044 | Batch: 400 | Loss: 0.06017 | Correct: 123/128\n",
      "2021-02-15 23:10:52,514 - INFO: Epoch: 044 | Validation Acc: 98.010 % | Historical Best: 98.180 %\n",
      "Estimator: 000 | Epoch: 045 | Batch: 000 | Loss: 0.02830 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 045 | Batch: 100 | Loss: 0.26521 | Correct: 118/128\n",
      "Estimator: 000 | Epoch: 045 | Batch: 200 | Loss: 0.17829 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 045 | Batch: 300 | Loss: 0.05930 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 045 | Batch: 400 | Loss: 0.08302 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 045 | Batch: 000 | Loss: 0.05867 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 045 | Batch: 100 | Loss: 0.11085 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 045 | Batch: 200 | Loss: 0.12647 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 045 | Batch: 300 | Loss: 0.08956 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 045 | Batch: 400 | Loss: 0.13817 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 045 | Batch: 000 | Loss: 0.08429 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 045 | Batch: 100 | Loss: 0.10975 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 045 | Batch: 200 | Loss: 0.14272 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 045 | Batch: 300 | Loss: 0.14490 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 045 | Batch: 400 | Loss: 0.08839 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 045 | Batch: 000 | Loss: 0.10448 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 045 | Batch: 100 | Loss: 0.07964 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 045 | Batch: 200 | Loss: 0.14224 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 045 | Batch: 300 | Loss: 0.05884 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 045 | Batch: 400 | Loss: 0.08170 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 045 | Batch: 000 | Loss: 0.11787 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 045 | Batch: 100 | Loss: 0.14199 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 045 | Batch: 200 | Loss: 0.04376 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 045 | Batch: 300 | Loss: 0.10954 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 045 | Batch: 400 | Loss: 0.03809 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 045 | Batch: 000 | Loss: 0.15223 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 045 | Batch: 100 | Loss: 0.07701 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 045 | Batch: 200 | Loss: 0.07027 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 045 | Batch: 300 | Loss: 0.16123 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 045 | Batch: 400 | Loss: 0.10048 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 045 | Batch: 000 | Loss: 0.07570 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 045 | Batch: 100 | Loss: 0.04889 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 045 | Batch: 200 | Loss: 0.09899 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 045 | Batch: 300 | Loss: 0.17354 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 045 | Batch: 400 | Loss: 0.12473 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 045 | Batch: 000 | Loss: 0.13061 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 045 | Batch: 100 | Loss: 0.06984 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 045 | Batch: 200 | Loss: 0.08382 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 045 | Batch: 300 | Loss: 0.13035 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 045 | Batch: 400 | Loss: 0.12955 | Correct: 120/128\n",
      "Estimator: 008 | Epoch: 045 | Batch: 000 | Loss: 0.06345 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 045 | Batch: 100 | Loss: 0.05574 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 045 | Batch: 200 | Loss: 0.12694 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 045 | Batch: 300 | Loss: 0.17364 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 045 | Batch: 400 | Loss: 0.11490 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 045 | Batch: 000 | Loss: 0.10342 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 045 | Batch: 100 | Loss: 0.14063 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 045 | Batch: 200 | Loss: 0.14726 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 045 | Batch: 300 | Loss: 0.12490 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 045 | Batch: 400 | Loss: 0.15491 | Correct: 120/128\n",
      "2021-02-15 23:12:33,049 - INFO: Epoch: 045 | Validation Acc: 98.180 % | Historical Best: 98.180 %\n",
      "Estimator: 000 | Epoch: 046 | Batch: 000 | Loss: 0.13729 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 046 | Batch: 100 | Loss: 0.12740 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 046 | Batch: 200 | Loss: 0.10064 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 046 | Batch: 300 | Loss: 0.16626 | Correct: 121/128\n",
      "Estimator: 000 | Epoch: 046 | Batch: 400 | Loss: 0.13238 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 046 | Batch: 000 | Loss: 0.11072 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 046 | Batch: 100 | Loss: 0.09188 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 046 | Batch: 200 | Loss: 0.07719 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 046 | Batch: 300 | Loss: 0.11944 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 046 | Batch: 400 | Loss: 0.13599 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 046 | Batch: 000 | Loss: 0.10103 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 046 | Batch: 100 | Loss: 0.09047 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 046 | Batch: 200 | Loss: 0.08934 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 046 | Batch: 300 | Loss: 0.10944 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 046 | Batch: 400 | Loss: 0.07149 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 046 | Batch: 000 | Loss: 0.14358 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 046 | Batch: 100 | Loss: 0.10797 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 046 | Batch: 200 | Loss: 0.07624 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 046 | Batch: 300 | Loss: 0.07374 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 046 | Batch: 400 | Loss: 0.14247 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 046 | Batch: 000 | Loss: 0.09302 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 046 | Batch: 100 | Loss: 0.07277 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 046 | Batch: 200 | Loss: 0.05991 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 046 | Batch: 300 | Loss: 0.10136 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 046 | Batch: 400 | Loss: 0.14986 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 046 | Batch: 000 | Loss: 0.06235 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 046 | Batch: 100 | Loss: 0.05438 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 046 | Batch: 200 | Loss: 0.18151 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 046 | Batch: 300 | Loss: 0.22420 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 046 | Batch: 400 | Loss: 0.03419 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 046 | Batch: 000 | Loss: 0.16086 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 046 | Batch: 100 | Loss: 0.16807 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 046 | Batch: 200 | Loss: 0.18770 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 046 | Batch: 300 | Loss: 0.09341 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 046 | Batch: 400 | Loss: 0.12281 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 046 | Batch: 000 | Loss: 0.11408 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 046 | Batch: 100 | Loss: 0.18550 | Correct: 119/128\n",
      "Estimator: 007 | Epoch: 046 | Batch: 200 | Loss: 0.10756 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 046 | Batch: 300 | Loss: 0.11832 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 046 | Batch: 400 | Loss: 0.07079 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 046 | Batch: 000 | Loss: 0.08618 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 046 | Batch: 100 | Loss: 0.06768 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 046 | Batch: 200 | Loss: 0.10642 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 046 | Batch: 300 | Loss: 0.09372 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 046 | Batch: 400 | Loss: 0.07725 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 046 | Batch: 000 | Loss: 0.06331 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 046 | Batch: 100 | Loss: 0.07013 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 046 | Batch: 200 | Loss: 0.08562 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 046 | Batch: 300 | Loss: 0.09137 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 046 | Batch: 400 | Loss: 0.09362 | Correct: 123/128\n",
      "2021-02-15 23:14:12,680 - INFO: Epoch: 046 | Validation Acc: 98.000 % | Historical Best: 98.180 %\n",
      "Estimator: 000 | Epoch: 047 | Batch: 000 | Loss: 0.08826 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 047 | Batch: 100 | Loss: 0.09309 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 047 | Batch: 200 | Loss: 0.09996 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 047 | Batch: 300 | Loss: 0.07668 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 047 | Batch: 400 | Loss: 0.06545 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 047 | Batch: 000 | Loss: 0.11878 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 047 | Batch: 100 | Loss: 0.07926 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 047 | Batch: 200 | Loss: 0.16316 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 047 | Batch: 300 | Loss: 0.06752 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 047 | Batch: 400 | Loss: 0.04980 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 047 | Batch: 000 | Loss: 0.20828 | Correct: 119/128\n",
      "Estimator: 002 | Epoch: 047 | Batch: 100 | Loss: 0.19967 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 047 | Batch: 200 | Loss: 0.21054 | Correct: 119/128\n",
      "Estimator: 002 | Epoch: 047 | Batch: 300 | Loss: 0.10719 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 047 | Batch: 400 | Loss: 0.06751 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 047 | Batch: 000 | Loss: 0.12970 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 047 | Batch: 100 | Loss: 0.05245 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 047 | Batch: 200 | Loss: 0.12208 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 047 | Batch: 300 | Loss: 0.22097 | Correct: 117/128\n",
      "Estimator: 003 | Epoch: 047 | Batch: 400 | Loss: 0.18724 | Correct: 118/128\n",
      "Estimator: 004 | Epoch: 047 | Batch: 000 | Loss: 0.10758 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 047 | Batch: 100 | Loss: 0.17376 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 047 | Batch: 200 | Loss: 0.05345 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 047 | Batch: 300 | Loss: 0.08572 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 047 | Batch: 400 | Loss: 0.06523 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 047 | Batch: 000 | Loss: 0.13787 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 047 | Batch: 100 | Loss: 0.10345 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 047 | Batch: 200 | Loss: 0.07320 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 047 | Batch: 300 | Loss: 0.08542 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 047 | Batch: 400 | Loss: 0.07856 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 047 | Batch: 000 | Loss: 0.15507 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 047 | Batch: 100 | Loss: 0.12634 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 047 | Batch: 200 | Loss: 0.04319 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 047 | Batch: 300 | Loss: 0.05652 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 047 | Batch: 400 | Loss: 0.12439 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 047 | Batch: 000 | Loss: 0.11439 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 047 | Batch: 100 | Loss: 0.14118 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 047 | Batch: 200 | Loss: 0.17586 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 047 | Batch: 300 | Loss: 0.17695 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 047 | Batch: 400 | Loss: 0.16206 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 047 | Batch: 000 | Loss: 0.13045 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 047 | Batch: 100 | Loss: 0.07040 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 047 | Batch: 200 | Loss: 0.18359 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 047 | Batch: 300 | Loss: 0.07563 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 047 | Batch: 400 | Loss: 0.12683 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 047 | Batch: 000 | Loss: 0.04912 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 047 | Batch: 100 | Loss: 0.10501 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 047 | Batch: 200 | Loss: 0.10164 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 047 | Batch: 300 | Loss: 0.10519 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 047 | Batch: 400 | Loss: 0.09820 | Correct: 124/128\n",
      "2021-02-15 23:15:52,463 - INFO: Epoch: 047 | Validation Acc: 98.090 % | Historical Best: 98.180 %\n",
      "Estimator: 000 | Epoch: 048 | Batch: 000 | Loss: 0.05577 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 048 | Batch: 100 | Loss: 0.19568 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 048 | Batch: 200 | Loss: 0.05643 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 048 | Batch: 300 | Loss: 0.08078 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 048 | Batch: 400 | Loss: 0.11448 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 048 | Batch: 000 | Loss: 0.15112 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 048 | Batch: 100 | Loss: 0.11177 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 048 | Batch: 200 | Loss: 0.26182 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 048 | Batch: 300 | Loss: 0.08701 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 048 | Batch: 400 | Loss: 0.13324 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 048 | Batch: 000 | Loss: 0.06005 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 048 | Batch: 100 | Loss: 0.08684 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 048 | Batch: 200 | Loss: 0.12709 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 048 | Batch: 300 | Loss: 0.11587 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 048 | Batch: 400 | Loss: 0.14719 | Correct: 120/128\n",
      "Estimator: 003 | Epoch: 048 | Batch: 000 | Loss: 0.12873 | Correct: 118/128\n",
      "Estimator: 003 | Epoch: 048 | Batch: 100 | Loss: 0.10924 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 048 | Batch: 200 | Loss: 0.13966 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 048 | Batch: 300 | Loss: 0.08913 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 048 | Batch: 400 | Loss: 0.03642 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 048 | Batch: 000 | Loss: 0.11895 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 048 | Batch: 100 | Loss: 0.08903 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 048 | Batch: 200 | Loss: 0.20421 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 048 | Batch: 300 | Loss: 0.13100 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 048 | Batch: 400 | Loss: 0.12745 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 048 | Batch: 000 | Loss: 0.07897 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 048 | Batch: 100 | Loss: 0.08691 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 048 | Batch: 200 | Loss: 0.19202 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 048 | Batch: 300 | Loss: 0.07167 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 048 | Batch: 400 | Loss: 0.10818 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 048 | Batch: 000 | Loss: 0.12888 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 048 | Batch: 100 | Loss: 0.07061 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 048 | Batch: 200 | Loss: 0.07679 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 048 | Batch: 300 | Loss: 0.14150 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 048 | Batch: 400 | Loss: 0.11628 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 048 | Batch: 000 | Loss: 0.07427 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 048 | Batch: 100 | Loss: 0.06861 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 048 | Batch: 200 | Loss: 0.12044 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 048 | Batch: 300 | Loss: 0.10994 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 048 | Batch: 400 | Loss: 0.04586 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 048 | Batch: 000 | Loss: 0.05773 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 048 | Batch: 100 | Loss: 0.11283 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 048 | Batch: 200 | Loss: 0.06983 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 048 | Batch: 300 | Loss: 0.12605 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 048 | Batch: 400 | Loss: 0.18810 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 048 | Batch: 000 | Loss: 0.17036 | Correct: 120/128\n",
      "Estimator: 009 | Epoch: 048 | Batch: 100 | Loss: 0.05367 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 048 | Batch: 200 | Loss: 0.11682 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 048 | Batch: 300 | Loss: 0.08351 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 048 | Batch: 400 | Loss: 0.13576 | Correct: 122/128\n",
      "2021-02-15 23:17:32,175 - INFO: Epoch: 048 | Validation Acc: 98.110 % | Historical Best: 98.180 %\n",
      "Estimator: 000 | Epoch: 049 | Batch: 000 | Loss: 0.24267 | Correct: 118/128\n",
      "Estimator: 000 | Epoch: 049 | Batch: 100 | Loss: 0.10520 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 049 | Batch: 200 | Loss: 0.08638 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 049 | Batch: 300 | Loss: 0.08099 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 049 | Batch: 400 | Loss: 0.11935 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 049 | Batch: 000 | Loss: 0.06977 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 049 | Batch: 100 | Loss: 0.06082 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 049 | Batch: 200 | Loss: 0.10586 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 049 | Batch: 300 | Loss: 0.12129 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 049 | Batch: 400 | Loss: 0.12791 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 049 | Batch: 000 | Loss: 0.06886 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 049 | Batch: 100 | Loss: 0.03419 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 049 | Batch: 200 | Loss: 0.05392 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 049 | Batch: 300 | Loss: 0.09922 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 049 | Batch: 400 | Loss: 0.16558 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 049 | Batch: 000 | Loss: 0.08935 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 049 | Batch: 100 | Loss: 0.15523 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 049 | Batch: 200 | Loss: 0.15318 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 049 | Batch: 300 | Loss: 0.12985 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 049 | Batch: 400 | Loss: 0.11687 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 049 | Batch: 000 | Loss: 0.13506 | Correct: 118/128\n",
      "Estimator: 004 | Epoch: 049 | Batch: 100 | Loss: 0.03113 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 049 | Batch: 200 | Loss: 0.08774 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 049 | Batch: 300 | Loss: 0.07269 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 049 | Batch: 400 | Loss: 0.20109 | Correct: 119/128\n",
      "Estimator: 005 | Epoch: 049 | Batch: 000 | Loss: 0.06924 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 049 | Batch: 100 | Loss: 0.15824 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 049 | Batch: 200 | Loss: 0.03642 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 049 | Batch: 300 | Loss: 0.18570 | Correct: 119/128\n",
      "Estimator: 005 | Epoch: 049 | Batch: 400 | Loss: 0.11353 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 049 | Batch: 000 | Loss: 0.10188 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 049 | Batch: 100 | Loss: 0.16061 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 049 | Batch: 200 | Loss: 0.06184 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 049 | Batch: 300 | Loss: 0.11764 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 049 | Batch: 400 | Loss: 0.16188 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 049 | Batch: 000 | Loss: 0.16633 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 049 | Batch: 100 | Loss: 0.13827 | Correct: 120/128\n",
      "Estimator: 007 | Epoch: 049 | Batch: 200 | Loss: 0.14362 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 049 | Batch: 300 | Loss: 0.09035 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 049 | Batch: 400 | Loss: 0.03789 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 049 | Batch: 000 | Loss: 0.07421 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 049 | Batch: 100 | Loss: 0.11968 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 049 | Batch: 200 | Loss: 0.05361 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 049 | Batch: 300 | Loss: 0.11192 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 049 | Batch: 400 | Loss: 0.13667 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 049 | Batch: 000 | Loss: 0.07765 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 049 | Batch: 100 | Loss: 0.03455 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 049 | Batch: 200 | Loss: 0.07947 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 049 | Batch: 300 | Loss: 0.07805 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 049 | Batch: 400 | Loss: 0.07316 | Correct: 125/128\n",
      "2021-02-15 23:19:12,281 - INFO: Epoch: 049 | Validation Acc: 98.090 % | Historical Best: 98.180 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torchensemble import VotingClassifier\n",
    "from torchensemble.utils.logging import set_logger\n",
    "\n",
    "# Define Your Base Estimator\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(784, 128)\n",
    "        self.linear2 = nn.Linear(128, 128)\n",
    "        self.linear3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.view(X.size(0), -1)\n",
    "        output = F.relu(self.linear1(X))\n",
    "        output = F.dropout(output)\n",
    "        output = F.relu(self.linear2(output))\n",
    "        output = self.linear3(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "train = datasets.MNIST('../../Dataset', train=True, download=True, transform=transform)\n",
    "test = datasets.MNIST('../../Dataset', train=False, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=128, shuffle=True)\n",
    "\n",
    "# Set the Logger\n",
    "logger = set_logger(\"classification_mnist_mlp\")\n",
    "\n",
    "# Set the model\n",
    "model = VotingClassifier(\n",
    "    estimator=MLP,\n",
    "    n_estimators=10,\n",
    "    cuda=True\n",
    ")\n",
    "model.set_optimizer(\"Adam\", lr=1e-3, weight_decay=5e-4)\n",
    "\n",
    "# Train and Evaluate\n",
    "model.fit(train_loader,\n",
    "          epochs=50,\n",
    "          test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}