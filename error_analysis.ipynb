{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.nli import *\n",
    "from src.model.nli_models import *\n",
    "from src.utils.nli_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_conf = {\"batch_size\":128,\"max_len\":50,\"device\":'cuda',\"tokenizer\":'spacy',\"use_char_emb\":True,\"max_word_len\":10}\n",
    "dataset = snli_module(snli_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "BiLSTM + Attention based SNLI model\n",
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, conf):\n",
    "        super(Attention, self).__init__()\n",
    "        self.Ws = nn.Linear(\n",
    "            2 * conf[\"hidden_size\"],\n",
    "            conf[\"attention_layer_param\"],\n",
    "            bias=False,\n",
    "        )\n",
    "        self.Wa = nn.Linear(conf[\"attention_layer_param\"], 1, bias=False)\n",
    "\n",
    "    def forward(self, hid):\n",
    "        opt = self.Ws(hid)\n",
    "        opt = torch.tanh(opt)\n",
    "        opt = self.Wa(opt)\n",
    "        opt = F.softmax(opt, dim=1)\n",
    "        return opt\n",
    "\n",
    "\n",
    "class Attn_Encoder(nn.Module):\n",
    "    def __init__(self, conf):\n",
    "        super(Attn_Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=conf[\"vocab_size\"],\n",
    "            embedding_dim=conf[\"embedding_dim\"],\n",
    "            padding_idx=conf[\"padding_idx\"],\n",
    "        )\n",
    "        self.translate = nn.Linear(\n",
    "            (\n",
    "                conf[\"embedding_dim\"]\n",
    "                + int(conf[\"use_char_emb\"]) * conf[\"char_embedding_dim\"]\n",
    "            ),\n",
    "            conf[\"hidden_size\"],\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=conf[\"dropout\"])\n",
    "\n",
    "        if conf[\"use_glove\"]:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                torch.load(\".vector_cache/{}_vectors.pt\".format(conf[\"dataset\"]))\n",
    "            )\n",
    "\n",
    "        if conf[\"use_char_emb\"]:\n",
    "            self.char_embedding = nn.Embedding(\n",
    "                num_embeddings=conf[\"char_vocab_size\"],\n",
    "                embedding_dim=conf[\"char_embedding_dim\"],\n",
    "                padding_idx=0,\n",
    "            )\n",
    "            self.char_cnn = nn.Conv2d(\n",
    "                conf[\"max_word_len\"],\n",
    "                conf[\"char_embedding_dim\"],\n",
    "                (1, 6),\n",
    "                stride=(1, 1),\n",
    "                padding=0,\n",
    "                bias=True,\n",
    "            )\n",
    "        self.lstm_layer = nn.LSTM(\n",
    "            input_size=conf[\"hidden_size\"],\n",
    "            hidden_size=conf[\"hidden_size\"],\n",
    "            num_layers=conf[\"num_layers\"],\n",
    "            dropout=conf[\"dropout\"],\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.attention = Attention(conf)\n",
    "\n",
    "    def char_embedding_forward(self, x):\n",
    "        # X - [batch_size, seq_len, char_emb_size])\n",
    "        batch_size, seq_len, char_emb_size = x.shape\n",
    "        x = x.view(-1, char_emb_size)\n",
    "        x = self.char_embedding(x)  # (batch_size * seq_len, char_emb_size, emb_size)\n",
    "        x = x.view(batch_size, -1, seq_len, char_emb_size)\n",
    "        x = x.permute(0, 3, 2, 1)\n",
    "        x = self.char_cnn(x)\n",
    "        x = torch.max(F.relu(x), 3)[0]\n",
    "        return x.view(batch_size, seq_len, -1)\n",
    "\n",
    "    def forward(self, inp, char_vec):\n",
    "        batch_size = inp.shape[0]\n",
    "        embedded = self.embedding(inp)\n",
    "        if char_vec != None:\n",
    "            char_emb = self.char_embedding_forward(char_vec)\n",
    "            embedded = torch.cat([embedded, char_emb], dim=2)\n",
    "        embedded = self.relu(self.translate(embedded))\n",
    "        all_, (_, _) = self.lstm_layer(embedded)\n",
    "        attn = self.attention(all_)\n",
    "        cont = torch.bmm(attn.permute(0, 2, 1), all_)\n",
    "        cont = cont.squeeze(1)\n",
    "        return cont\n",
    "\n",
    "\n",
    "class AttnBiLSTM_snli(nn.Module):\n",
    "    def __init__(self, conf):\n",
    "        super(AttnBiLSTM_snli, self).__init__()\n",
    "        self.conf = conf\n",
    "        self.encoder = Attn_Encoder(conf)\n",
    "        self.fc_in = nn.Linear(\n",
    "            2 * 4 * self.conf[\"hidden_size\"],\n",
    "            self.conf[\"hidden_size\"],\n",
    "        )\n",
    "        self.fcs = nn.ModuleList(\n",
    "            [\n",
    "                nn.Linear(self.conf[\"hidden_size\"], self.conf[\"hidden_size\"])\n",
    "                for i in range(self.conf[\"fcs\"])\n",
    "            ]\n",
    "        )\n",
    "        self.fc_out = nn.Linear(self.conf[\"hidden_size\"], 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.dropout = nn.Dropout(p=self.conf[\"dropout\"])\n",
    "\n",
    "    def forward(self, x0, x1,**kwargs):\n",
    "        char_vec_x0 = kwargs.get(\"char_premise\",None)\n",
    "        char_vec_x1 = kwargs.get(\"char_hypothesis\",None)\n",
    "        x0_enc = self.encoder(x0,char_vec_x0)\n",
    "        x1_enc = self.encoder(x1,char_vec_x1)\n",
    "        cont = torch.cat(\n",
    "            [x0_enc, x1_enc, torch.abs(x0_enc - x1_enc), x0_enc * x1_enc], dim=1\n",
    "        )\n",
    "        opt = self.fc_in(cont)\n",
    "        opt = self.dropout(opt)\n",
    "        for fc in self.fcs:\n",
    "            opt = self.relu(self.dropout(fc(opt)))\n",
    "        opt = self.fc_out(opt)\n",
    "        return opt\n",
    "\n",
    "\n",
    "def attn_bilstm_snli(options):\n",
    "    return AttnBiLSTM_snli(options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conf = {\n",
    "    \"hidden_size\":300,\n",
    "    \"embedding_dim\":300,\n",
    "    \"char_embedding_dim\":100,\n",
    "    \"dropout\":0.3,\n",
    "    \"use_glove\":True,\n",
    "    \"num_layers\":1,\n",
    "    \"dataset\":\"snli\",\n",
    "    \"fcs\":1,\n",
    "    \"use_char_emb\":True,\n",
    "    \"vocab_size\":dataset.vocab_size(),\n",
    "    \"char_vocab_size\":dataset.char_vocab_size(),\n",
    "    \"max_word_len\": dataset.char_word_len(),\n",
    "    \"tokenizer\":\"spacy\",\n",
    "    \"padding_idx\":dataset.padding_idx(),\n",
    "    \"attention_layer_param\":200,\n",
    "    # \"r\":3,\n",
    "    # \"gated_embedding_dim\":150,\n",
    "    # \"pool_strategy\":'max',\n",
    "    # \"gated\":True\n",
    "}\n",
    "\n",
    "hparams = {\n",
    "    \"optimizer_base\": {\n",
    "        \"optim\": \"adamw\",\n",
    "        \"lr\": 0.0010039910781394373,\n",
    "        \"scheduler\": \"const\",\n",
    "    },\n",
    "    \"optimizer_tune\": {\n",
    "        \"optim\": \"adam\",\n",
    "        \"lr\": 0.0010039910781394373,\n",
    "        \"weight_decay\": 0.1,\n",
    "        \"scheduler\": \"lambda\",\n",
    "    },\n",
    "    \"switch_epoch\": 5,\n",
    "}\n",
    "\n",
    "model = AttnBiLSTM_snli(model_conf)\n",
    "# model = SNLI_model(attn_bilstm_snli,model_conf,hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n[torchtext.data.batch.Batch of size 128 from SNLI]\n\t[.premise]:[torch.cuda.LongTensor of size 128x50 (GPU 0)]\n\t[.hypothesis]:[torch.cuda.LongTensor of size 128x50 (GPU 0)]\n\t[.label]:[torch.cuda.LongTensor of size 128 (GPU 0)]\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.train_dataloader():\n",
    "    print(i)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([128, 50])\n",
      "torch.Size([128, 50, 10])\n",
      "torch.Size([128, 50])\n",
      "torch.Size([128, 50, 10])\n"
     ]
    }
   ],
   "source": [
    "opt = model(i.premise.cpu(),i.hypothesis.cpu(),**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "kwargs={}\n",
    "\n",
    "char_premise = Variable(\n",
    "    torch.LongTensor(dataset.data.characterize(i.premise))\n",
    ")\n",
    "char_hypothesis = Variable(\n",
    "    torch.LongTensor(dataset.data.characterize(i.hypothesis))\n",
    ")\n",
    "\n",
    "char_premise = char_premise.cpu()\n",
    "char_hypothesis = char_hypothesis.cpu()\n",
    "\n",
    "kwargs[\"char_premise\"] = char_premise\n",
    "kwargs[\"char_hypothesis\"] = char_hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((128,600,3))\n",
    "b = torch.rand((3,600,150))\n",
    "#.unsqueeze(0).repeat(128,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(43, 'https://www.youtube.com/watch?v=txrsvc25gh8'),\n",
       " (32, 'http://fresnosmilemakeovers.com/'),\n",
       " (18, 'telecommunications'),\n",
       " (17, 'underconstruction'),\n",
       " (17, 'telecommunication'),\n",
       " (17, 'sings,(presumably'),\n",
       " (17, 'extraterrestrials'),\n",
       " (17, 'environmentalists'),\n",
       " (17, 'anashthesiologist'),\n",
       " (16, 'unprofessionally')]"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "values = [len(w) for w in dataset.data.TEXT.vocab.itos]\n",
    "\n",
    "sorted(zip(values, dataset.data.TEXT.vocab.itos), reverse=True)[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://www.youtube.com/watch?v=txrsvc25gh8'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "dataset.data.TEXT.vocab.itos[28118]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (128) must match the size of tensor b (3) at non-singleton dimension 0",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-86775c255192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (3) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "a.permute(0,2,1) @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = model(i.premise,i.hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = opt.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([128, 600])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "torch.rand([2, 128, 300])[-2:].transpose(0,1).contiguous().view(128,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'02:23:36'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "import time\n",
    "time.strftime('%H:%M:%S', time.gmtime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_ = torch.rand((128,40,400))\n",
    "attn = torch.rand((128,40,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = torch.bmm(all_.permute(1, 2, 0), attn.permute(1, 0, 2)).permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 40, 400])"
      ]
     },
     "metadata": {},
     "execution_count": 173
    }
   ],
   "source": [
    "cont.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "bilstm_model_data = torch.load(\"results/bilstm/snli/best-bilstm-snli-params.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.nli_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bilstm_snli(bilstm_model_data[\"options\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "model.load_state_dict(bilstm_model_data[\"model_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BiLSTM_encoder(\n",
       "  (embedding): Embedding(39927, 300, padding_idx=1)\n",
       "  (projection): Linear(in_features=300, out_features=400, bias=True)\n",
       "  (lstm): LSTM(400, 400, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you']"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "dataset.data.TEXT.tokenize(\"Hello how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['hello', 'how', 'are', 'you', 'doing', 'hack', '##ob', '##bs']"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "dataset.data.TEXT.tokenize(\"Hello how are you doing hackobbs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, Iterator, TabularDataset, NestedField, LabelField, BucketIterator\n",
    "from torchtext import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(lower=True, tokenize='spacy', batch_first = True)\n",
    "LABEL = Field(sequential=False, unk_token = None, is_target = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[7592, 2129, 2024, 2017]"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "train, dev, test = datasets.SNLI.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nesting_field = Field(pad_token='<c>', init_token='<w>', eos_token='</w>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = NestedField(nesting_field, init_token='<s>', eos_token='</s>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch = [[list('john'), list('loves'), list('mary')],\n",
    "[list('mary'), list('cries')],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = field.pad(minibatch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[   [   ['<w>', '<s>', '</w>', '<c>', '<c>', '<c>', '<c>'],\n        ['<w>', 'j', 'o', 'h', 'n', '</w>', '<c>'],\n        ['<w>', 'l', 'o', 'v', 'e', 's', '</w>'],\n        ['<w>', 'm', 'a', 'r', 'y', '</w>', '<c>'],\n        ['<w>', '</s>', '</w>', '<c>', '<c>', '<c>', '<c>']],\n    [   ['<w>', '<s>', '</w>', '<c>', '<c>', '<c>', '<c>'],\n        ['<w>', 'm', 'a', 'r', 'y', '</w>', '<c>'],\n        ['<w>', 'c', 'r', 'i', 'e', 's', '</w>'],\n        ['<w>', '</s>', '</w>', '<c>', '<c>', '<c>', '<c>'],\n        ['<c>', '<c>', '<c>', '<c>', '<c>', '<c>', '<c>']]]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(sequential=True, tokenize=list, fix_length=1014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,dev,test = datasets.SNLI.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train, max_size=10000)\n",
    "LABEL.build_vocab(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def onehot_encode(self, texts):\n",
    "    # A helper function to do the one-hot encoding of characters.\n",
    "    sen_len, batch_size = texts.shape\n",
    "    out = torch.zeros(size=(sen_len, batch_size, self.voc_size), device=texts.device)\n",
    "    out.scatter_(2, texts.view(sen_len, batch_size, 1), 1)\n",
    "    return out.permute(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = Iterator(\n",
    "        train,\n",
    "        device='cuda',\n",
    "        batch_size=128,\n",
    "        sort_key=lambda x: len(x.text),\n",
    "        repeat=False,\n",
    "        train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n[torchtext.data.batch.Batch of size 128 from SNLI]\n\t[.premise]:[torch.cuda.LongTensor of size 1014x128 (GPU 0)]\n\t[.hypothesis]:[torch.cuda.LongTensor of size 1014x128 (GPU 0)]\n\t[.label]:[torch.cuda.LongTensor of size 128 (GPU 0)]\n"
     ]
    }
   ],
   "source": [
    "for i in train_iterator:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'PAAAMAaATATtATTAAAAOATAAAACAAAMTATAAAAAAFFTSAAAAVAACSAAAATAAAAAYAAAAAAAATTTTTaAPAAWATTAAAAAGAAATTAAAAaASAAATYFWSFTTAAATAATAAAAYA'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "\"\".join([TEXT.vocab.itos[i] for i in i.premise[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'PTTTTttTTNTtACTtAANTTTATTATSTtMTATAAATAATFTGTTTAOTACSAAAATTtAAaASTTTAAtaTTTTtNAtHASAATTAAaAaAAATTATTPAAOTATTAOATFATAtATBcTTACMYA'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "\"\".join([TEXT.vocab.itos[i] for i in i.hypothesis[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([33, 26, 26, 26, 26,  8,  8, 26, 26, 47, 26,  8, 25, 36, 26,  8, 25, 25,\n",
       "        47, 26, 26, 26, 25, 26, 26, 25, 26, 32, 26,  8, 34, 26, 25, 26, 25, 25,\n",
       "        25, 26, 25, 25, 26, 37, 26, 43, 26, 26, 26, 25, 42, 26, 25, 36, 32, 25,\n",
       "        25, 25, 25, 26, 26,  8, 25, 25,  4, 25, 32, 26, 26, 26, 25, 25,  8,  4,\n",
       "        26, 26, 26, 26,  8, 47, 25,  8, 45, 25, 32, 25, 25, 26, 26, 25, 25,  4,\n",
       "        25,  4, 25, 25, 25, 26, 26, 25, 26, 26, 33, 25, 25, 42, 26, 25, 26, 26,\n",
       "        25, 42, 25, 26, 37, 25, 26, 25,  8, 25, 26, 40, 17, 26, 26, 25, 36, 34,\n",
       "        48, 25], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "i.hypothesis[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "defaultdict(<function torchtext.vocab._default_unk_index>,\n",
       "            {' ': 2,\n",
       "             '!': 70,\n",
       "             '\"': 44,\n",
       "             '#': 73,\n",
       "             '$': 79,\n",
       "             '%': 80,\n",
       "             '&': 72,\n",
       "             \"'\": 35,\n",
       "             '(': 68,\n",
       "             ')': 69,\n",
       "             '*': 87,\n",
       "             '+': 84,\n",
       "             ',': 28,\n",
       "             '-': 31,\n",
       "             '.': 20,\n",
       "             '/': 76,\n",
       "             '0': 58,\n",
       "             '1': 59,\n",
       "             '2': 54,\n",
       "             '3': 57,\n",
       "             '4': 62,\n",
       "             '5': 61,\n",
       "             '6': 66,\n",
       "             '7': 71,\n",
       "             '8': 67,\n",
       "             '9': 64,\n",
       "             ':': 77,\n",
       "             ';': 63,\n",
       "             '<': 86,\n",
       "             '<pad>': 1,\n",
       "             '<unk>': 0,\n",
       "             '=': 85,\n",
       "             '>': 88,\n",
       "             '?': 75,\n",
       "             '@': 83,\n",
       "             'A': 25,\n",
       "             'B': 40,\n",
       "             'C': 36,\n",
       "             'D': 50,\n",
       "             'E': 51,\n",
       "             'F': 37,\n",
       "             'G': 43,\n",
       "             'H': 45,\n",
       "             'I': 46,\n",
       "             'J': 56,\n",
       "             'K': 53,\n",
       "             'L': 49,\n",
       "             'M': 34,\n",
       "             'N': 47,\n",
       "             'O': 42,\n",
       "             'P': 33,\n",
       "             'Q': 74,\n",
       "             'R': 52,\n",
       "             'S': 32,\n",
       "             'T': 26,\n",
       "             'U': 60,\n",
       "             'V': 55,\n",
       "             'W': 39,\n",
       "             'X': 65,\n",
       "             'Y': 48,\n",
       "             'Z': 78,\n",
       "             '[': 89,\n",
       "             '\\\\': 82,\n",
       "             '`': 81,\n",
       "             'a': 4,\n",
       "             'b': 21,\n",
       "             'c': 17,\n",
       "             'd': 14,\n",
       "             'e': 3,\n",
       "             'f': 22,\n",
       "             'g': 13,\n",
       "             'h': 11,\n",
       "             'i': 6,\n",
       "             'j': 29,\n",
       "             'k': 24,\n",
       "             'l': 12,\n",
       "             'm': 16,\n",
       "             'n': 5,\n",
       "             'o': 7,\n",
       "             'p': 18,\n",
       "             'q': 41,\n",
       "             'r': 9,\n",
       "             's': 10,\n",
       "             't': 8,\n",
       "             'u': 19,\n",
       "             'v': 27,\n",
       "             'w': 15,\n",
       "             'x': 30,\n",
       "             'y': 23,\n",
       "             'z': 38})"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "TEXT.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.SNLI()"
   ]
  }
 ]
}