{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.nli import *\n",
    "from src.model.nli_models import *\n",
    "from src.utils.nli_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_conf = {\"batch_size\":128,\"max_len\":50,\"device\":'cuda',\"tokenizer\":'spacy',\"use_char_emb\":False,\"max_word_len\":10}\n",
    "dataset = snli_module(snli_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "BiLSTM + Attention based SNLI model\n",
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, conf):\n",
    "        super(Attention, self).__init__()\n",
    "        self.Ws = nn.Linear(\n",
    "            2 * conf[\"hidden_size\"],\n",
    "            conf[\"attention_layer_param\"],\n",
    "            bias=False,\n",
    "        )\n",
    "        self.Wa = nn.Linear(conf[\"attention_layer_param\"], 1, bias=False)\n",
    "\n",
    "    def forward(self, hid):\n",
    "        opt = self.Ws(hid)\n",
    "        opt = torch.tanh(opt)\n",
    "        opt = self.Wa(opt)\n",
    "        opt = F.softmax(opt, dim=1)\n",
    "        return opt\n",
    "\n",
    "\n",
    "class Attn_Encoder(nn.Module):\n",
    "    def __init__(self, conf):\n",
    "        super(Attn_Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=conf[\"vocab_size\"],\n",
    "            embedding_dim=conf[\"embedding_dim\"],\n",
    "            padding_idx=conf[\"padding_idx\"],\n",
    "        )\n",
    "        self.translate = nn.Linear(\n",
    "            (\n",
    "                conf[\"embedding_dim\"]\n",
    "                + int(conf[\"use_char_emb\"]) * conf[\"char_embedding_dim\"]\n",
    "            ),\n",
    "            conf[\"hidden_size\"],\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=conf[\"dropout\"])\n",
    "\n",
    "        if conf[\"use_glove\"]:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                torch.load(\".vector_cache/{}_vectors.pt\".format(conf[\"dataset\"]))\n",
    "            )\n",
    "\n",
    "        if conf[\"use_char_emb\"]:\n",
    "            self.char_embedding = nn.Embedding(\n",
    "                num_embeddings=conf[\"char_vocab_size\"],\n",
    "                embedding_dim=conf[\"char_embedding_dim\"],\n",
    "                padding_idx=0,\n",
    "            )\n",
    "            self.char_cnn = nn.Conv2d(\n",
    "                conf[\"max_word_len\"],\n",
    "                conf[\"char_embedding_dim\"],\n",
    "                (1, 6),\n",
    "                stride=(1, 1),\n",
    "                padding=0,\n",
    "                bias=True,\n",
    "            )\n",
    "        self.lstm_layer = nn.LSTM(\n",
    "            input_size=conf[\"hidden_size\"],\n",
    "            hidden_size=conf[\"hidden_size\"],\n",
    "            num_layers=conf[\"num_layers\"],\n",
    "            dropout=conf[\"dropout\"],\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.attention = Attention(conf)\n",
    "\n",
    "    def char_embedding_forward(self, x):\n",
    "        # X - [batch_size, seq_len, char_emb_size])\n",
    "        batch_size, seq_len, char_emb_size = x.shape\n",
    "        x = x.view(-1, char_emb_size)\n",
    "        x = self.char_embedding(x)  # (batch_size * seq_len, char_emb_size, emb_size)\n",
    "        x = x.view(batch_size, -1, seq_len, char_emb_size)\n",
    "        x = x.permute(0, 3, 2, 1)\n",
    "        x = self.char_cnn(x)\n",
    "        x = torch.max(F.relu(x), 3)[0]\n",
    "        return x.view(batch_size, seq_len, -1)\n",
    "\n",
    "    def forward(self, inp, char_vec):\n",
    "        batch_size = inp.shape[0]\n",
    "        embedded = self.embedding(inp)\n",
    "        if char_vec != None:\n",
    "            char_emb = self.char_embedding_forward(char_vec)\n",
    "            embedded = torch.cat([embedded, char_emb], dim=2)\n",
    "        embedded = self.relu(self.translate(embedded))\n",
    "        all_, (_, _) = self.lstm_layer(embedded)\n",
    "        attn = self.attention(all_)\n",
    "        cont = torch.bmm(attn.permute(0, 2, 1), all_)\n",
    "        cont = cont.squeeze(1)\n",
    "        return cont\n",
    "\n",
    "\n",
    "class AttnBiLSTM_snli(nn.Module):\n",
    "    def __init__(self, conf):\n",
    "        super(AttnBiLSTM_snli, self).__init__()\n",
    "        self.conf = conf\n",
    "        self.encoder = Attn_Encoder(conf)\n",
    "        self.fc_in = nn.Linear(\n",
    "            2 * 4 * self.conf[\"hidden_size\"],\n",
    "            self.conf[\"hidden_size\"],\n",
    "        )\n",
    "        self.fcs = nn.ModuleList(\n",
    "            [\n",
    "                nn.Linear(self.conf[\"hidden_size\"], self.conf[\"hidden_size\"])\n",
    "                for i in range(self.conf[\"fcs\"])\n",
    "            ]\n",
    "        )\n",
    "        self.fc_out = nn.Linear(self.conf[\"hidden_size\"], 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.dropout = nn.Dropout(p=self.conf[\"dropout\"])\n",
    "\n",
    "    def forward(self, x0, x1,**kwargs):\n",
    "        char_vec_x0 = kwargs.get(\"char_premise\",None)\n",
    "        char_vec_x1 = kwargs.get(\"char_hypothesis\",None)\n",
    "        x0_enc = self.encoder(x0,char_vec_x0)\n",
    "        x1_enc = self.encoder(x1,char_vec_x1)\n",
    "        cont = torch.cat(\n",
    "            [x0_enc, x1_enc, torch.abs(x0_enc - x1_enc), x0_enc * x1_enc], dim=1\n",
    "        )\n",
    "        opt = self.fc_in(cont)\n",
    "        opt = self.dropout(opt)\n",
    "        for fc in self.fcs:\n",
    "            opt = self.relu(self.dropout(fc(opt)))\n",
    "        opt = self.fc_out(opt)\n",
    "        return opt\n",
    "\n",
    "\n",
    "def attn_bilstm_snli(options):\n",
    "    return AttnBiLSTM_snli(options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conf = {\n",
    "    \"hidden_size\":300,\n",
    "    \"embedding_dim\":300,\n",
    "    \"char_embedding_dim\":100,\n",
    "    \"dropout\":0.3,\n",
    "    \"use_glove\":True,\n",
    "    \"num_layers\":1,\n",
    "    \"dataset\":\"snli\",\n",
    "    \"fcs\":1,\n",
    "    \"use_char_emb\":True,\n",
    "    \"vocab_size\":dataset.vocab_size(),\n",
    "    \"char_vocab_size\":dataset.char_vocab_size(),\n",
    "    \"max_word_len\": dataset.char_word_len(),\n",
    "    \"tokenizer\":\"spacy\",\n",
    "    \"padding_idx\":dataset.padding_idx(),\n",
    "    \"attention_layer_param\":200,\n",
    "    # \"r\":3,\n",
    "    # \"gated_embedding_dim\":150,\n",
    "    # \"pool_strategy\":'max',\n",
    "    # \"gated\":True\n",
    "}\n",
    "\n",
    "hparams = {\n",
    "    \"optimizer_base\": {\n",
    "        \"optim\": \"adamw\",\n",
    "        \"lr\": 0.0010039910781394373,\n",
    "        \"scheduler\": \"const\",\n",
    "    },\n",
    "    \"optimizer_tune\": {\n",
    "        \"optim\": \"adam\",\n",
    "        \"lr\": 0.0010039910781394373,\n",
    "        \"weight_decay\": 0.1,\n",
    "        \"scheduler\": \"lambda\",\n",
    "    },\n",
    "    \"switch_epoch\": 5,\n",
    "}\n",
    "\n",
    "model = AttnBiLSTM_snli(model_conf)\n",
    "# model = SNLI_model(attn_bilstm_snli,model_conf,hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n[torchtext.data.batch.Batch of size 128 from SNLI]\n\t[.premise]:[torch.cuda.LongTensor of size 128x50 (GPU 0)]\n\t[.hypothesis]:[torch.cuda.LongTensor of size 128x50 (GPU 0)]\n\t[.label]:[torch.cuda.LongTensor of size 128 (GPU 0)]\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.train_dataloader():\n",
    "    print(i)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([128, 50])\n",
      "torch.Size([128, 50, 10])\n",
      "torch.Size([128, 50])\n",
      "torch.Size([128, 50, 10])\n"
     ]
    }
   ],
   "source": [
    "opt = model(i.premise.cpu(),i.hypothesis.cpu(),**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "kwargs={}\n",
    "\n",
    "char_premise = Variable(\n",
    "    torch.LongTensor(dataset.data.characterize(i.premise))\n",
    ")\n",
    "char_hypothesis = Variable(\n",
    "    torch.LongTensor(dataset.data.characterize(i.hypothesis))\n",
    ")\n",
    "\n",
    "char_premise = char_premise.cpu()\n",
    "char_hypothesis = char_hypothesis.cpu()\n",
    "\n",
    "kwargs[\"char_premise\"] = char_premise\n",
    "kwargs[\"char_hypothesis\"] = char_hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((128,600,3))\n",
    "b = torch.rand((3,600,150))\n",
    "#.unsqueeze(0).repeat(128,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(43, 'https://www.youtube.com/watch?v=txrsvc25gh8'),\n",
       " (32, 'http://fresnosmilemakeovers.com/'),\n",
       " (18, 'telecommunications'),\n",
       " (17, 'underconstruction'),\n",
       " (17, 'telecommunication'),\n",
       " (17, 'sings,(presumably'),\n",
       " (17, 'extraterrestrials'),\n",
       " (17, 'environmentalists'),\n",
       " (17, 'anashthesiologist'),\n",
       " (16, 'unprofessionally')]"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "values = [len(w) for w in dataset.data.TEXT.vocab.itos]\n",
    "\n",
    "sorted(zip(values, dataset.data.TEXT.vocab.itos), reverse=True)[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://www.youtube.com/watch?v=txrsvc25gh8'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "dataset.data.TEXT.vocab.itos[28118]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (128) must match the size of tensor b (3) at non-singleton dimension 0",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-86775c255192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (3) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "a.permute(0,2,1) @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = model(i.premise,i.hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = opt.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([128, 600])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "torch.rand([2, 128, 300])[-2:].transpose(0,1).contiguous().view(128,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'02:23:36'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "import time\n",
    "time.strftime('%H:%M:%S', time.gmtime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_ = torch.rand((128,40,400))\n",
    "attn = torch.rand((128,40,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = torch.bmm(all_.permute(1, 2, 0), attn.permute(1, 0, 2)).permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 40, 400])"
      ]
     },
     "metadata": {},
     "execution_count": 173
    }
   ],
   "source": [
    "cont.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "bilstm_model_data = torch.load(\"results/bilstm/snli/best-bilstm-snli-params.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.nli_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bilstm_snli(bilstm_model_data[\"options\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "model.load_state_dict(bilstm_model_data[\"model_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BiLSTM_encoder(\n",
       "  (embedding): Embedding(39927, 300, padding_idx=1)\n",
       "  (projection): Linear(in_features=300, out_features=400, bias=True)\n",
       "  (lstm): LSTM(400, 400, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you']"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "dataset.data.TEXT.tokenize(\"Hello how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['hello', 'how', 'are', 'you', 'doing', 'hack', '##ob', '##bs']"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "dataset.data.TEXT.tokenize(\"Hello how are you doing hackobbs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, Iterator, TabularDataset, NestedField, LabelField, BucketIterator\n",
    "from torchtext import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(lower=True, tokenize='spacy', batch_first = True)\n",
    "LABEL = Field(sequential=False, unk_token = None, is_target = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[7592, 2129, 2024, 2017]"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "train, dev, test = datasets.SNLI.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nesting_field = Field(pad_token='<c>', init_token='<w>', eos_token='</w>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = NestedField(nesting_field, init_token='<s>', eos_token='</s>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch = [[list('john'), list('loves'), list('mary')],\n",
    "[list('mary'), list('cries')],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = field.pad(minibatch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[   [   ['<w>', '<s>', '</w>', '<c>', '<c>', '<c>', '<c>'],\n        ['<w>', 'j', 'o', 'h', 'n', '</w>', '<c>'],\n        ['<w>', 'l', 'o', 'v', 'e', 's', '</w>'],\n        ['<w>', 'm', 'a', 'r', 'y', '</w>', '<c>'],\n        ['<w>', '</s>', '</w>', '<c>', '<c>', '<c>', '<c>']],\n    [   ['<w>', '<s>', '</w>', '<c>', '<c>', '<c>', '<c>'],\n        ['<w>', 'm', 'a', 'r', 'y', '</w>', '<c>'],\n        ['<w>', 'c', 'r', 'i', 'e', 's', '</w>'],\n        ['<w>', '</s>', '</w>', '<c>', '<c>', '<c>', '<c>'],\n        ['<c>', '<c>', '<c>', '<c>', '<c>', '<c>', '<c>']]]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(sequential=True, tokenize=list, fix_length=1014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<torchtext.data.example.Example object at 0x7efce6c180b8>\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.data.train:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field,NestedField,LabelField\n",
    "from torchtext import datasets\n",
    "\n",
    "field_word = Field(sequential = True,tokenize=\"spacy\")\n",
    "field_char = NestedField(Field(\n",
    "        pad_token=\"PAD_WORD\",\n",
    "        tokenize=list,\n",
    "        init_token=\"SOS_WORD\",\n",
    "        eos_token=\"EOS_WORD\",\n",
    "        batch_first=True,\n",
    "        fix_length=12),\n",
    "        fix_length =12\n",
    "    )\n",
    "label_field = LabelField(dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word,val_word,test_word = datasets.SNLI.splits(field_word, label_field)\n",
    "train_char,val_char,test_char = datasets.SNLI.splits(field_char, label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_char.build_vocab(train_char)\n",
    "field_word.build_vocab(train_word)\n",
    "label_field.build_vocab(train_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def merge_snli(word_dataset,char_dataset):\n",
    "    assert len(word_dataset)==len(char_dataset)\n",
    "    for id in range(len(word_dataset)):\n",
    "        word_ex = word_dataset.examples[id]\n",
    "        char_ex = char_dataset.examples[id]\n",
    "        setattr(word_ex,'premise_char',char_ex.premise)\n",
    "        setattr(word_ex,'hypothesis_char',char_ex.hypothesis)\n",
    "        word_dataset.fields[\"premise_char\"] = char_dataset.fields[\"premise\"]\n",
    "        word_dataset.fields[\"hypothesis_char\"] = char_dataset.fields[\"hypothesis\"]\n",
    "    return word_dataset\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,val,test = merge_snli(train_word,train_char),merge_snli(val_word,val_char),merge_snli(val_word,val_char)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter,val_iter,test_iter = data.BucketIterator.splits((train,val,test),batch_size=128,device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n[torchtext.data.batch.Batch of size 128 from SNLI]\n\t[.premise]:[torch.cuda.LongTensor of size 35x128 (GPU 0)]\n\t[.hypothesis]:[torch.cuda.LongTensor of size 19x128 (GPU 0)]\n\t[.label]:[torch.cuda.LongTensor of size 128 (GPU 0)]\n\t[.premise_char]:[torch.cuda.LongTensor of size 128x12x15 (GPU 0)]\n\t[.hypothesis_char]:[torch.cuda.LongTensor of size 128x12x17 (GPU 0)]\n"
     ]
    }
   ],
   "source": [
    "for i in train_iter:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 2, 26,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 2,  6,  4, 10, 28,  8, 20, 11,  3,  1,  1,  1,  1,  1,  1],\n",
       "        [ 2, 13,  8,  8, 25,  7,  6, 14,  3,  1,  1,  1,  1,  1,  1],\n",
       "        [ 2, 10,  4, 15, 32, 12,  5,  7, 10,  4, 15,  3,  1,  1,  1],\n",
       "        [ 2, 14,  7, 10, 13,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 2, 18,  5, 10,  4, 23, 20, 13, 13, 24,  3,  1,  1,  1,  1],\n",
       "        [ 2, 12,  5,  6, 15, 13,  4, 11,  3,  1,  1,  1,  1,  1,  1],\n",
       "        [ 2, 11,  8, 17,  4,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 2, 17,  4, 15,  7, 18,  5, 13,  3,  1,  1,  1,  1,  1,  1],\n",
       "        [ 2,  4, 42, 20,  7, 19, 17,  4,  6,  9,  3,  1,  1,  1,  1],\n",
       "        [ 2,  7,  6,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 2,  5,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 180
    }
   ],
   "source": [
    "i.premise_char[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['H', 'e', 'l', 'l', 'o'], ['h', 'o', 'w'], ['a', 'r', 'e'], ['y', 'o', 'u']]"
      ]
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "source": [
    "field_char.preprocess(\"Hello how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [5, 1] at entry 0 and [3, 1] at entry 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-2ddac891965e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfield_char\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_char\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello how are you\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[0;34m(self, arrs, device)\u001b[0m\n\u001b[1;32m    673\u001b[0m                 arr, device=device)\n\u001b[1;32m    674\u001b[0m             \u001b[0mnumericalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumericalized_ex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mpadded_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumericalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnesting_field\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [5, 1] at entry 0 and [3, 1] at entry 1"
     ]
    }
   ],
   "source": [
    "field_char.numericalize(field_char.preprocess(\"Hello how are you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 2, 46,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "\n",
       "        [[ 2,  4,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "\n",
       "        [[ 2, 13,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "\n",
       "        [[ 2, 13,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "\n",
       "        [[ 2,  8,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "\n",
       "        [[ 2,  0,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "\n",
       "        [[ 2, 12,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "\n",
       "        [[ 2,  8,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "\n",
       "        [[ 2, 16,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "\n",
       "        [[ 2,  0,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "\n",
       "        [[ 2,  5,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "\n",
       "        [[ 2, 10,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "\n",
       "        [[ 2,  4,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "\n",
       "        [[ 2,  0,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "\n",
       "        [[ 2, 24,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "\n",
       "        [[ 2,  8,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
       "\n",
       "        [[ 2, 20,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]]])"
      ]
     },
     "metadata": {},
     "execution_count": 169
    }
   ],
   "source": [
    "field_char.numericalize(field_char.preprocess((field_char.pad(\"Hello how are you\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[['SOS_WORD',\n",
       "   'H',\n",
       "   'EOS_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD']],\n",
       " [['SOS_WORD',\n",
       "   'e',\n",
       "   'EOS_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD']],\n",
       " [['SOS_WORD',\n",
       "   'l',\n",
       "   'EOS_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD']],\n",
       " [['SOS_WORD',\n",
       "   'l',\n",
       "   'EOS_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD']],\n",
       " [['SOS_WORD',\n",
       "   'o',\n",
       "   'EOS_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD']],\n",
       " [['SOS_WORD',\n",
       "   ' ',\n",
       "   'EOS_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD']],\n",
       " [['SOS_WORD',\n",
       "   'h',\n",
       "   'EOS_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD']],\n",
       " [['SOS_WORD',\n",
       "   'o',\n",
       "   'EOS_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD']],\n",
       " [['SOS_WORD',\n",
       "   'w',\n",
       "   'EOS_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD']],\n",
       " [['SOS_WORD',\n",
       "   ' ',\n",
       "   'EOS_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD']],\n",
       " [['SOS_WORD',\n",
       "   'a',\n",
       "   'EOS_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD']],\n",
       " [['SOS_WORD',\n",
       "   'r',\n",
       "   'EOS_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD']],\n",
       " [['SOS_WORD',\n",
       "   'e',\n",
       "   'EOS_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD']],\n",
       " [['SOS_WORD',\n",
       "   ' ',\n",
       "   'EOS_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD']],\n",
       " [['SOS_WORD',\n",
       "   'y',\n",
       "   'EOS_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD']],\n",
       " [['SOS_WORD',\n",
       "   'o',\n",
       "   'EOS_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD']],\n",
       " [['SOS_WORD',\n",
       "   'u',\n",
       "   'EOS_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD',\n",
       "   'PAD_WORD']]]"
      ]
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "source": [
    "field_char.pad(\"Hello how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}