{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.nli import *\n",
    "from src.model.nli_models import *\n",
    "from src.utils.nli_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_conf = {\"batch_size\":128,\"max_len\":100,\"device\":'cuda',\"tokenizer\":'spacy',\"use_char_emb\":False,\"max_word_len\":10}\n",
    "dataset = snli_module(snli_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning:\n",
      "\n",
      "Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning:\n",
      "\n",
      "LabelField class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "\n",
      "downloading snli_1.0.zip\n",
      "snli_1.0.zip: 100%|██████████| 94.6M/94.6M [00:04<00:00, 19.9MB/s]\n",
      "extracting\n",
      "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:13: UserWarning:\n",
      "\n",
      "Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "\n",
      ".vector_cache/glove.840B.300d.zip: 2.18GB [06:52, 5.27MB/s]                            \n",
      "100%|█████████▉| 2195919/2196017 [05:20<00:00, 7096.98it/s]/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning:\n",
      "\n",
      "BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "        \n",
    "\n",
    "\n",
    "class ESIM(nn.Module):\n",
    "    def __init__(self,conf):\n",
    "        super(ESIM, self).__init__()\n",
    "        self.conf = conf\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=conf[\"vocab_size\"],\n",
    "            embedding_dim=conf[\"embedding_dim\"],\n",
    "            padding_idx=conf[\"padding_idx\"],\n",
    "        )\n",
    "        self.translate = nn.Linear(conf[\"embedding_dim\"],conf[\"hidden_size\"])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=conf[\"dropout\"])\n",
    "\n",
    "        if conf[\"use_glove\"]:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                torch.load(\".vector_cache/{}_vectors.pt\".format(conf[\"dataset\"]))\n",
    "            )\n",
    "        self.lstm_layer = nn.LSTM(\n",
    "            input_size=conf[\"hidden_size\"],\n",
    "            hidden_size=conf[\"hidden_size\"],\n",
    "            num_layers=conf[\"num_layers\"],\n",
    "            dropout=conf[\"dropout\"],\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        \n",
    "        self.projection = nn.Sequential(nn.Linear(4*2*conf[\"hidden_size\"],conf[\"hidden_size\"]),nn.ReLU())\n",
    "        self.composition = nn.LSTM(\n",
    "            input_size=conf[\"hidden_size\"],\n",
    "            hidden_size=conf[\"hidden_size\"],\n",
    "            num_layers=conf[\"num_layers\"],\n",
    "            dropout=conf[\"dropout\"],\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "            )\n",
    "        self.classification = nn.Sequential(nn.Dropout(p=conf[\"dropout\"]),\n",
    "                                             nn.Linear(2*4*conf[\"hidden_size\"],\n",
    "                                                       conf[\"hidden_size\"]),\n",
    "                                             nn.Tanh(),\n",
    "                                             nn.Dropout(p=conf[\"dropout\"]),\n",
    "                                             nn.Linear(conf[\"hidden_size\"],\n",
    "                                                       2))\n",
    "\n",
    "    def forward(self,x0,x1):\n",
    "        x0_enc = self.encode(x0)\n",
    "        x1_enc = self.encode(x1)\n",
    "\n",
    "        x0_att,x1_att = self.softmax_attention(x0_enc,x1_enc)\n",
    "\n",
    "        enh_x0 = torch.cat([x0_enc,x0_att,x0_enc - x0_att,x0_enc * x0_att],dim=-1)\n",
    "        enh_x1 = torch.cat([x1_enc,x1_att,x1_enc - x1_att,x1_enc * x1_att],dim=-1)\n",
    "\n",
    "        proj_x0 = self.dropout(self.projection(enh_x0))\n",
    "        proj_x1 = self.dropout(self.projection(enh_x1))\n",
    "\n",
    "        comp_x0,(_,_) = self.composition(proj_x0)\n",
    "        comp_x1,(_,_) = self.composition(proj_x1)\n",
    "\n",
    "\n",
    "        avg_x0 = torch.mean(comp_x0,dim=1)\n",
    "        avg_x1 = torch.mean(comp_x1,dim=1)\n",
    "\n",
    "        max_x0 = torch.max(comp_x0,dim=1).values\n",
    "        max_x1 = torch.max(comp_x1,dim=1).values\n",
    "\n",
    "        v = torch.cat([avg_x0, avg_x1, max_x0, max_x1], dim=1)\n",
    "        return self.classification(v)\n",
    "\n",
    "\n",
    "    def softmax_attention(self,x,y):\n",
    "        similarity_matrix = x.bmm(y.transpose(2, 1).contiguous())\n",
    "        x_att = F.softmax(similarity_matrix,dim=1)\n",
    "        y_att = F.softmax(similarity_matrix.transpose(1, 2).contiguous(),dim=1)\n",
    "        x_att_emb = x_att.bmm(y)\n",
    "        y_att_emb = y_att.bmm(x)\n",
    "        return x_att_emb,y_att_emb\n",
    "        \n",
    "\n",
    "    def encode(self,x):\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = self.relu(self.translate(embedded))\n",
    "        all_, (_, _) = self.lstm_layer(embedded)\n",
    "        return all_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:61: UserWarning:\n\ndropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_conf = {\"dropout\":0.2,\"hidden_size\":300,\"num_layers\":1,\"use_glove\":False}\n",
    "model_conf[\"vocab_size\"] = dataset.vocab_size()\n",
    "model_conf[\"padding_idx\"] = dataset.padding_idx()\n",
    "model_conf[\"embedding_dim\"] = 300\n",
    "\n",
    "hparams = {\n",
    "    \"optimizer_base\": {\n",
    "        \"optim\": \"adamw\",\n",
    "        \"lr\": 0.0010039910781394373,\n",
    "        \"scheduler\": \"const\",\n",
    "    },\n",
    "    \"optimizer_tune\": {\n",
    "        \"optim\": \"adam\",\n",
    "        \"lr\": 0.0010039910781394373,\n",
    "        \"weight_decay\": 0.1,\n",
    "        \"scheduler\": \"lambda\",\n",
    "    },\n",
    "    \"switch_epoch\": 5,\n",
    "}\n",
    "\n",
    "model = ESIM(model_conf)\n",
    "# model = SNLI_model(attn_bilstm_snli,model_conf,hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "14601302"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl,val_dl,test_dl = dataset.data.get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[tensor([[   2,    4,   46,  ...,    1,    1,    1],\n        [   2,    4,   46,  ...,    1,    1,    1],\n        [   2,    4,   46,  ...,    1,    1,    1],\n        ...,\n        [   2, 1518, 1134,  ...,    1,    1,    1],\n        [   2,    6, 2169,  ...,    1,    1,    1],\n        [   2,    6, 2169,  ...,    1,    1,    1]]), tensor([[ 2,  4, 46,  ...,  1,  1,  1],\n        [ 2,  4, 46,  ...,  1,  1,  1],\n        [ 2,  4, 46,  ...,  1,  1,  1],\n        ...,\n        [ 2,  4, 33,  ...,  1,  1,  1],\n        [ 2,  4, 33,  ...,  1,  1,  1],\n        [ 2,  4, 33,  ...,  1,  1,  1]])], tensor([2, 1, 0, 2, 0, 1, 1, 0, 2, 2, 1, 2, 2, 1, 0, 2, 1, 0, 0, 1, 2, 2, 1, 0,\n        1, 0, 2, 2, 1, 0, 2, 0, 1, 1, 2, 0, 1, 0, 2, 2, 0, 1, 2, 0, 0, 0, 2, 1,\n        1, 0, 2, 1, 0, 2, 1, 2, 0, 2, 1, 0, 0, 1, 2, 0, 2, 1, 1, 0, 2, 1, 0, 2,\n        2, 1, 0, 2, 1, 0, 1, 0, 2, 2, 1, 0, 0, 1, 2, 1, 0, 2, 1, 0, 1, 2, 1, 2,\n        0, 2, 2, 0, 2, 1, 1, 0, 0, 2, 0, 1, 1, 0, 2, 2, 0, 1, 1, 2, 0, 0, 2, 1,\n        1, 2, 0, 1, 2, 0, 2, 0])]\n"
     ]
    }
   ],
   "source": [
    "for i in train_dl:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([128, 100, 600])\ntorch.Size([128, 2400])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0282, -0.0408],\n",
       "        [ 0.0202, -0.0525],\n",
       "        [ 0.0224, -0.0503],\n",
       "        [ 0.0366, -0.0530],\n",
       "        [ 0.0353, -0.0414],\n",
       "        [ 0.0398, -0.0516],\n",
       "        [ 0.0286, -0.0404],\n",
       "        [ 0.0290, -0.0517],\n",
       "        [ 0.0377, -0.0596],\n",
       "        [ 0.0204, -0.0438],\n",
       "        [ 0.0305, -0.0502],\n",
       "        [ 0.0277, -0.0437],\n",
       "        [ 0.0196, -0.0325],\n",
       "        [ 0.0272, -0.0532],\n",
       "        [ 0.0174, -0.0504],\n",
       "        [ 0.0371, -0.0332],\n",
       "        [ 0.0281, -0.0441],\n",
       "        [ 0.0380, -0.0396],\n",
       "        [ 0.0398, -0.0366],\n",
       "        [ 0.0326, -0.0413],\n",
       "        [ 0.0293, -0.0479],\n",
       "        [ 0.0269, -0.0540],\n",
       "        [ 0.0330, -0.0464],\n",
       "        [ 0.0171, -0.0616],\n",
       "        [ 0.0361, -0.0551],\n",
       "        [ 0.0270, -0.0508],\n",
       "        [ 0.0408, -0.0427],\n",
       "        [ 0.0364, -0.0420],\n",
       "        [ 0.0377, -0.0497],\n",
       "        [ 0.0309, -0.0478],\n",
       "        [ 0.0342, -0.0489],\n",
       "        [ 0.0241, -0.0464],\n",
       "        [ 0.0353, -0.0432],\n",
       "        [ 0.0265, -0.0490],\n",
       "        [ 0.0292, -0.0527],\n",
       "        [ 0.0409, -0.0452],\n",
       "        [ 0.0413, -0.0467],\n",
       "        [ 0.0348, -0.0442],\n",
       "        [ 0.0302, -0.0485],\n",
       "        [ 0.0397, -0.0378],\n",
       "        [ 0.0330, -0.0451],\n",
       "        [ 0.0329, -0.0508],\n",
       "        [ 0.0347, -0.0536],\n",
       "        [ 0.0324, -0.0464],\n",
       "        [ 0.0269, -0.0581],\n",
       "        [ 0.0279, -0.0397],\n",
       "        [ 0.0440, -0.0538],\n",
       "        [ 0.0274, -0.0523],\n",
       "        [ 0.0388, -0.0442],\n",
       "        [ 0.0325, -0.0483],\n",
       "        [ 0.0374, -0.0449],\n",
       "        [ 0.0356, -0.0528],\n",
       "        [ 0.0268, -0.0595],\n",
       "        [ 0.0334, -0.0559],\n",
       "        [ 0.0374, -0.0406],\n",
       "        [ 0.0304, -0.0469],\n",
       "        [ 0.0315, -0.0493],\n",
       "        [ 0.0231, -0.0403],\n",
       "        [ 0.0322, -0.0419],\n",
       "        [ 0.0386, -0.0509],\n",
       "        [ 0.0480, -0.0617],\n",
       "        [ 0.0286, -0.0595],\n",
       "        [ 0.0309, -0.0479],\n",
       "        [ 0.0309, -0.0467],\n",
       "        [ 0.0303, -0.0495],\n",
       "        [ 0.0303, -0.0454],\n",
       "        [ 0.0312, -0.0427],\n",
       "        [ 0.0262, -0.0540],\n",
       "        [ 0.0281, -0.0468],\n",
       "        [ 0.0313, -0.0517],\n",
       "        [ 0.0225, -0.0466],\n",
       "        [ 0.0349, -0.0460],\n",
       "        [ 0.0259, -0.0446],\n",
       "        [ 0.0253, -0.0436],\n",
       "        [ 0.0362, -0.0482],\n",
       "        [ 0.0311, -0.0297],\n",
       "        [ 0.0361, -0.0517],\n",
       "        [ 0.0355, -0.0536],\n",
       "        [ 0.0147, -0.0316],\n",
       "        [ 0.0261, -0.0541],\n",
       "        [ 0.0328, -0.0462],\n",
       "        [ 0.0306, -0.0421],\n",
       "        [ 0.0330, -0.0543],\n",
       "        [ 0.0248, -0.0332],\n",
       "        [ 0.0421, -0.0564],\n",
       "        [ 0.0341, -0.0409],\n",
       "        [ 0.0396, -0.0447],\n",
       "        [ 0.0320, -0.0460],\n",
       "        [ 0.0161, -0.0573],\n",
       "        [ 0.0382, -0.0513],\n",
       "        [ 0.0382, -0.0359],\n",
       "        [ 0.0244, -0.0524],\n",
       "        [ 0.0283, -0.0507],\n",
       "        [ 0.0280, -0.0309],\n",
       "        [ 0.0339, -0.0448],\n",
       "        [ 0.0224, -0.0451],\n",
       "        [ 0.0389, -0.0533],\n",
       "        [ 0.0284, -0.0447],\n",
       "        [ 0.0284, -0.0401],\n",
       "        [ 0.0428, -0.0457],\n",
       "        [ 0.0334, -0.0407],\n",
       "        [ 0.0345, -0.0597],\n",
       "        [ 0.0270, -0.0461],\n",
       "        [ 0.0259, -0.0544],\n",
       "        [ 0.0332, -0.0446],\n",
       "        [ 0.0302, -0.0407],\n",
       "        [ 0.0419, -0.0512],\n",
       "        [ 0.0350, -0.0442],\n",
       "        [ 0.0334, -0.0341],\n",
       "        [ 0.0250, -0.0517],\n",
       "        [ 0.0388, -0.0521],\n",
       "        [ 0.0340, -0.0607],\n",
       "        [ 0.0422, -0.0437],\n",
       "        [ 0.0386, -0.0501],\n",
       "        [ 0.0263, -0.0446],\n",
       "        [ 0.0250, -0.0326],\n",
       "        [ 0.0319, -0.0435],\n",
       "        [ 0.0344, -0.0618],\n",
       "        [ 0.0343, -0.0385],\n",
       "        [ 0.0272, -0.0553],\n",
       "        [ 0.0277, -0.0456],\n",
       "        [ 0.0401, -0.0482],\n",
       "        [ 0.0309, -0.0391],\n",
       "        [ 0.0299, -0.0435],\n",
       "        [ 0.0389, -0.0461],\n",
       "        [ 0.0329, -0.0471],\n",
       "        [ 0.0379, -0.0353],\n",
       "        [ 0.0289, -0.0472]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "model(i[0][0],i[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97ebcedef97547a89decafe15126da0b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'x1'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1f2bcaf5c2f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlr_finder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlr_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"exp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlr_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlr_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_lr_finder/lr_finder.py\u001b[0m in \u001b[0;36mrange_test\u001b[0;34m(self, train_loader, val_loader, start_lr, end_lr, num_iter, step_mode, smooth_f, diverge_th, accumulation_steps, non_blocking_transfer)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0maccumulation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mnon_blocking_transfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking_transfer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             )\n\u001b[1;32m    322\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_lr_finder/lr_finder.py\u001b[0m in \u001b[0;36m_train_batch\u001b[0;34m(self, train_iter, accumulation_steps, non_blocking_transfer)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'x1'"
     ]
    }
   ],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(train_dl, val_loader=val_dl, end_lr=0.01, num_iter=100, step_mode=\"exp\")\n",
    "lr_finder.plot(log_lr=False)\n",
    "lr_finder.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (128x400 and 2400x300)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-188c2cabb68b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-b01822a21508>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x0, x1)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mavg_x0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_x1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_x0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_x1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x400 and 2400x300)"
     ]
    }
   ],
   "source": [
    "model.cpu()\n",
    "model(i[0][0].cpu(),i[0][1].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[   2,    4,   46,  ...,    1,    1,    1],\n",
       "        [   2,    4,   46,  ...,    1,    1,    1],\n",
       "        [   2,    4,   46,  ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [   2, 1518, 1134,  ...,    1,    1,    1],\n",
       "        [   2,    6, 2169,  ...,    1,    1,    1],\n",
       "        [   2,    6, 2169,  ...,    1,    1,    1]])"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "i[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_sum = x_att.bmm(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['_train_transforms',\n",
       " '_val_transforms',\n",
       " '_test_transforms',\n",
       " 'dims',\n",
       " '_has_prepared_data',\n",
       " '_has_setup_fit',\n",
       " '_has_setup_test',\n",
       " 'conf',\n",
       " 'batch_size',\n",
       " 'data',\n",
       " '__module__',\n",
       " '__init__',\n",
       " 'prepare_data',\n",
       " 'train_dataloader',\n",
       " 'val_dataloader',\n",
       " 'test_dataloader',\n",
       " 'vocab_size',\n",
       " 'char_vocab_size',\n",
       " 'padding_idx',\n",
       " 'charpadding_idx',\n",
       " 'out_dim',\n",
       " 'labels',\n",
       " '__doc__',\n",
       " 'setup',\n",
       " '__annotations__',\n",
       " 'name',\n",
       " 'train_transforms',\n",
       " 'val_transforms',\n",
       " 'test_transforms',\n",
       " 'size',\n",
       " 'has_prepared_data',\n",
       " 'has_setup_fit',\n",
       " 'has_setup_test',\n",
       " 'transfer_batch_to_device',\n",
       " 'add_argparse_args',\n",
       " 'from_argparse_args',\n",
       " 'get_init_arguments_and_types',\n",
       " '__dict__',\n",
       " '__weakref__',\n",
       " '__repr__',\n",
       " '__hash__',\n",
       " '__str__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__new__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "dataset.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'SNLIDataModule' object has no attribute 'embedding_dim'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-133dcf6a70ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SNLIDataModule' object has no attribute 'embedding_dim'"
     ]
    }
   ],
   "source": [
    "dataset.embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}