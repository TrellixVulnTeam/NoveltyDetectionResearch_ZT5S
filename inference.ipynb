{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.nli_models import *\n",
    "from src.model.novelty_models import *\n",
    "from src.defaults import *\n",
    "from torchtext.data import Example \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import html\n",
    "import random\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import IFrame\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from transformers import BertTokenizer, DistilBertTokenizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def encode_text(text,field):\n",
    "    ex = Example.fromlist([text],[(\"text\",field)])\n",
    "    enc = field.process([ex.text])\n",
    "    return torch.tensor(enc)\n",
    "\n",
    "def load_novelty_model(_id):\n",
    "    # load model data \n",
    "    check_model(_id)\n",
    "    def load_model_data(_id):\n",
    "        model_path = os.path.join(\"./results/\", _id, \"model.pt\")\n",
    "        model_data = torch.load(model_path)\n",
    "        return model_data\n",
    "    field = load_field(_id)\n",
    "    model_data = load_model_data(_id)\n",
    "    encoder_id = model_data[\"options\"][\"load_nli\"]\n",
    "    check_model(encoder_id)\n",
    "\n",
    "    def load_encoder(enc_data):\n",
    "        if enc_data[\"options\"].get(\"attention_layer_param\", 0) == 0:\n",
    "            enc_data[\"options\"][\"use_glove\"] = False\n",
    "            model = bilstm_snli(enc_data[\"options\"])\n",
    "        elif enc_data[\"options\"].get(\"r\", 0) == 0:\n",
    "            enc_data[\"options\"][\"use_glove\"] = False\n",
    "            model = attn_bilstm_snli(enc_data[\"options\"])\n",
    "        else:\n",
    "            enc_data[\"options\"][\"use_glove\"] = False\n",
    "            model = struc_attn_snli(enc_data[\"options\"])\n",
    "        model.load_state_dict(enc_data[\"model_dict\"])\n",
    "        return model\n",
    "    \n",
    "    enc_data = load_encoder_data(encoder_id)\n",
    "    encoder = load_encoder(enc_data).encoder\n",
    "\n",
    "    model = HAN(model_data[\"options\"],encoder)\n",
    "    model.load_state_dict(model_data[\"model_dict\"])\n",
    "    return model,field\n",
    "\n",
    "def decode(inp,field):\n",
    "    if hasattr(field.nesting_field,\"vocab\"):\n",
    "        return [[field.nesting_field.vocab.itos[i] for i in sent] for sent in inp]\n",
    "    else:\n",
    "        tok = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "        return [tok.convert_ids_to_tokens(i) for i in inp.tolist()]\n",
    "\n",
    "\n",
    "def attention_combined(inp,field,s_att,w_att=None):\n",
    "    tok_str = decode(inp,field)\n",
    "    assert len(tok_str) == s_att.shape[0]\n",
    "    assert len(tok_str) == w_att.shape[0]\n",
    "    assert len(tok_str[0]) == w_att.shape[1]\n",
    "    \n",
    "\n",
    "    opt = []\n",
    "    for sent in range(len(tok_str)):\n",
    "        sent_with_att = []\n",
    "        for word in range(len(tok_str[0])):\n",
    "            word_str = tok_str[sent][word]\n",
    "            if word_str not in [\"<pad>\",'[PAD]']:\n",
    "                sent_with_att.append((word_str,w_att[sent][word].item()))\n",
    "        if sent_with_att!=[]:\n",
    "            opt.append((sent_with_att,s_att[sent].item()))\n",
    "    return opt\n",
    "\n",
    "\n",
    "\n",
    "def html_string(word,color,new_line = False):\n",
    "    template = '<span class=\"barcode\"; style=\"color: black; background-color: {}\">{}</span>'\n",
    "    colored_string = template.format(color, '&nbsp' + word + '&nbsp') + (\"<br>\" if new_line else \"\")\n",
    "    return colored_string\n",
    "\n",
    "\n",
    "def colorize(attention_list):\n",
    "    cmap_sent = matplotlib.cm.Blues\n",
    "    cmap_word = matplotlib.cm.Reds\n",
    "\n",
    "    template = '<span class=\"barcode\"; style=\"color: black; background-color: {}\">{}</span>'\n",
    "    colored_string = ''\n",
    "\n",
    "    for sent, sent_att in attention_list:\n",
    "        sent_color = matplotlib.colors.rgb2hex(cmap_sent(sent_att*5)[:3])\n",
    "        colored_string  += html_string('\\t---\\t ',sent_color)\n",
    "        for word,word_att in sent:\n",
    "            word_color = matplotlib.colors.rgb2hex(cmap_word(word_att)[:3])\n",
    "            colored_string += html_string(word,word_color)\n",
    "        colored_string += \"<br>\"\n",
    "    colored_string += \"<br><br><br>\"\n",
    "    return colored_string\n",
    "\n",
    "    seed_torch()\n",
    "\n",
    "def plot_attention(src,trg,model,field,true_cls = False,return_html=False,cuda=False):\n",
    "    cmap_word = matplotlib.cm.inferno\n",
    "\n",
    "    s_enc = encode_text(src,field)\n",
    "    t_enc = encode_text(trg,field)\n",
    "    template = '<span class=\"barcode\"; style=\"color: black; background-color: {}\">{}</span>'\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if cuda == True:\n",
    "            s_enc = s_enc.cuda()\n",
    "            t_enc = t_enc.cuda()\n",
    "        opt,s_att,t_att = model.forward_with_attn(s_enc,t_enc)\n",
    "        pred = F.softmax(opt)\n",
    "        pred = pred.cpu()\n",
    "        s_att = [i.cpu() for i in s_att]\n",
    "        t_att = [i.cpu() for i in t_att]\n",
    "\n",
    "    src_att_map = attention_combined(s_enc[0],field,s_att[0].permute((1,0)),s_att[1][0])\n",
    "    trg_att_map = attention_combined(t_enc[0],field,t_att[0].permute((1,0)),t_att[1][0])\n",
    "\n",
    "    s_html = colorize(src_att_map)\n",
    "    t_html = colorize(trg_att_map)\n",
    "    if pred[0][0].item()>0.5:\n",
    "        prob = pred[0][0].item()\n",
    "        pred_str = \"Prediction :    \" +str(pred[0][0].item())+ \"   Non-Novel\"\n",
    "    else:\n",
    "        prob = pred[0][1].item()\n",
    "        pred_str = \"Prediction :    \" +str(pred[0][1].item())+ \"   Novel\"\n",
    "    \n",
    "    col = matplotlib.colors.rgb2hex(cmap_word(prob)[:3])\n",
    "    pred_html = template.format(col,pred_str)\n",
    "    \n",
    "    if true_cls:\n",
    "        pred_html += \"<br> \" +template.format(col,\" True Class :   \"+true_cls)\n",
    "    if return_html:\n",
    "        return s_html+t_html+ \"<br><br><br>\"+pred_html, pred[0]\n",
    "    with open('colorize.html', 'w') as f:\n",
    "        f.write(s_html+t_html+ \"<br><br><br>\"+pred_html )\n",
    "    \n",
    "\n",
    "\n",
    "def disp_attention():\n",
    "    IFrame('./colorize.html',width=1200,height=400)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,field = load_novelty_model('NOV-1146') # 54,46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"We also experimented with the document encoder to find if document level pretraining has any impact on the novelty detection performance. We train our document encoder described in on the Reuters dataset with an objective of 10 class classification. The reuters dataset aligns with the dataset we use for novelty detection, the Reuters dataset contains news articles which are to be classified into categories like Investment, Shipping, Crop, Oil and so on\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Identifing each of these classes requires the ability to extract features which tell which industry the news is related to. We hypothesise that this information is also essential while calculating the novelty of a document, since knowing if the target document is talking about the same thing or topic is also important. This can be seen as assisting the information filtering task. For this experiment we have 3 settings, we test the impact with and without pretraining for Reuters dataset and Reuters+NLI dataset combined. The settings used are listed below.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = plot_attention(source,target,model,field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f26ef2be5d0>"
      ],
      "text/html": "\n        <iframe\n            width=\"2200\"\n            height=\"1000\"\n            src=\"./colorize.html\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        "
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "IFrame('./colorize.html',width=2200,height=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.data/dlnd/TAP-DLND-1.0_LREC2018_modified/dlnd.jsonl','r') as f:\n",
    "    items = f.readlines()\n",
    "data = [json.loads(i) for i in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction:\n",
      "Actual:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Novel'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "example = data[120]\n",
    "print(\"Prediction:\")\n",
    "plot_attention(example[\"source\"],example[\"target_text\"],model,field,example[\"DLA\"])\n",
    "print(\"Actual:\")\n",
    "example[\"DLA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa57f666b50>"
      ],
      "text/html": "\n        <iframe\n            width=\"2200\"\n            height=\"2000\"\n            src=\"./colorize.html\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        "
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "IFrame('./colorize.html',width=2200,height=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4765\n"
     ]
    }
   ],
   "source": [
    "lens = []\n",
    "for i in data:\n",
    "    lens.append(len(i['source']))\n",
    "print(lens.index(min(lens)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [(i,lens[i]) for i in range(len(lens))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "\n",
    "from tqdm import tqdm\n",
    "def predict(data,model,field):\n",
    "    wrong_pred_path = './results/all_pred/wrong_pred'\n",
    "    correct_pred_path = './results/all_pred/correct_pred'\n",
    "    if not os.path.exists(correct_pred_path):\n",
    "        os.makedirs(wrong_pred_path)\n",
    "        os.makedirs(correct_pred_path)\n",
    "\n",
    "    for i in tqdm(range(len(data))):\n",
    "        src = data[i]['source']\n",
    "        trg = data[i]['target_text']\n",
    "        true = data[i]['DLA']\n",
    "        html_str,pred = plot_attention(src,trg,model,field,true_cls = true,return_html=True,cuda=True)\n",
    "        pred_lab = \"Non-Novel\" if pred[0]>0.5 else \"Novel\"\n",
    "            \n",
    "        if pred_lab!=true:\n",
    "            html_path = os.path.join(wrong_pred_path,str(i)+\".html\")\n",
    "            with open(html_path,'w') as f:\n",
    "                f.write(html_str)\n",
    "        else:\n",
    "            html_path = os.path.join(correct_pred_path,str(i)+\".html\")\n",
    "            with open(html_path,'w') as f:\n",
    "                f.write(html_str)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "\n",
    "from tqdm import tqdm\n",
    "def predict(data,model,field):\n",
    "    \n",
    "    wrong_id = []\n",
    "    for i in tqdm(range(len(data))):\n",
    "        src = data[i]['source']\n",
    "        trg = data[i]['target_text']\n",
    "        true = data[i]['DLA']\n",
    "        s_enc = encode_text(src,field)\n",
    "        t_enc = encode_text(trg,field)\n",
    "        \n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            opt,s_att,t_att = model.forward_with_attn(s_enc.cuda(),t_enc.cuda())\n",
    "            pred = F.softmax(opt)[0][1].item()\n",
    "        if pred > 0.5:\n",
    "            pred = \"Novel\"\n",
    "        else:\n",
    "            pred = \"Non-Novel\"\n",
    "        if pred!=true:\n",
    "            wrong_id.append(i)\n",
    "    return wrong_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 5435/5435 [02:49<00:00, 32.05it/s]\n"
     ]
    }
   ],
   "source": [
    "wrong_id = predict(data,model,field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "HAN(\n",
       "  (encoder): HAN_DOC(\n",
       "    (encoder): Attn_Encoder(\n",
       "      (embedding): Embedding(33934, 300, padding_idx=1)\n",
       "      (translate): Linear(in_features=300, out_features=400, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (lstm_layer): LSTM(400, 400, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "      (attention): Attention(\n",
       "        (Ws): Linear(in_features=800, out_features=200, bias=False)\n",
       "        (Wa): Linear(in_features=200, out_features=1, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (translate): Linear(in_features=800, out_features=400, bias=True)\n",
       "    (act): ReLU()\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (lstm_layer): LSTM(400, 400, bidirectional=True)\n",
       "    (attention): StrucSelfAttention(\n",
       "      (ut_dense): Linear(in_features=800, out_features=200, bias=False)\n",
       "      (et_dense): Linear(in_features=200, out_features=10, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (act): ReLU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=32000, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5261, 2128)\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for i in sorted(lens,key = lambda x:x[1]): \n",
    "    c+=1\n",
    "    if i[0] in wrong_id:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "wrong_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 12.92931979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}