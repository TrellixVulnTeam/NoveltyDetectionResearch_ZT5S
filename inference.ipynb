{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.nli_models import *\n",
    "from src.model.novelty_models import *\n",
    "from src.defaults import *\n",
    "from torchtext.data import Example \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import html\n",
    "import random\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import IFrame\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from transformers import BertTokenizer, DistilBertTokenizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def encode_text(text,field):\n",
    "    ex = Example.fromlist([text],[(\"text\",field)])\n",
    "    enc = field.process([ex.text])\n",
    "    return torch.tensor(enc)\n",
    "\n",
    "def load_novelty_model(_id):\n",
    "    # load model data \n",
    "    check_model(_id)\n",
    "    def load_model_data(_id):\n",
    "        model_path = os.path.join(\"./results/\", _id, \"model.pt\")\n",
    "        model_data = torch.load(model_path)\n",
    "        return model_data\n",
    "    field = load_field(_id)\n",
    "    model_data = load_model_data(_id)\n",
    "    encoder_id = model_data[\"options\"][\"load_nli\"]\n",
    "    check_model(encoder_id)\n",
    "\n",
    "    def load_encoder(enc_data):\n",
    "        if enc_data[\"options\"].get(\"attention_layer_param\", 0) == 0:\n",
    "            enc_data[\"options\"][\"use_glove\"] = False\n",
    "            model = bilstm_snli(enc_data[\"options\"])\n",
    "        elif enc_data[\"options\"].get(\"r\", 0) == 0:\n",
    "            enc_data[\"options\"][\"use_glove\"] = False\n",
    "            model = attn_bilstm_snli(enc_data[\"options\"])\n",
    "        else:\n",
    "            enc_data[\"options\"][\"use_glove\"] = False\n",
    "            model = struc_attn_snli(enc_data[\"options\"])\n",
    "        model.load_state_dict(enc_data[\"model_dict\"])\n",
    "        return model\n",
    "    \n",
    "    enc_data = load_encoder_data(encoder_id)\n",
    "    encoder = load_encoder(enc_data).encoder\n",
    "\n",
    "    model = HAN(model_data[\"options\"],encoder)\n",
    "    model.load_state_dict(model_data[\"model_dict\"])\n",
    "    return model,field\n",
    "\n",
    "def decode(inp,field):\n",
    "    if hasattr(field.nesting_field,\"vocab\"):\n",
    "        return [[field.nesting_field.vocab.itos[i] for i in sent] for sent in inp]\n",
    "    else:\n",
    "        tok = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "        return [tok.convert_ids_to_tokens(i) for i in inp.tolist()]\n",
    "\n",
    "\n",
    "def attention_combined(inp,field,s_att,w_att=None):\n",
    "    tok_str = decode(inp,field)\n",
    "    assert len(tok_str) == s_att.shape[0]\n",
    "    assert len(tok_str) == w_att.shape[0]\n",
    "    assert len(tok_str[0]) == w_att.shape[1]\n",
    "    \n",
    "\n",
    "    opt = []\n",
    "    for sent in range(len(tok_str)):\n",
    "        sent_with_att = []\n",
    "        for word in range(len(tok_str[0])):\n",
    "            word_str = tok_str[sent][word]\n",
    "            if word_str not in [\"<pad>\",'[PAD]']:\n",
    "                sent_with_att.append((word_str,w_att[sent][word].item()))\n",
    "        if sent_with_att!=[]:\n",
    "            opt.append((sent_with_att,s_att[sent].item()))\n",
    "    return opt\n",
    "        \n",
    "\n",
    "\n",
    "def html_string(word,color,new_line = False):\n",
    "    template = '<span class=\"barcode\"; style=\"color: black; background-color: {}\">{}</span>'\n",
    "    colored_string = template.format(color, '&nbsp' + word + '&nbsp') + (\"<br>\" if new_line else \"\")\n",
    "    return colored_string\n",
    "\n",
    "\n",
    "def colorize(attention_list):\n",
    "    cmap_sent = matplotlib.cm.Blues\n",
    "    cmap_word = matplotlib.cm.Reds\n",
    "\n",
    "    template = '<span class=\"barcode\"; style=\"color: black; background-color: {}\">{}</span>'\n",
    "    colored_string = ''\n",
    "\n",
    "    for sent, sent_att in attention_list:\n",
    "        sent_color = matplotlib.colors.rgb2hex(cmap_sent(sent_att*5)[:3])\n",
    "        colored_string  += html_string('\\t---\\t ',sent_color)\n",
    "        for word,word_att in sent:\n",
    "            word_color = matplotlib.colors.rgb2hex(cmap_word(word_att)[:3])\n",
    "            colored_string += html_string(word,word_color)\n",
    "        colored_string += \"<br>\"\n",
    "    colored_string += \"<br><br><br>\"\n",
    "    return colored_string\n",
    "\n",
    "    seed_torch()\n",
    "\n",
    "def plot_attention(src,trg,model,field,true_cls = False):\n",
    "    cmap_word = matplotlib.cm.inferno\n",
    "\n",
    "    s_enc = encode_text(src,field)\n",
    "    t_enc = encode_text(trg,field)\n",
    "    template = '<span class=\"barcode\"; style=\"color: black; background-color: {}\">{}</span>'\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        opt,s_att,t_att = model.forward_with_attn(s_enc,t_enc)\n",
    "        pred = F.softmax(opt)\n",
    "\n",
    "    src_att_map = attention_combined(s_enc[0],field,s_att[0].permute((1,0)),s_att[1][0])\n",
    "    trg_att_map = attention_combined(t_enc[0],field,t_att[0].permute((1,0)),t_att[1][0])\n",
    "\n",
    "    s_html = colorize(src_att_map)\n",
    "    t_html = colorize(trg_att_map)\n",
    "    if pred[0][0].item()>0.5:\n",
    "        prob = pred[0][0].item()\n",
    "        pred_str = \"Prediction :    \" +str(pred[0][0].item())+ \"   Non-Novel\"\n",
    "    else:\n",
    "        prob = pred[0][1].item()\n",
    "        pred_str = \"Prediction :    \" +str(pred[0][1].item())+ \"   Novel\"\n",
    "    \n",
    "    col = matplotlib.colors.rgb2hex(cmap_word(prob)[:3])\n",
    "    pred_html = template.format(col,pred_str)\n",
    "    \n",
    "    if true_cls:\n",
    "        pred_html += \"<br> \" +template.format(col,\" True Class :   \"+true_cls)\n",
    "\n",
    "    with open('colorize.html', 'w') as f:\n",
    "        f.write(s_html+t_html+ \"<br><br><br>\"+pred_html )\n",
    "    \n",
    "\n",
    "\n",
    "def disp_attention():\n",
    "    IFrame('./colorize.html',width=1200,height=400)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,field = load_novelty_model('NOV-1146') # 54,46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"We also experimented with the document encoder to find if document level pretraining has any impact on the novelty detection performance. We train our document encoder described in on the Reuters dataset with an objective of 10 class classification. The reuters dataset aligns with the dataset we use for novelty detection, the Reuters dataset contains news articles which are to be classified into categories like Investment, Shipping, Crop, Oil and so on\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Identifing each of these classes requires the ability to extract features which tell which industry the news is related to. We hypothesise that this information is also essential while calculating the novelty of a document, since knowing if the target document is talking about the same thing or topic is also important. This can be seen as assisting the information filtering task. For this experiment we have 3 settings, we test the impact with and without pretraining for Reuters dataset and Reuters+NLI dataset combined. The settings used are listed below.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = plot_attention(source,target,model,field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa57f58b690>"
      ],
      "text/html": "\n        <iframe\n            width=\"2200\"\n            height=\"1000\"\n            src=\"./colorize.html\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        "
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "IFrame('./colorize.html',width=2200,height=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.data/dlnd/TAP-DLND-1.0_LREC2018_modified/dlnd.jsonl','r') as f:\n",
    "    items = f.readlines()\n",
    "data = [json.loads(i) for i in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction:\n",
      "Actual:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Novel'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "example = data[120]\n",
    "print(\"Prediction:\")\n",
    "plot_attention(example[\"source\"],example[\"target_text\"],model,field,example[\"DLA\"])\n",
    "print(\"Actual:\")\n",
    "example[\"DLA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa57f666b50>"
      ],
      "text/html": "\n        <iframe\n            width=\"2200\"\n            height=\"2000\"\n            src=\"./colorize.html\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        "
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "IFrame('./colorize.html',width=2200,height=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4765\n"
     ]
    }
   ],
   "source": [
    "lens = []\n",
    "for i in data:\n",
    "    lens.append(len(i['source']))\n",
    "print(lens.index(min(lens)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [(i,lens[i]) for i in range(len(lens))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "\n",
    "from tqdm import tqdm\n",
    "def predict(data,model,field):\n",
    "    wrong_id = []\n",
    "    for i in tqdm(range(len(data))):\n",
    "        src = data[i]['source']\n",
    "        trg = data[i]['target_text']\n",
    "        true = data[i]['DLA']\n",
    "        s_enc = encode_text(src,field)\n",
    "        t_enc = encode_text(trg,field)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            opt,s_att,t_att = model.forward_with_attn(s_enc.cuda(),t_enc.cuda())\n",
    "            pred = F.softmax(opt)[0][1].item()\n",
    "        if pred > 0.5:\n",
    "            pred = \"Novel\"\n",
    "        else:\n",
    "            pred = \"Non-Novel\"\n",
    "        if pred!=true:\n",
    "            wrong_id.append(i)\n",
    "    return wrong_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 5435/5435 [02:49<00:00, 32.05it/s]\n"
     ]
    }
   ],
   "source": [
    "wrong_id = predict(data,model,field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "HAN(\n",
       "  (encoder): HAN_DOC(\n",
       "    (encoder): Attn_Encoder(\n",
       "      (embedding): Embedding(33934, 300, padding_idx=1)\n",
       "      (translate): Linear(in_features=300, out_features=400, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (lstm_layer): LSTM(400, 400, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "      (attention): Attention(\n",
       "        (Ws): Linear(in_features=800, out_features=200, bias=False)\n",
       "        (Wa): Linear(in_features=200, out_features=1, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (translate): Linear(in_features=800, out_features=400, bias=True)\n",
       "    (act): ReLU()\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (lstm_layer): LSTM(400, 400, bidirectional=True)\n",
       "    (attention): StrucSelfAttention(\n",
       "      (ut_dense): Linear(in_features=800, out_features=200, bias=False)\n",
       "      (et_dense): Linear(in_features=200, out_features=10, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (act): ReLU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=32000, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5261, 2128)\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for i in sorted(lens,key = lambda x:x[1]): \n",
    "    c+=1\n",
    "    if i[0] in wrong_id:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "wrong_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"\"\"ORANGE, Calif. — A gunman opened fire at a Southern California real estate office on Wednesday, killing four people, including a 9-year-old boy who the authorities said appeared to have died in his mother’s arms as she tried to shield him from the gunfire.\n",
    "\n",
    "The shooting was likely related to a “business and personal relationship which existed between the suspect and all of the victims,” Lt. Jennifer Amat, a spokeswoman for the Orange Police Department, said at a news conference on Thursday morning.\n",
    "\n",
    "“This appears to be an isolated incident, and we believe everyone knew each other,” Lieutenant Amat said.\n",
    "\n",
    "The woman holding the boy was wounded in the shooting and remained in a hospital on Thursday after emergency treatment, with the Orange County district attorney, Todd Spitzer, cautioning that their relationship had not been formally determined. The police did not provide details about the other victims, a man and two women, because their next of kin had not all been notified.\n",
    "\n",
    "The suspect, identified as Aminadab Gaxiola Gonzalez, 44, of Fullerton, was also hospitalized in critical condition with a gunshot wound, the authorities said.\n",
    "\n",
    "Dig deeper into the moment.\n",
    "Special offer: Subscribe for $1 a week.\n",
    "Mr. Spitzer called the shooting a “horrific massacre,” and said that officials would learn more as the investigation unfolded. “It is a horrible, horrible tragedy that Mr. Gonzalez made a decision to use deadly force to deal with issues he was dealing with, apparently, in his life,” Mr. Spitzer said.\n",
    "\n",
    "The attack in Orange, about 30 miles southeast of Los Angeles, occurred at the offices of Unified Homes, a real estate and mobile home dealer, according to the business’s website.\n",
    "\n",
    "When officers arrived after reports of a shooting around 5:30 p.m., the gates to the complex were closed with bicycle cable locks. The suspect fired shots toward officers, who fired their weapons from outside the gates, Lieutenant Amat said.\n",
    "\n",
    "Officers then forced their way in, using bolt cutters to enter, officials said. When they reached the courtyard, officers found a wounded Mr. Gonzalez and took him into custody. It was unclear whether the officers struck the suspect or whether his injuries were self-inflicted.\n",
    "\n",
    "Editors’ Picks\n",
    "\n",
    "Deals Designed to Lure Travelers Off Their Couches\n",
    "\n",
    "When Ian Desmond Opted Out, His Work Was Just Starting\n",
    "Continue reading the main story\n",
    "At the scene, which covered two floors and a courtyard area of the building, officials recovered a semiautomatic handgun and a backpack containing pepper spray, handcuffs and ammunition, Lieutenant Amat said. The suspect had arrived at the location in a rental car, she said, and was believed to have been living out of a hotel room in Anaheim.\n",
    "\n",
    "Wednesday’s shooting set people on edge both near and far from the scene because it came shortly after two nationally publicized mass shootings. On March 16, a gunman killed eight people at three spas in the Atlanta area. Six days later, a man stormed a grocery store in Boulder, Colo., and killed 10 people.\n",
    "\n",
    "Until the shooting in Atlanta, it had been a year since a large-scale shooting in a public place in the United States, according to the Violence Project. But researchers say the kind of violence that unfolded in Orange never went away during the coronavirus pandemic — it simply went out of view. Data from the Violence Project shows that in 2020 there were more than 600 shootings in which at least four people were shot by one person, compared with 417 in 2019.\n",
    "\n",
    "“Those numbers clearly indicate that it’s not that there were less during the pandemic, but actually more,” Ronnie Dunn, a professor of urban studies at Cleveland State University, said about mass shootings, adding that record gun sales may have added to the spike in shootings.\n",
    "\n",
    "“It’s almost as if people have become desensitized to the human loss of the shootings in urban areas,” he said.\n",
    "\n",
    "\n",
    "\n",
    "Emma Soto, 26, who lives in an apartment near the Orange real estate office, was doing laundry on Wednesday when she said she heard seven to 10 gunshots.\n",
    "\n",
    "“It just sounded like a popping sound,” she said, adding: “We’re hearing of all these shootings going on, so I just thought, ‘Another shooting.’ But we never imagined it would be that close to us.”\n",
    "\n",
    "Almost immediately after hearing the gunfire, Ms. Soto said, several police vehicles pulled up. She watched as officers emerged with their weapons drawn and ran toward the building.\n",
    "\n",
    "The neighborhood is typically quiet and peaceful, and it is largely Hispanic, said Ms. Soto, a manager at a nearby big-box store.\n",
    "\n",
    "Hope Orozco, 27, was with her 3-year-old son at a neighbor’s house when she said she heard the gunfire. She said her son liked to watch her neighbor’s children play Call of Duty, the popular video game. At first, she said, she mistook the commotion outside for gunfire from the game.\n",
    "\n",
    "“I was like, ‘Wait a minute, is this from the TV?’” Ms. Orozco said. She realized it was real after noticing that all the players were wearing headsets.\n",
    "\n",
    "Hector Gomez and Edgar Gonzalez work at a roofing business located on the first floor of the building where the shooting occurred. Mr. Gomez said the woman who ran the real estate office would often bring her son to the building.\n",
    "\n",
    "“He’s a cute little boy,” Mr. Gomez said.\n",
    "\n",
    "The two men said they were convinced the woman and her son were among the victims. The woman’s S.U.V. was still in the parking lot, they said, as the police conducted their investigation late into the evening.\n",
    "\n",
    "Mr. Gomez and Mr. Gonzalez usually leave the office around 5:30 p.m., when the shooting happened. On Wednesday, they left early.\n",
    "\n",
    "“It could have been us,” said Mr. Gomez, who came back with Mr. Gonzalez after hearing about the shooting from their boss. “I don’t want to say this, but it probably would have been us. Because we’re always the last ones here.”\n",
    "\n",
    "\n",
    "ImageInvestigators at the scene of a shooting in Orange, Calif., where four people were killed.\n",
    "Investigators at the scene of a shooting in Orange, Calif., where four people were killed.Credit...Allison Zaucha for The New York Times\n",
    "The squat commercial building where the shooting took place is mostly surrounded by homes and apartment buildings in Orange, a city of 139,000 people less than six miles from Disneyland. Late Wednesday evening, about a dozen police and fire vehicles blocked the wide Lincoln Avenue.\n",
    "\n",
    "The beige, low-rise building houses several businesses, including a property management company, an insurance agency and a consulting firm.\n",
    "\n",
    "Lieutenant Amat said Orange had not seen “an incident like this” since a rampage in 1997 at a Caltrans maintenance yard, in which a gunman killed four people and was later killed by the police in a shootout.\n",
    "\n",
    "Gov. Gavin Newsom of California said on Twitter that he was jolted by the shooting.\n",
    "\n",
    "“Horrifying and heartbreaking,” he said. “Our hearts are with the families impacted by this terrible tragedy.”\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"\"\"he man accused of carrying out a massacre at an office building in Orange Wednesday evening, leaving four people including a child dead, was charged in an assault case six years ago.\n",
    "\n",
    "Records from the Orange County Superior Court show Aminadab Gonzalez-Gaxiola faced four misdemeanor charges of child abuse and endangerment, assault with a deadly weapon other than a gun, dissuading a witness, and battery for an incident that occurred on March 31, 2015.\n",
    "\n",
    "Gonzalez-Gaxiola pleaded not guilty to all counts and prosecutors dismissed all but the battery charge at a hearing later that year. The battery charge was dismissed in 2017 after the records show Gonzalez-Gaxiola successfully completed a probationary sentence. \n",
    "\n",
    "Other court filings showed Gonzalez-Gaxiola was cited for traffic violations in 2014 and 2015, and one of the cases indicated that, at the time, he was working as a commercial truck driver.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9970517158508301 Non-Novel\n"
     ]
    }
   ],
   "source": [
    "a = plot_attention(source,target,model,field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f1c9c2f0b50>"
      ],
      "text/html": "\n        <iframe\n            width=\"2200\"\n            height=\"2000\"\n            src=\"./colorize.html\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        "
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "IFrame('./colorize.html',width=2200,height=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}