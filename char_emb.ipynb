{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_padded_index_sequences(datasets):\n",
    "    \"\"\"\n",
    "    Annotate datasets with feature vectors. Adding right-sided padding. \n",
    "    \"\"\"\n",
    "    # Extract vocabulary\n",
    "    def tokenize(string):\n",
    "        string = re.sub(r'\\(|\\)', '', string)\n",
    "        return string.split()\n",
    "    \n",
    "\n",
    "    word_counter = collections.Counter()\n",
    "    char_counter = collections.Counter()\n",
    "\n",
    "    for example in tqdm(dataset):\n",
    "        s1_tokenize = tokenize(example[0])\n",
    "        s2_tokenize = tokenize(example[1])\n",
    "\n",
    "        word_counter.update(s1_tokenize)\n",
    "        word_counter.update(s2_tokenize)\n",
    "\n",
    "        for i, word in enumerate(s1_tokenize):\n",
    "            char_counter.update([c for c in word])\n",
    "        for word in s2_tokenize:\n",
    "            char_counter.update([c for c in word])\n",
    "\n",
    "    vocabulary = set([word for word in word_counter])\n",
    "    vocabulary = list(vocabulary)\n",
    "    if config.embedding_replacing_rare_word_with_UNK: \n",
    "        vocabulary = [PADDING, \"<UNK>\"] + vocabulary\n",
    "    else:\n",
    "        vocabulary = [PADDING] + vocabulary\n",
    "    \n",
    "    word_indices = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "    indices_to_words = {v: k for k, v in word_indices.items()}\n",
    "    char_vocab = set([char for char in char_counter])\n",
    "    char_vocab = list(char_vocab)\n",
    "    char_vocab = [PADDING] + char_vocab\n",
    "    char_indices = dict(zip(char_vocab, range(len(char_vocab))))\n",
    "    indices_to_char = {v: k for k, v in char_indices.items()}\n",
    "    \n",
    "\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        for example in tqdm(dataset):\n",
    "            for sentence in [, 'sentence2_binary_parse']:\n",
    "                example[sentence + '_index_sequence'] = np.zeros((FIXED_PARAMETERS[\"seq_length\"]), dtype=np.int32)\n",
    "                example[sentence + '_inverse_term_frequency'] = np.zeros((FIXED_PARAMETERS[\"seq_length\"]), dtype=np.float32)\n",
    "\n",
    "                token_sequence = tokenize(example[sentence])\n",
    "                padding = FIXED_PARAMETERS[\"seq_length\"] - len(token_sequence)\n",
    "                      \n",
    "                for i in range(FIXED_PARAMETERS[\"seq_length\"]):\n",
    "                    if i >= len(token_sequence):\n",
    "                        index = word_indices[PADDING]\n",
    "                        itf = 0\n",
    "                    else:\n",
    "                        if config.embedding_replacing_rare_word_with_UNK:\n",
    "                            index = word_indices[token_sequence[i]] if word_counter[token_sequence[i]] >= config.UNK_threshold else word_indices[\"<UNK>\"]\n",
    "                        else:\n",
    "                            index = word_indices[token_sequence[i]]\n",
    "                        itf = 1 / (word_counter[token_sequence[i]] + 1)\n",
    "                    example[sentence + '_index_sequence'][i] = index\n",
    "                    \n",
    "                    example[sentence + '_inverse_term_frequency'][i] = itf\n",
    "                \n",
    "                example[sentence + '_char_index'] = np.zeros((FIXED_PARAMETERS[\"seq_length\"], config.char_in_word_size), dtype=np.int32)\n",
    "                for i in range(FIXED_PARAMETERS[\"seq_length\"]):\n",
    "                    if i >= len(token_sequence):\n",
    "                        continue\n",
    "                    else:\n",
    "                        chars = [c for c in token_sequence[i]]\n",
    "                        for j in range(config.char_in_word_size):\n",
    "                            if j >= (len(chars)):\n",
    "                                break\n",
    "                            else:\n",
    "                                index = char_indices[chars[j]]\n",
    "                            example[sentence + '_char_index'][i,j] = index \n",
    "    \n",
    "\n",
    "    return indices_to_words, word_indices, char_indices, indices_to_char\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import collections\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn \n",
    "import os\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tag import StanfordPOSTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py:183: DeprecationWarning: \nThe StanfordTokenizer will be deprecated in version 3.2.5.\nPlease use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py:149: DeprecationWarning: \nThe StanfordTokenizer will be deprecated in version 3.2.5.\nPlease use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "PADDING = \"<PAD>\"\n",
    "POS_Tagging = [PADDING, 'WP$', 'RBS', 'SYM', 'WRB', 'IN', 'VB', 'POS', 'TO', ':', '-RRB-', '$', 'MD', 'JJ', '#', 'CD', '``', 'JJR', 'NNP', \"''\", 'LS', 'VBP', 'VBD', 'FW', 'RBR', 'JJS', 'DT', 'VBG', 'RP', 'NNS', 'RB', 'PDT', 'PRP$', '.', 'XX', 'NNPS', 'UH', 'EX', 'NN', 'WDT', 'VBN', 'VBZ', 'CC', ',', '-LRB-', 'PRP', 'WP']\n",
    "POS_dict = {pos:i for i, pos in enumerate(POS_Tagging)}\n",
    "\n",
    "stemmer = nltk.SnowballStemmer('english')\n",
    "\n",
    "tt = nltk.tokenize.treebank.TreebankWordTokenizer()\n",
    "\n",
    "nst = StanfordNERTagger('stanford-ner-2020-11-17/classifiers/english.muc.7class.distsim.crf.ser.gz', 'stanford-ner-2020-11-17/stanford-ner-4.2.0.jar',encoding='utf-8')\n",
    "\n",
    "\n",
    "pst = StanfordPOSTagger('stanford-postagger-full-2020-11-17/models/english-bidirectional-distsim.tagger', \\\n",
    "                    'stanford-postagger-full-2020-11-17/stanford-postagger.jar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_exact_match(token1, token2):\n",
    "    token1 = token1.lower()\n",
    "    token2 = token2.lower()\n",
    "    \n",
    "    token1_stem = stemmer.stem(token1)\n",
    "\n",
    "    if token1 == token2:\n",
    "        return True\n",
    "    \n",
    "    for synsets in wn.synsets(token2):\n",
    "        for lemma in synsets.lemma_names():\n",
    "            if token1_stem == stemmer.stem(lemma):\n",
    "                return True\n",
    "    \n",
    "    if token1 == \"n't\" and token2 == \"not\":\n",
    "        return True\n",
    "    elif token1 == \"not\" and token2 == \"n't\":\n",
    "        return True\n",
    "    elif token1_stem == stemmer.stem(token2):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_antonyms(token1, token2):\n",
    "    token1 = token1.lower()\n",
    "    token2 = token2.lower()\n",
    "    token1_stem = stemmer.stem(token1)\n",
    "    antonym_lists_for_token2 = []\n",
    "    for synsets in wn.synsets(token2):\n",
    "        for lemma_synsets in [wn.synsets(l) for l in synsets.lemma_names()]:\n",
    "            for lemma_syn in lemma_synsets:\n",
    "                for lemma in lemma_syn.lemmas():\n",
    "                    for antonym in lemma.antonyms():\n",
    "                        antonym_lists_for_token2.append(antonym.name())\n",
    "                        # if token1_stem == stemmer.stem(antonym.name()):\n",
    "                        #     return True \n",
    "    antonym_lists_for_token2 = list(set(antonym_lists_for_token2))\n",
    "    for atnm in antonym_lists_for_token2:\n",
    "        if token1_stem == stemmer.stem(atnm):\n",
    "            return True\n",
    "    return False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SNLIDataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n('A person on a horse jumps over a broken down airplane.', 'A person is training his horse for a competition.', tensor(2))\n"
     ]
    }
   ],
   "source": [
    "for i,e in enumerate(data):\n",
    "    print(i)\n",
    "    print(e)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 549360/549360 [00:43<00:00, 12667.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract vocabulary\n",
    "def tokenize(string):\n",
    "    string = re.sub(r'\\(|\\)', '', string)\n",
    "    return string.split()\n",
    "\n",
    "\n",
    "word_counter = collections.Counter()\n",
    "char_counter = collections.Counter()\n",
    "\n",
    "for example in tqdm(data):\n",
    "    s1_tokenize = tokenize(example[0])\n",
    "    s2_tokenize = tokenize(example[1])\n",
    "\n",
    "    word_counter.update(s1_tokenize)\n",
    "    word_counter.update(s2_tokenize)\n",
    "\n",
    "    for i, word in enumerate(s1_tokenize):\n",
    "        char_counter.update([c for c in word])\n",
    "    for word in s2_tokenize:\n",
    "        char_counter.update([c for c in word])\n",
    "\n",
    "vocabulary = set([word for word in word_counter])\n",
    "vocabulary = list(vocabulary)\n",
    "vocabulary = [PADDING, \"<UNK>\"] + vocabulary\n",
    "\n",
    "\n",
    "word_indices = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "indices_to_words = {v: k for k, v in word_indices.items()}\n",
    "char_vocab = set([char for char in char_counter])\n",
    "char_vocab = list(char_vocab)\n",
    "char_vocab = [PADDING] + char_vocab\n",
    "char_indices = dict(zip(char_vocab, range(len(char_vocab))))\n",
    "indices_to_char = {v: k for k, v in char_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 549360/549360 [00:54<00:00, 9992.75it/s]\n"
     ]
    }
   ],
   "source": [
    "for example in tqdm(data):\n",
    "    indx_seq = np.zeros((12), dtype=np.int32)\n",
    "    tfidf = np.zeros((12), dtype=np.float32)\n",
    "\n",
    "    for sentence in [0,1]:\n",
    "        token_sequence = tokenize(example[sentence])\n",
    "        padding = 12 - len(token_sequence)\n",
    "        \n",
    "        for i in range(12):\n",
    "            if i >= len(token_sequence):\n",
    "                index = word_indices[PADDING]\n",
    "                itf = 0\n",
    "            else:\n",
    "                \n",
    "                index = word_indices[token_sequence[i]] if word_counter[token_sequence[i]] >= 3 else word_indices[\"<UNK>\"]\n",
    "                itf = 1 / (word_counter[token_sequence[i]] + 1)\n",
    "            indx_seq[i] = index\n",
    "            \n",
    "            tfidf[i] = itf\n",
    "        \n",
    "        char_index = np.zeros((12, 8), dtype=np.int32)\n",
    "        for i in range(12):\n",
    "            if i >= len(token_sequence):\n",
    "                continue\n",
    "            else:\n",
    "                chars = [c for c in token_sequence[i]]\n",
    "                for j in range(8):\n",
    "                        if j >= (len(chars)):\n",
    "                            break\n",
    "                        else:\n",
    "                            index = char_indices[chars[j]]\n",
    "                        char_index[i,j] = index \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/549360 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 84/549360 [00:00<10:59, 832.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 193/549360 [00:00<10:13, 894.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 286/549360 [00:00<10:08, 902.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 375/549360 [00:00<10:11, 897.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 459/549360 [00:00<10:25, 877.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 566/549360 [00:00<09:51, 927.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 674/549360 [00:00<09:27, 967.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 774/549360 [00:00<09:23, 973.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 899/549360 [00:00<08:46, 1040.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1002/549360 [00:01<09:07, 1000.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1102/549360 [00:01<09:10, 996.15it/s] \u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1202/549360 [00:01<09:52, 924.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1301/549360 [00:01<09:41, 942.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1401/549360 [00:01<09:32, 957.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1512/549360 [00:01<09:09, 997.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1616/549360 [00:01<09:02, 1009.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1718/549360 [00:01<09:10, 994.76it/s] \u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1818/549360 [00:01<09:33, 955.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1927/549360 [00:01<09:12, 990.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2036/549360 [00:02<08:57, 1017.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2146/549360 [00:02<08:46, 1038.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2253/549360 [00:02<08:42, 1047.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2362/549360 [00:02<08:36, 1059.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2469/549360 [00:02<09:42, 938.66it/s] \u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2579/549360 [00:02<09:17, 980.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2696/549360 [00:02<08:51, 1028.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 2802/549360 [00:02<08:52, 1026.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 2907/549360 [00:02<09:03, 1004.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3017/549360 [00:03<08:49, 1031.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3122/549360 [00:03<08:59, 1012.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3225/549360 [00:03<09:11, 989.75it/s] \u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3326/549360 [00:03<09:10, 992.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3437/549360 [00:03<08:54, 1022.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3571/549360 [00:03<08:16, 1099.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3683/549360 [00:03<08:24, 1081.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3793/549360 [00:03<08:24, 1081.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3904/549360 [00:03<08:20, 1088.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4014/549360 [00:03<08:22, 1085.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4124/549360 [00:04<08:24, 1080.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4233/549360 [00:04<08:44, 1038.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4340/549360 [00:04<08:40, 1046.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4446/549360 [00:04<08:55, 1018.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4549/549360 [00:04<09:20, 971.30it/s] \u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4655/549360 [00:04<09:07, 994.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4768/549360 [00:04<08:48, 1031.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4879/549360 [00:04<08:37, 1051.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4985/549360 [00:04<08:46, 1034.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 5089/549360 [00:05<08:54, 1018.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 5201/549360 [00:05<08:40, 1046.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 5307/549360 [00:05<08:58, 1010.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 5409/549360 [00:05<09:21, 968.10it/s] \u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 5507/549360 [00:05<10:10, 890.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 5621/549360 [00:05<09:30, 952.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 5734/549360 [00:05<09:03, 999.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 5837/549360 [00:05<09:12, 982.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 5943/549360 [00:05<09:02, 1001.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 6055/549360 [00:05<08:46, 1032.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 6164/549360 [00:06<08:37, 1049.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 6284/549360 [00:06<08:18, 1089.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 6394/549360 [00:06<08:44, 1035.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 6499/549360 [00:06<09:18, 971.44it/s] \u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 6598/549360 [00:06<09:30, 952.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 6709/549360 [00:06<09:05, 994.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 6830/549360 [00:06<08:37, 1048.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 6946/549360 [00:06<08:23, 1078.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 7056/549360 [00:06<08:31, 1059.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 7164/549360 [00:07<08:33, 1055.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 7271/549360 [00:07<08:44, 1034.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 7376/549360 [00:07<09:22, 962.68it/s] \u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 7490/549360 [00:07<08:56, 1009.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 7596/549360 [00:07<08:50, 1021.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 7700/549360 [00:07<08:54, 1012.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 7807/549360 [00:07<08:46, 1027.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 7911/549360 [00:07<09:14, 975.67it/s] \u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 8017/549360 [00:07<09:02, 998.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 8118/549360 [00:08<09:10, 983.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 8217/549360 [00:08<09:13, 977.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8316/549360 [00:08<09:19, 967.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8421/549360 [00:08<09:07, 987.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8521/549360 [00:08<09:19, 967.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8619/549360 [00:08<10:20, 871.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8712/549360 [00:08<10:11, 883.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8806/549360 [00:08<10:01, 898.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8897/549360 [00:08<10:01, 899.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9001/549360 [00:08<09:36, 937.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9096/549360 [00:09<09:44, 924.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9201/549360 [00:09<09:24, 957.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9310/549360 [00:09<09:04, 992.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9411/549360 [00:09<09:08, 983.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9512/549360 [00:09<09:04, 991.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9626/549360 [00:09<08:43, 1030.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9742/549360 [00:09<08:27, 1064.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9850/549360 [00:09<08:42, 1032.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9956/549360 [00:09<08:39, 1037.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 10061/549360 [00:10<08:55, 1006.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 10163/549360 [00:10<09:07, 985.49it/s] \u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 10263/549360 [00:10<09:24, 954.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 10377/549360 [00:10<08:57, 1003.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 10479/549360 [00:10<09:19, 963.88it/s] \u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 10581/549360 [00:10<09:10, 978.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 10680/549360 [00:10<09:10, 978.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 10781/549360 [00:10<09:06, 986.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 10881/549360 [00:10<09:13, 973.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 10979/549360 [00:10<09:14, 970.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 11102/549360 [00:11<08:40, 1034.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 11207/549360 [00:11<08:43, 1028.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 11311/549360 [00:11<08:51, 1013.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 11414/549360 [00:11<09:06, 984.70it/s] \u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 11514/549360 [00:11<09:14, 969.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 11612/549360 [00:11<09:19, 960.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 11709/549360 [00:11<09:52, 907.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 11810/549360 [00:11<09:35, 933.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 11912/549360 [00:11<09:21, 957.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 12009/549360 [00:12<10:15, 872.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 12116/549360 [00:12<09:42, 921.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 12211/549360 [00:12<10:05, 887.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 12323/549360 [00:12<09:27, 946.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 12420/549360 [00:12<09:55, 902.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 12513/549360 [00:12<10:17, 869.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 12623/549360 [00:12<09:38, 927.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 12718/549360 [00:12<09:52, 905.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 12826/549360 [00:12<09:24, 950.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 12941/549360 [00:13<08:57, 998.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 13043/549360 [00:13<09:14, 967.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 13157/549360 [00:13<08:49, 1013.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 13265/549360 [00:13<08:40, 1030.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 13370/549360 [00:13<09:13, 968.12it/s] \u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 13469/549360 [00:13<09:17, 961.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 13567/549360 [00:13<09:14, 965.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 13683/549360 [00:13<08:47, 1015.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 13794/549360 [00:13<08:34, 1041.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 13900/549360 [00:14<10:03, 886.91it/s] \u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 14003/549360 [00:14<09:39, 923.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 14100/549360 [00:14<09:32, 935.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 14204/549360 [00:14<09:16, 962.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 14303/549360 [00:14<10:06, 881.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 14406/549360 [00:14<09:41, 920.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 14501/549360 [00:14<09:37, 925.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 14596/549360 [00:14<09:47, 910.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 14697/549360 [00:14<09:30, 936.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 14792/549360 [00:14<09:42, 918.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 14906/549360 [00:15<09:08, 974.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 15010/549360 [00:15<08:58, 991.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 15111/549360 [00:15<08:57, 993.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 15212/549360 [00:15<08:57, 994.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 15312/549360 [00:15<09:10, 969.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 15410/549360 [00:15<09:12, 966.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 15507/549360 [00:15<09:37, 924.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 15601/549360 [00:15<09:54, 897.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 15704/549360 [00:15<09:31, 933.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 15824/549360 [00:16<08:54, 998.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 15929/549360 [00:16<08:47, 1011.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 16032/549360 [00:16<08:50, 1005.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 16134/549360 [00:16<08:48, 1009.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 16238/549360 [00:16<08:44, 1015.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 16347/549360 [00:16<08:35, 1033.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 16451/549360 [00:16<08:41, 1021.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 16560/549360 [00:16<08:31, 1040.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 16666/549360 [00:16<08:29, 1045.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 16771/549360 [00:16<08:57, 991.46it/s] \u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 16880/549360 [00:17<08:43, 1018.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 16985/549360 [00:17<08:38, 1026.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 17089/549360 [00:17<08:46, 1010.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 17195/549360 [00:17<08:40, 1022.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 17298/549360 [00:17<08:50, 1003.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 17399/549360 [00:17<09:17, 953.95it/s] \u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 17505/549360 [00:17<09:01, 981.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 17608/549360 [00:17<08:54, 994.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 17709/549360 [00:17<08:58, 986.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 17819/549360 [00:17<08:42, 1017.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 17925/549360 [00:18<08:36, 1028.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 18031/549360 [00:18<08:32, 1037.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 18136/549360 [00:18<08:36, 1027.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 18240/549360 [00:18<08:58, 985.65it/s] \u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 18340/549360 [00:18<09:19, 949.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 18436/549360 [00:18<09:17, 951.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 18538/549360 [00:18<09:06, 970.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 18642/549360 [00:18<08:57, 987.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 18742/549360 [00:18<09:09, 965.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 18843/549360 [00:19<09:03, 976.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 18944/549360 [00:19<08:58, 985.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 19043/549360 [00:19<09:13, 957.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 19143/549360 [00:19<09:07, 969.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 19247/549360 [00:19<08:56, 988.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 19356/549360 [00:19<08:41, 1016.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 19462/549360 [00:19<08:35, 1027.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 19566/549360 [00:19<09:19, 946.58it/s] \u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 19663/549360 [00:19<09:32, 925.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 19765/549360 [00:19<09:17, 950.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 19861/549360 [00:20<09:18, 948.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 19961/549360 [00:20<09:11, 960.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 20059/549360 [00:20<09:09, 962.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 20164/549360 [00:20<08:56, 985.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 20265/549360 [00:20<08:53, 992.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 20365/549360 [00:20<08:58, 982.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 20464/549360 [00:20<09:52, 893.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 20562/549360 [00:20<09:36, 917.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 20659/549360 [00:20<09:27, 931.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 20762/549360 [00:21<09:12, 957.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 20859/549360 [00:21<09:21, 940.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 20965/549360 [00:21<09:03, 972.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 21063/549360 [00:21<09:12, 956.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 21170/549360 [00:21<08:55, 986.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 21279/549360 [00:21<08:41, 1013.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 21381/549360 [00:21<09:04, 969.69it/s] \u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 21488/549360 [00:21<08:49, 997.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 21589/549360 [00:21<09:14, 951.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 21698/549360 [00:21<08:54, 987.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 21798/549360 [00:22<09:00, 976.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 21897/549360 [00:22<09:08, 962.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 21994/549360 [00:22<09:48, 895.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 22106/549360 [00:22<09:14, 951.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 22203/549360 [00:22<09:11, 955.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 22300/549360 [00:22<09:14, 949.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 22408/549360 [00:22<08:56, 983.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 22508/549360 [00:22<09:16, 946.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 22606/549360 [00:22<09:12, 954.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 22707/549360 [00:23<09:04, 966.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 22807/549360 [00:23<08:59, 975.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 22912/549360 [00:23<08:48, 996.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 23014/549360 [00:23<08:45, 1001.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 23116/549360 [00:23<08:43, 1005.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 23217/549360 [00:23<08:54, 985.22it/s] \u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 23321/549360 [00:23<08:46, 999.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 23426/549360 [00:23<08:40, 1011.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 23532/549360 [00:23<08:33, 1025.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 23639/549360 [00:23<08:27, 1036.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 23745/549360 [00:24<08:24, 1042.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 23850/549360 [00:24<08:37, 1015.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 23952/549360 [00:24<08:37, 1016.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 24054/549360 [00:24<08:38, 1013.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 24168/549360 [00:24<08:21, 1047.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 24274/549360 [00:24<08:39, 1011.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 24376/549360 [00:24<09:16, 943.05it/s] \u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 24478/549360 [00:24<09:04, 964.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 24576/549360 [00:24<09:33, 915.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 24669/549360 [00:25<09:38, 906.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 24773/549360 [00:25<09:17, 940.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 24878/549360 [00:25<09:00, 970.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 24978/549360 [00:25<08:56, 977.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 25077/549360 [00:25<09:05, 961.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 25174/549360 [00:25<09:04, 963.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 25271/549360 [00:25<09:13, 947.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 25378/549360 [00:25<08:56, 975.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 25477/549360 [00:25<09:02, 966.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 25579/549360 [00:25<08:54, 979.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 25678/549360 [00:26<08:52, 984.12it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ca61ed1d9b7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0ms1_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \"\"\"\n\u001b[1;32m    133\u001b[0m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_pos_tag\u001b[0;34m(tokens, tagset, tagger)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mtagged_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mtagged_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en-ptb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtagged_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36mtag\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mprev2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Do a secondary alphabetic sort, for stability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(data):\n",
    "    s1_pos = nltk.pos_tag(nltk.word_tokenize(i[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Hello', 'NNP'), ('how', 'WRB'), ('are', 'VBP'), ('you', 'PRP')]"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(\"Hello how are you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting chars2vec\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/0a/8c327aae23e0532d239ec7b30446aca765eb5d9547b4c4b09cdd82e49797/chars2vec-0.1.7.tar.gz (8.1MB)\n",
      "\u001b[K     |████████████████████████████████| 8.1MB 5.3MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: chars2vec\n",
      "  Building wheel for chars2vec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for chars2vec: filename=chars2vec-0.1.7-cp36-none-any.whl size=8111095 sha256=70ab86f76114af6952aba5fdc1f8ec59a9420683d6d57c98d49cf4d534feef89\n",
      "  Stored in directory: /root/.cache/pip/wheels/97/b6/65/d7e778ef1213ec77d315aea0f536068b96e36cc94c02abbfde\n",
      "Successfully built chars2vec\n",
      "Installing collected packages: chars2vec\n",
      "Successfully installed chars2vec-0.1.7\n"
     ]
    }
   ],
   "source": [
    "!pip install chars2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chars2vec\n",
    "c2v_model = chars2vec.load_model('eng_50')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CHAR_LIST = ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.',\n",
    "               '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<',\n",
    "               '=', '>', '?', '@', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n",
    "               'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w',\n",
    "               'x', 'y', 'z']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ind = {CHAR_LIST[j]:j for j in range(len(CHAR_LIST))}\n",
    "ind_to_char = {j:CHAR_LIST[j] for j in range(len(CHAR_LIST))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}